<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sketchy Polytopes</title>
    <description>Algorithms, optimization; systems, data, and people 
</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 25 Dec 2019 02:25:42 -0800</pubDate>
    <lastBuildDate>Wed, 25 Dec 2019 02:25:42 -0800</lastBuildDate>
    <generator>Jekyll v3.8.6</generator>
    
      <item>
        <title>Obituaries: Cathleen Morawetz (1923-2017)</title>
        <description>&lt;p&gt;In the mathematics of flows and shocks, &lt;a href=&quot;https://sinews.siam.org/Details-Page/obituary-cathleen-morawetz&quot;&gt;Cathleen Morawetz&lt;/a&gt;, 
&lt;a href=&quot;http://www.ams.org/notices/200411/fea-olga.pdf&quot;&gt;Olga Ladyzhenskaya&lt;/a&gt;, and Olga Oleinik together form a singular legacy, 
an interconnected legacy (&lt;a href=&quot;http://topo.math.auburn.edu/pub/2Olgas-proceedings/pa003-morawetz.pdf&quot;&gt;Early Memories of Olga Ladyzhenskaya and Olga Oleinik&lt;/a&gt;). 
One senses a process and procedure of inheritance indifferent to the act of birth 
(&lt;a href=&quot;http://topo.math.auburn.edu/pub/2Olgas-proceedings/&quot;&gt;Women in Mathematics: The Legacy of Ladyzhenskaya and Oleinik&lt;/a&gt;). &lt;/p&gt;

&lt;p&gt;“Of course, many discoveries have something of an accident about them,” 
&lt;a href=&quot;https://www.simonsfoundation.org/science_lives_video/cathleen-morawetz/&quot;&gt;said&lt;/a&gt; Morawetz. And, perhaps, Hölderlin would have 
responded: ”By that mysterious yearning toward the chasm; / Chaotic deeps attract, and whole peoples too”&lt;/p&gt;
</description>
        <pubDate>Fri, 18 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/08/18/obituaries-cathleen-morawetz-1923-2017/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/18/obituaries-cathleen-morawetz-1923-2017/</guid>
        
        <category>Obit</category>
        
        
      </item>
    
      <item>
        <title>Obituaries: Maryam Mirzakhani (1977 - 2017)</title>
        <description>&lt;p&gt;Maryam Mirzakhani &lt;a href=&quot;http://www.sfgate.com/bayarea/article/Stanford-University-professor-and-mathematician-11291210.php&quot;&gt;died&lt;/a&gt; 
today. Terrance Tao &lt;a href=&quot;https://terrytao.wordpress.com/2017/07/15/maryam-mirzakhani/&quot;&gt;writes&lt;/a&gt; about her. Elsewhere, Derrida - 
writing about Deleuze (&lt;em&gt;I’ll Have to Wander All Alone&lt;/em&gt;): “Too much to say, and I don’t have the heart for it today.” It is because:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;death takes from us not only some particular life within the world, some moment that belongs to us, but, each time, without limit, someone through whom the world, and first of all our own world, will have opened up in a both finite and infinite—mortally infinite—way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=mxPE6vYwqLg&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/mxPE6vYwqLg/0.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ias.edu/ideas/dynamics-moduli-spaces-curves-i&quot;&gt;Dynamics of the Moduli Spaces of Curves&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Jul 2017 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/07/16/obituaries-maryam-mirzakhani-1977-2017/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/07/16/obituaries-maryam-mirzakhani-1977-2017/</guid>
        
        <category>Obit</category>
        
        
      </item>
    
      <item>
        <title>A fearful sphere, whose center is everywhere</title>
        <description>&lt;p&gt;In a beautiful article, &lt;em&gt;The Mathematics of Doodling&lt;/em&gt;, &lt;a href=&quot;http://math.stanford.edu/~vakil/&quot;&gt;Ravi Vakil&lt;/a&gt; poses two problems:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Given a random curve, like a doodle, in what sense do closed curves successively drawn around the doodle become more and 
more circular?&lt;/li&gt;
  &lt;li&gt;How do geometric invariants, like area and volume, of the closed curves relate with the original shape and with each other?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/p2e.gif&quot; alt=&quot;p2e&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first question, at least, seemed connected to another interesting paper, &lt;em&gt;Random polygon to ellipse: an eigenanalysis.&lt;/em&gt; 
Here Elmachtoub and &lt;a href=&quot;http://www.cs.cornell.edu/cv/&quot;&gt;van Loan&lt;/a&gt; ask:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If we start with a random polygon and then create a succession of polygons by averaging the vertices of the previous polygon, 
do the polygons converge to something structured?&lt;/li&gt;
  &lt;li&gt;How is this structure related to the initial configuration of the polygon?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/loan.png&quot; alt=&quot;loan&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One uses geometry, and the other uses matrix analysis to investigate these question but both seems to ask how certain iterations of a geometric body lead to another.&lt;/p&gt;

&lt;p&gt;Let’s pose two related problems, and explore two methods that may give insight:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What kind of iterations transform bounded &lt;a href=&quot;https://en.wikipedia.org/wiki/Convex_polytope&quot;&gt;convex polyhedra&lt;/a&gt; to a circle?&lt;/li&gt;
  &lt;li&gt;How are the &lt;a href=&quot;https://en.wikipedia.org/wiki/Centroid&quot;&gt;centroid&lt;/a&gt;s of the polyhedra related to the center of the circle?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Cimmino’s algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gianfranco Cimmino [Benzi04] gave a unique method for solving a system of linear equations (&lt;strong&gt;A . x = b &lt;/strong&gt;i.e. &lt;strong&gt;ai&lt;/strong&gt; &lt;strong&gt;.&lt;/strong&gt; &lt;strong&gt;x&lt;/strong&gt; = &lt;strong&gt;b&lt;/strong&gt;, i = 1, 2…m). To find the point of intersection of &lt;em&gt;m&lt;/em&gt; n-dimensional hyperplanes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;start with an arbitrary point &lt;em&gt;y&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;find the mirror image of &lt;em&gt;y&lt;/em&gt; with respect to each hyperplane to yield &lt;em&gt;m&lt;/em&gt; projected points&lt;/li&gt;
  &lt;li&gt;calculate a weighted centroid of these m points&lt;/li&gt;
  &lt;li&gt;use the centroid as the new iterate&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/screen-shot-2016-12-19-at-4-24-05-pm.png&quot; alt=&quot;screen-shot-2016-12-19-at-4-24-05-pm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cimmino iteration [&lt;a href=&quot;http://www.dm.unibo.it/~simoncin/cimmino.pdf&quot;&gt;ref&lt;/a&gt;][/caption]How do we find the mirror image? 
Given a hyperplane &lt;strong&gt;ai&lt;/strong&gt;, its unit normal vector is &lt;strong&gt;-&lt;/strong&gt; &lt;strong&gt;ai &lt;/strong&gt;/ &lt;strong&gt;|a|&lt;/strong&gt;, where &lt;strong&gt;||&lt;/strong&gt; denotes the Euclidean norm. 
The distance between y and &lt;strong&gt;ai&lt;/strong&gt; is &lt;strong&gt;a&lt;/strong&gt;&lt;strong&gt;i&lt;/strong&gt; &lt;strong&gt;.&lt;/strong&gt; &lt;strong&gt;y&lt;/strong&gt; - &lt;strong&gt;b&lt;/strong&gt;, hence the distance between y and its reflection 
must be twice that. The unit normal vector transports y over a distance 
2 (&lt;strong&gt;ai&lt;/strong&gt; &lt;strong&gt;.&lt;/strong&gt; &lt;strong&gt;y&lt;/strong&gt; &lt;strong&gt;-&lt;/strong&gt; &lt;strong&gt;b&lt;/strong&gt;) to y + 2 (&lt;strong&gt;b - &lt;/strong&gt;&lt;strong&gt;ai .&lt;/strong&gt; &lt;strong&gt;y&lt;/strong&gt; &lt;strong&gt;) &lt;/strong&gt;ai &lt;strong&gt;/&lt;/strong&gt; |a|&lt;em&gt;**&lt;/em&gt;. Note that we need to choose 
the negative unit normal vector, instead of positive, to reflect the point around the hyperplane.&lt;/p&gt;

&lt;p&gt;The centroid is the average of these reflected point: 2/&lt;em&gt;m&lt;/em&gt; &lt;strong&gt;∑ (&lt;/strong&gt;b - &lt;strong&gt;**ai .&lt;/strong&gt; &lt;strong&gt;y&lt;/strong&gt; &lt;strong&gt;) &lt;/strong&gt;ai &lt;strong&gt;/&lt;/strong&gt; |a|&lt;strong&gt;**&lt;/strong&gt;. 
The weighted centroid for arbitrary normalized weights &lt;em&gt;wi&lt;/em&gt; would be: 
2 &lt;strong&gt;∑&lt;/strong&gt; wi&lt;strong&gt; (&lt;/strong&gt;b - &lt;strong&gt;**ai .&lt;/strong&gt; &lt;strong&gt;y&lt;/strong&gt; &lt;strong&gt;) &lt;/strong&gt;ai &lt;strong&gt;/&lt;/strong&gt; |a|&lt;strong&gt;,&lt;/strong&gt;** where ∑&lt;em&gt;wi&lt;/em&gt; = 1.&lt;/p&gt;

&lt;p&gt;In fact, this weighted centroid is only an &lt;a href=&quot;http://math.stackexchange.com/questions/3177/why-doesnt-a-simple-mean-give-the-position-of-a-centroid-in-a-polygon&quot;&gt;approximation&lt;/a&gt; to the true geometric centroid of the polygon since the entire mass of the initial polygon isn’t concentrated in its vertices (otherwise, a single iteration would suffice). Successive iterations improve this approximation by shrinking the polygon to a point, which is the geometric centroid.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://math.haifa.ac.il/yair/&quot;&gt;Censor&lt;/a&gt; and Elving extend Cimmino’s algorithm to a system of linear inequalities (Ax &amp;lt;= B) 
to fin one solution (i.e. a feasible point) [Censor83]. The calculation of the weighted centroid was all they needed to 
revamp, so the geometry of the algorithm remains unchanged.  To prove convergence, the authors appeal to the Fejér montonicity 
[Combettes00] of iterates (cf. with &lt;a href=&quot;https://en.wikipedia.org/wiki/Banach_fixed-point_theorem&quot;&gt;contraction mapping&lt;/a&gt; for 
Banach space). A sufficient condition for convergence in their scheme is that &lt;em&gt;wi&lt;/em&gt; &amp;gt; 0.&lt;/p&gt;

&lt;p&gt;How does this relate to [Elmachtoub07]?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In both Cimmino’s algorithm and [Elmachtoub07]’s Algorithm 1, the centroid is fixed but unknown. They both construct 
successive polytopes that converge to the centroid.&lt;/li&gt;
  &lt;li&gt;Both Cimmino’s algorithm and Algorithm 1 converge to the centroid of the initial polygon.&lt;/li&gt;
  &lt;li&gt;Cimmino’s polygon, far from being random, is specifically constructed using orthogonal projections of a given point. The 
constructed polygon is &lt;a href=&quot;http://mathworld.wolfram.com/CyclicPolygon.html&quot;&gt;cyclic&lt;/a&gt;, and its 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Circumscribed_circle&quot;&gt;circumcenter&lt;/a&gt; and centroid coincide.&lt;/li&gt;
  &lt;li&gt;How do normalized iterates affect convergence? If iterates in Cimmino’s algorithm are normalized such that the circumcenter 
doesn’t change, then they oscillate on a limit cycle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;von Neumann’s algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An early algorithm for solving a system of linear inequalities, &lt;strong&gt;A . x &amp;lt;= b&lt;/strong&gt;, comes from 
&lt;a href=&quot;https://en.wikipedia.org/wiki/John_von_Neumann&quot;&gt;John von Neumann&lt;/a&gt; via 
&lt;a href=&quot;https://en.wikipedia.org/wiki/George_Dantzig&quot;&gt;George Dantzig&lt;/a&gt; [Dantzig92].&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/screen-shot-2016-12-20-at-12-00-24-am.png&quot; alt=&quot;screen-shot-2016-12-20-at-12-00-24-am&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We start with a “standardized” polyhedron:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Transform &lt;strong&gt;A . x&lt;/strong&gt; &lt;strong&gt;&amp;lt;= b&lt;/strong&gt; into &lt;strong&gt;∑ Pj . x&lt;/strong&gt; = &lt;strong&gt;0&lt;/strong&gt;, &lt;strong&gt;∑ x = 1&lt;/strong&gt;, &lt;strong&gt;x &amp;gt;= 0&lt;/strong&gt; such that &lt;strong&gt;|&lt;/strong&gt;&lt;strong&gt;Pj|&lt;/strong&gt; = 1. Thus the 
points &lt;strong&gt;Pj&lt;/strong&gt; lie on a hypersphere of radius 1 and center 0.&lt;/li&gt;
  &lt;li&gt;Select an arbitrary initial point &lt;strong&gt;x&lt;/strong&gt; &amp;gt;= 0, such that ∑x = 1. This also corresponds to selecting an arbitrary point P1 on 
the hyper-sphere and considered as iterate A1.&lt;/li&gt;
  &lt;li&gt;The aim is to set the next iterate At so that the distance, ut, to origin is minimized. This is done by choosing the 
hypersphere point, Ps, that minimizes the angle, φ, subtended by At-1 and Ps. Then At is point on the line At-1 - Ps and its normal that passes through origin.&lt;/li&gt;
  &lt;li&gt;Iterate till ut decreases to ε.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unlike Cimmino or Algorithm 1, the centroid is fixed and known as the circumcenter of given points. What the algorithm 
discovers, while solving the feasibility problem, is the polygon whose weighted point-mass centroid would be this circumcenter. 
Note that since the algorithm projects points to minimize distance to the center, the number of iterations is independent of 
the dimensions of the problem (unlike Cimmino). If iterates are normalized, then they are always projected on to the 
hypersphere, which would be their limit cycle.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fourier polygons&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Why does a general polygon, under averaging iterations, converge to an ellipse and not to a circle? The short answer is 
that the &lt;a href=&quot;https://www.cs.mtu.edu/~shene/COURSES/cs3621/NOTES/geometry/geo-tran.html#affine&quot;&gt;affine transformation&lt;/a&gt; of a 
circle is an ellipse.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/screen-shot-2016-12-22-at-3-18-44-pm.png&quot; alt=&quot;screen-shot-2016-12-22-at-3-18-44-pm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A compelling reinterpretation of the discrete Fourier transform [Glassner99] argues that the transform matrix can be
viewed as regular polygons in the complex plane. As a corollary, any polygon can be decomposed into a weighted sum 
(an affine transformation) of regular polygons.&lt;/p&gt;

&lt;p&gt;$P = \dfrac1n \sum\limits_{k=0}^{n-1} X_k P_k$&lt;/p&gt;

&lt;p&gt;In any such transformation, three regular polygons are important: $P_0$, $P_1$, and $P_{n-1}$. $P_0$ corresponds on a point, but 
the other two are &lt;a href=&quot;https://en.wikipedia.org/wiki/Regular_polygon&quot;&gt;regular, convex n-gons&lt;/a&gt;. The averaging transformation can 
now be applied to this sum of regular polygons. As David Radcliffe 
&lt;a href=&quot;https://mathblag.wordpress.com/2013/10/08/inscribed-polygons-and-the-fourier-transform/&quot;&gt;argues&lt;/a&gt;, all component polygons 
shrink (except for $P_0$) but $P_1$ and $P_{n-1}$ shrink at the slowest rate leaving us with an affine combination of the 
three shrunk regular polygons converging to an ellipse. While [Elmachtoub07] uses a rather involved matrix analysis 
to converge a random polygon to an ellipse, Radcliffe’s argument is far more intuitive (and not too far from quantization).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Steiner, Weyl, Minkowski&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We return to Vakil’s problem. For parallel bodies drawn around a non-empty convex body, $K$, 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Jakob_Steiner&quot;&gt;Steiner&lt;/a&gt; proposed a volume formula:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/screen-shot-2016-12-22-at-12-25-12-pm.png&quot; alt=&quot;screen-shot-2016-12-22-at-12-25-12-pm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The formula, as Vakil notes, is polynomial in the radius, ε, of the neighborhood, and relates volume to surface area. 
Depending on ε, the volume may converge to an n-sphere, $V(Β_n)$, or to the volume of the convex body, $V(K)$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A &lt;em&gt;fearful sphere&lt;/em&gt; comes from a &lt;a href=&quot;https://sites.google.com/site/jimeikner/home/borges/the-fearful-sphere-of-pascal&quot;&gt;handful of metaphors&lt;/a&gt;. 
For linear systems, &lt;a href=&quot;https://en.wikipedia.org/wiki/Kaczmarz_method&quot;&gt;Kaczmarz&lt;/a&gt; and Cimmino are basic iterative algorithms, 
now considered part of &lt;a href=&quot;https://arxiv.org/pdf/1406.6143.pdf&quot;&gt;projection methods&lt;/a&gt;. von Neumann studied the general question - 
maps of &lt;a href=&quot;http://press.princeton.edu/titles/3136.html&quot;&gt;linear operators&lt;/a&gt; - of early on. The discrete Fourier transform can 
be &lt;a href=&quot;http://www-personal.umich.edu/~pion/feat/fcarc-geometricFT1.htm&quot;&gt;viewed&lt;/a&gt; geometrically and 
&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.384.3752&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;applied&lt;/a&gt; to geometric shapes. The 
Steiner formula is a special instance of &lt;a href=&quot;https://en.wikipedia.org/wiki/Hermann_Minkowski&quot;&gt;Minkowski&lt;/a&gt;’s 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Mixed_volume&quot;&gt;mixed volume&lt;/a&gt; [Schröder08], and 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Hermann_Weyl&quot;&gt;Weyl&lt;/a&gt;’s formula for the 
&lt;a href=&quot;http://www.math.uchicago.edu/~shmuel/AAT-readings/Data%20Analysis%20/Tubes/Weyl,%20volume%20of%20tubes.pdf&quot;&gt;volume of a tube&lt;/a&gt; 
of a submanifold.&lt;/p&gt;

&lt;p&gt;Fourier polygons&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.mathcs.emory.edu/~benzi/Web_papers/cimmino.pdf&quot;&gt;Benzi04&lt;/a&gt; M. Benzi. &lt;em&gt;Gianfranco Cimmino’s contributions to numerical mathematics.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=E917107F48557468472D333B1CBCDE19?doi=10.1.1.221.2980&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Combettes00&lt;/a&gt; P. Combettes. &lt;em&gt;Fejér monotonicity in convex optimization&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/0024379582901495&quot;&gt;Censor83&lt;/a&gt; Y. Censor, T. Elfving. &lt;em&gt;New methods for linear inequalities.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.stanford.edu/group/SOL/reports/SOL-92-5.pdf&quot;&gt;Dantzig92&lt;/a&gt; G. Dantzig. &lt;em&gt;An ε-precise feasible solution to a linear program with a convexity constraint in 1/ε² iterations independent of problem size.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.cornell.edu/cv/ResearchPDF/EllipsePoly.pdf&quot;&gt;Elmachtoub07&lt;/a&gt; A. Elmachtoub, C. van Loan. &lt;em&gt;Random polygons to ellipse: an eigenanalysis&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.glassner.com/wp-content/uploads/2014/04/CG-CGA-PDF-99-01-Fourier-Polygons-Jan99.pdf&quot;&gt;Glassner99&lt;/a&gt; A. Glassner. &lt;em&gt;Fourier polygons&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.multires.caltech.edu/pubs/GeoMeasureCourse.pdf&quot;&gt;Shröder08&lt;/a&gt; P. Schröder. &lt;em&gt;What can we measure?&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.maa.org/sites/default/files/pdf/awards/The%20Mathematics%20of%20Doodling.pdf&quot;&gt;Vakil04&lt;/a&gt; R. Vakil. &lt;em&gt;The mathematics of doodling&lt;/em&gt;. .&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 23 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2016/12/23/a-fearful-sphere-whose-center-is-everywhere/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/12/23/a-fearful-sphere-whose-center-is-everywhere/</guid>
        
        <category>Convex</category>
        
        <category>geometry,</category>
        
        <category>Convex</category>
        
        <category>optimization,</category>
        
        <category>First-order</category>
        
        <category>methods,</category>
        
        <category>Linear</category>
        
        <category>Algebra,</category>
        
        <category>Linear</category>
        
        <category>programming,</category>
        
        <category>Linear</category>
        
        <category>systems,</category>
        
        <category>Mathematics</category>
        
        
      </item>
    
      <item>
        <title>2-butterfly derangement</title>
        <description>&lt;p&gt;The hallmark of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cooley–Tukey_FFT_algorithm&quot;&gt;Cooley-Tukey algorithm&lt;/a&gt; for  &lt;a href=&quot;https://en.wikipedia.org/wiki/Fast_Fourier_transform&quot;&gt;Fast Fourier Transform&lt;/a&gt; is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Butterfly_network&quot;&gt;butterfly network&lt;/a&gt;, which helps reduce O(N^2) computations to O(N_log_N). Butterflies are very special graphs entangled in routing [Arora], switching [Chung], shuffling [Yang], and mixing [Czumaj].&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_1761” align=”aligncenter” width=”619”]&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/res3.png&quot; alt=&quot;res3&quot; /&gt; Three butterflies - FFT flow graph, shuffling network, and a nonblocking interconnect[/caption]&lt;/p&gt;

&lt;p&gt;The butterfly with 2 inputs and outputs (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Butterfly_diagram#Radix-2_butterfly_diagram&quot;&gt;radix-2 butterfly&lt;/a&gt;, or the &lt;a href=&quot;http://mathworld.wolfram.com/CompleteBipartiteGraph.html&quot;&gt;bipartite graph&lt;/a&gt; K(2, 2)) is a building block for larger networks [Chung]. It can implement two distinct operations: pass-through and swap.&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_1779” align=”aligncenter” width=”465”]&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/screen-shot-2016-12-09-at-1-49-32-pm.png&quot; alt=&quot;screen-shot-2016-12-09-at-1-49-32-pm&quot; /&gt; pass-through, and swap[/caption]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem 1&lt;/strong&gt;: Can an array of size N be &lt;a href=&quot;https://en.wikipedia.org/wiki/Permutation&quot;&gt;permuted&lt;/a&gt; using only swapping 2-butterflies in a single stage? Single stage implies that every element is swapped exactly once.&lt;/p&gt;

&lt;p&gt;Clearly, it can be iff N is even (otherwise the mapping is not bijective). Each permutation is also a &lt;a href=&quot;https://en.wikipedia.org/wiki/Matching_(graph_theory)&quot;&gt;maximal matching&lt;/a&gt; on the K(N/2, N/2) spanning N elements.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem 2&lt;/strong&gt;: Can an array be &lt;a href=&quot;https://en.wikipedia.org/wiki/Derangement&quot;&gt;deranged&lt;/a&gt; using only swapping 2-butterflies in a single stage?&lt;/p&gt;

&lt;p&gt;There are always at least two derangements for any even-sized array when N &amp;gt; 2 (only one if N = 2). One can be obtained by swapping N/2 non-overlapping pairs. Another, by swapping the two halves of the array. Here’re two for N = 16:&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_1822” align=”alignnone” width=”1191”]&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/fft16.png&quot; alt=&quot;fft16&quot; /&gt; Any even N has at least these two derangements[/caption]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem 3&lt;/strong&gt;: How many such derangements are possible?&lt;/p&gt;

&lt;p&gt;Let N = m * 2^k, where m &amp;gt;= 1 is some odd integer, and k &amp;gt; 0. There are at most log(k) - or, log(N), if m = 1 - distinct derangements.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Problem 4&lt;/strong&gt;: Is there a permutation of the first N natural numbers, [1..N], such that if a number x is mapped to a number y in the permutation, then&lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt;== K for all x and y, and for a given 0 &amp;lt; K &amp;lt; N?&lt;/td&gt;
      &lt;td&gt;*&lt;/td&gt;
      &lt;td&gt;denotes the absolute value. In other words, is there a bijective function f mapping [1..N] to [1..N] such that&lt;/td&gt;
      &lt;td&gt;x - f(x)&lt;/td&gt;
      &lt;td&gt;== K?&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/screen-shot-2016-12-09-at-3-14-18-pm.png&quot; alt=&quot;screen-shot-2016-12-09-at-3-14-18-pm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since K &amp;gt; 0, this permutation must be a derangement. The previous two examples for N = 16 illustrate K = 1 and K = 8. They represent a derangement that swaps N / K groups of K neighbors with each other. If K leaves an even factor to N, and K &amp;lt;= N/2, then such a derangement always exists. Here’s a short program to print them out:&lt;/p&gt;

&lt;p&gt;[code language=”java”] public static String permute(int n, int k) { StringBuilder result = new StringBuilder(2 * n); if (n % 2 == 0 &amp;amp;&amp;amp; k &amp;gt; 0 &amp;amp;&amp;amp; k &amp;lt;= (n / 2)) { // any k that leaves an even factor is fine // e.g. k = 4 for n = 12 is not valid but k = 2 is if ((n % k == 0) &amp;amp;&amp;amp; ((n / k) % 2 == 0)) { // groups of k are swapped with neighbors int k2 = k * 2; for (int g = 0; g &amp;lt; n / k2; ++g) { int f = k2 * g; for (int i = k + 1; i &amp;lt;= k2; ++i) { result.append(f + i).append(“ “); } for (int i = 1; i &amp;lt;= k; ++i) { result.append(f + i).append(“ “); } } return result.toString(); } } return “No permutation exists”; } [/code]&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://www.cs.princeton.edu/~arora/pubs/nonblock.ps&quot;&gt;Arora&lt;/a&gt;] S. Arora, F. T. Leighton, B. M. Maggs. &lt;em&gt;Online algorithms for path selection in a nonblocking network&lt;/em&gt;. [&lt;a href=&quot;http://www.math.ucsd.edu/~fan/mypaps/fanpap/fc15algebraic.pdf&quot;&gt;Chung&lt;/a&gt;] F. R. K. Chung. &lt;em&gt;An algebraic approach to switching networks&lt;/em&gt;. [&lt;a href=&quot;https://arxiv.org/pdf/1204.1958.pdf&quot;&gt;Yang&lt;/a&gt;] Q. Yang, J. Ellis, K. Mamakani, F. Ruskey. &lt;em&gt;In-place permuting and perfect shuffling using involutions&lt;/em&gt;. [&lt;a href=&quot;http://www.dcs.warwick.ac.uk/~czumaj/PUBLICATIONS/CONFERENCES/Czumaj-STOC-2015-703-712.pdf&quot;&gt;Czumaj&lt;/a&gt;] A. Czumaj. &lt;em&gt;Random permutations using __switching networks&lt;/em&gt;.&lt;/p&gt;
</description>
        <pubDate>Sat, 10 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2016/12/10/2-butterfly-derangement/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/12/10/2-butterfly-derangement/</guid>
        
        
      </item>
    
      <item>
        <title>Maximum weighted independent set - connected component</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/coloringpeteresen2.png&quot; alt=&quot;coloringpeteresen2&quot; /&gt;Given a weighted &lt;a href=&quot;https://en.wikipedia.org/wiki/Connected_component_(graph_theory)&quot;&gt;connected component&lt;/a&gt;, what is the weight of of the maximum independent set, and how many different sets have this weight? A &lt;a href=&quot;https://en.wikipedia.org/wiki/Petersen_graph&quot;&gt;Petersen graph&lt;/a&gt; GP(5, 2) with zero vertex weights has three maximal subsets by size, 0 maximum set weight but 76 distinct independent sets with this weight.&lt;/p&gt;

&lt;p&gt;The brute-force method is to enumerate all possible set of nodes, check for independence and filter for maximum weight. It is guaranteed to run 2^n times, which quickly becomes prohibitively slow (e.g. n &amp;gt;= 30). The only graph this method really works for is a forest of singletons, which, as we saw in the previous post, can be processed very quickly.&lt;/p&gt;

&lt;p&gt;private static Result powerSetMethod(int size, Map&amp;lt;Integer, BitSet&amp;gt; adjacent, int[] compWeights) {
     int maxSetSum = 0;
     int maxSetCount = 0;
     long maxIdx = (long) (Math.pow(2, size) - 1);
     for (long idx = 1; idx &amp;lt;= maxIdx; ++idx) {
         BitSet set = BitSet.valueOf(new long[] { idx });
         if (isIndependent(set, adjacent)) {
             int setSum = weightSum(set, compWeights);
             if (setSum &amp;gt; maxSetSum) {
                 maxSetSum = setSum; maxSetCount = 1;
             } else if (setSum == maxSetSum) {
                 ++maxSetCount;
             }
         }
     }
     // number of ways to get the max weight
     return new Result(maxSetSum, maxSetCount);
 }&lt;/p&gt;

&lt;p&gt;Yet, as we will see, it is still a simple and useful method for enumerating all sets if n is small.&lt;/p&gt;

&lt;p&gt;A faster way would be to start with the set of all nodes and, in each iteration, check for independence. If the set is independent, check for the maximum weight. Otherwise, for a given node with conflict, create two new sets: one without the node, and one without its neighbors. The independent sets iteratively found this way are maximal.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] /* * select the node, v, from remnant component V that maximizes the values of w(v) + w(V - {v U N(v)}). V - {v U * N(v)} is the remnant component for the next iteration. */ private static Result recursiveMethod(int size, Map&amp;lt;Integer, BitSet&amp;gt; adjacent, int[] compWeights) { // all nodes to start with BitSet maxSet = new BitSet(size); maxSet.set(0, size); TreeSet stack = new TreeSet&amp;lt;&amp;gt;(BITSET_COMPARATOR); stack.add(maxSet); return recurse(stack, adjacent, compWeights); }&lt;/p&gt;

&lt;p&gt;/** * recursively find maximum weighted independent subset by enumerating all maximal independent subsets */ private static Result recurse( TreeSet stack, Map&amp;lt;Integer, BitSet&amp;gt; adjacent, int[] compWeights ) { HashSet maximalSets = new HashSet&amp;lt;&amp;gt;(); int maxSum = 0; // collect maximal sets while (!stack.isEmpty()) { boolean isIndependent = true; BitSet nodeSet = stack.pollFirst(); // for a pair of adjacents, create two new for (int i = nodeSet.length(); (i = nodeSet.previousSetBit(i - 1)) &amp;gt;= 0;) { BitSet adjSet = adjacent.get(i); if (nodeSet.intersects(adjSet)) { isIndependent = false; BitSet newSet = (BitSet) nodeSet.clone(); newSet.clear(i); // keep neighbors stack.add(newSet); for (int j = adjSet.length(); (j = adjSet.previousSetBit(j - 1)) &amp;gt;= 0;) { nodeSet.clear(j); // remove neighbors, reuse nodeSet } stack.add(nodeSet); break; } } if (isIndependent) { int nodeSetSum = weightSum(nodeSet, compWeights); if (nodeSetSum &amp;gt; maxSum) { maxSum = nodeSetSum; maximalSets.clear(); maximalSets.add(nodeSet); } else if (nodeSetSum == maxSum) { maximalSets.add(nodeSet); } } } // break maximal sets, if needed HashSet indepSets = new HashSet&amp;lt;&amp;gt;(); for (BitSet nodeSet : maximalSets) { processMaximalSet(nodeSet, compWeights, indepSets); } return new Result(maxSum, indepSets.size()); } [/sourcecode]&lt;/p&gt;

&lt;p&gt;If all the nodes in a maximum independent set are positively weighted, we can just return all such sets. For maximum sets with zero-weighted nodes, we’ll need to find all unique subsets that have the same weight. This is where power-set enumeration is helpful.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] private static void processMaximalSet(BitSet nodeSet, int[] compWeights, HashSet&lt;Integer&gt; indepSets) { // generate and store all non-maximal independent subsets from a given maximal List&lt;Integer&gt; nodesWithZeros = new ArrayList&amp;lt;&amp;gt;(nodeSet.length() + 1); BitSet nodeSetClone = (BitSet) nodeSet.clone(); for (int i = nodeSet.length(); (i = nodeSet.previousSetBit(i - 1)) &amp;gt;= 0;) { if (compWeights\[i\] == 0) { nodesWithZeros.add(i); nodeSetClone.clear(i); } } if (nodesWithZeros.isEmpty()) { indepSets.add(nodeSetClone.hashCode()); } else { // no empty sets, please if (nodeSetClone.cardinality() &amp;gt;= 1) { indepSets.add(nodeSetClone.hashCode()); } long maxIdx = (long) (Math.pow(2, nodesWithZeros.size()) - 1); for (long idx = 1; idx &amp;lt;= maxIdx; ++idx) { BitSet idxSet = BitSet.valueOf(new long\[\] { idx }); BitSet cloneWithZeros = (BitSet) nodeSetClone.clone(); for (int i = idxSet.length(); (i = idxSet.previousSetBit(i - 1)) &amp;gt;= 0;) { cloneWithZeros.set(nodesWithZeros.get(i)); } indepSets.add(cloneWithZeros.hashCode()); } } } \[/sourcecode\]&lt;/Integer&gt;&lt;/Integer&gt;&lt;/p&gt;

&lt;p&gt;-&lt;/p&gt;
</description>
        <pubDate>Fri, 09 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2016/12/09/maximum-weighted-independent-set-connected-component/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/12/09/maximum-weighted-independent-set-connected-component/</guid>
        
        
      </item>
    
      <item>
        <title>Maximum weighted independent set - singletons and forest</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Gus wants to open franchises of his restaurant, Los Pollos Hermanos, along Central Avenue. There are n possible locations for franchises, where location i is at mile i on Central. Each location i &amp;gt; 1, is thus a distance of 1 mile from the previous one. There are two rules.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;At each location, there can be at most one restaurant, and the profit of a restaurant at location i is p_i.&lt;/li&gt;
    &lt;li&gt;Any two restaurants must be at least 2 miles apart.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/12/clebschgraphk16_800.gif&quot; alt=&quot;clebschgraphk16_800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.unm.edu/~saia/classes/561-f14/hw/hw3.pdf&quot;&gt;This&lt;/a&gt; is one way to state the sequential facility location problem, which can be solved efficiently using a memo-ized dynamic program:&lt;/p&gt;

&lt;p&gt;int sequentialFacility(idx, profits[]):
    if (idx &amp;gt;= profits.length) 
        return 0
    return MAX( sequentialFacility(idx + 1),  sequentialFacility(idx + 2) + profits[idx])&lt;/p&gt;

&lt;p&gt;Its generalization, graph facility location, is NP-complete, being equivalent to finding the &lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_set_(graph_theory)&quot;&gt;maximum weighted independent set&lt;/a&gt; of a graph. This post is about calculating the weight of such a set, and the number of ways to find this maximum weight, for a general graph. We’ll assume non-negative weights throughout.&lt;/p&gt;

&lt;p&gt;Let’s start with graph representation. We’ll assume that the graph can be conveniently represented with &lt;a href=&quot;https://docs.oracle.com/javase/7/docs/api/java/util/BitSet.html&quot;&gt;BitSet&lt;/a&gt;s (which are very &lt;a href=&quot;http://lemire.me/blog/2012/11/13/fast-sets-of-integers/&quot;&gt;efficient&lt;/a&gt; to work with). This graph can be searched with a map that gives the adjacent set for each node, and then node independence can be tested for quickly:&lt;/p&gt;

&lt;p&gt;[code language=”java”] /* * @return true iff the nodes in a given set are independent. Assumes that all BitSets involved are of the same * size, and that a node is not adjacent to itself. O(n^2) really, but still much faster */ private static boolean isIndependent(BitSet set, Map&amp;lt;Integer, BitSet&amp;gt; adjacent) { for (int i = set.length(); (i = set.previousSetBit(i - 1)) &amp;gt;= 0;) { if (set.intersects(adjacent.get(i))) { return false; } } return true; } [/code]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Singletons&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;What if the given graph is composed only of singletons? The max weight of the independent set is trivial: sum of all nodes. The number of ways to achieve this max  depends on whether or not there are nodes with zero weight. There are three cases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;All node weights are positive&lt;/li&gt;
  &lt;li&gt;All node weight are zero&lt;/li&gt;
  &lt;li&gt;Non-negative weights&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1) is trivial, and there is only 1 way to achieve the max weight; (2) implies a power-set: there are 2^n ways to sum to 0 using only 0s, including the null set; (3) implies a union of (1) and (2) - there are 2^k ways, where k &amp;lt; n is the number of nodes with zero weight.&lt;/p&gt;

&lt;p&gt;[code language=”java”] /* * For N singletons, each with weight w[i] &amp;gt;= 0, returns the sum of weights, and the number of ways to achieve * sum-weight, across singletons. For all non-zero components, there’s only one way to achieve sum-weight. */ private static Result singletons(int[] w) { int zeros = 0, sum = 0; for (int i = 0; i &amp;lt; w.length; ++i) { if (w[i] == 0) { ++zeros; } sum += w[i]; } // zeros translates to power-set (including the null set) if (zeros == w.length) { return new Result(0, BigInteger.valueOf(2).pow(w.length)); } else if (zeros == 0) { return new Result(sum, 1); } // size of the union of non-zeros (treated as one set) and the powerset of zeros i.e. null set is accounted for return new Result(sum, BigInteger.valueOf(2).pow(zeros)); } [/code]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Forest&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Though a forest in graph theory &lt;a href=&quot;https://en.wikipedia.org/wiki/Tree_(graph_theory)#Forest&quot;&gt;refers&lt;/a&gt; to a disjoint set of trees, we’ll use it to mean any disjoint set of connected components. Forests are a natural extension of singletons, and help decompose a given graph into smaller independent set problems. If we are given all the connected components of a graph, and, for each component, the sum of its weighted max independent set and the number of ways to find the sum; how can we combine this information to solve for the general graph? We face the same three cases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;All component weights are positive: the graph sum is the sum of all components, and the number of ways is the product of the ways of all components.&lt;/li&gt;
  &lt;li&gt;Zero weights: perhaps the most interesting case. Consider three components with ways (1, 2, 3). The number of ways of combining them would be: 1 + (1 + 2 + 3) + (1*2 + 2*3 + 1*3 )+ (1*2*3). This enumeration forms a pretty polynomial: given values a, b, c…, there are (a + 1)(b + 1)(c + 1)… ways (including null set). This generalizes naturally to the power-set for the case where a = b = c …= 1.&lt;/li&gt;
  &lt;li&gt;As before, it’s a union of (1) and (2)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;/*
 * For N components, each with weight w[i] &amp;gt;= 0, returns the sum of weights, and the number of ways to achieve
 * sum-weight, across components. For all non-zero components with ways = 1, there’s only one way to achieve
 * sum-weight. For zeros, well, it’s a little more complicated. E.g. given components with 0 max, and ways (a, b, * c), there’re 2^3 combinations of combinations: a + b + c + (a * b) + (a * c) + (b * c) + (a * b * c) = (a + 1)(b * + 1)(c + 1) e.g. 1 + 2 + 3 + 1*2 + 2*3 + 1*3 + 1*2*3 + 1 (including null set)
 */
 private static Result components(Result[] c) {
     int zeros = 0, sum = 0;
     BigInteger nonzeroProduct = BigInteger.ONE;
     for (int i = 0; i &amp;lt; c.length; ++i) {
         if (c[i].max == 0) {
             ++zeros;
         } else {
             nonzeroProduct = nonzeroProduct.multiply(c[i].ways);
         }
         sum += c[i].max;
     }
     // all components have non-zero max
     if (zeros == 0) {
         return new Result(sum, nonzeroProduct);
     }
     // since we already have the number of ways to sum all non-zero components,
     // find the number of way to sum zero components by evaluating the product polynomial
     BigInteger zeroTotal = BigInteger.ONE;
     for (int i = 0; i &amp;lt; c.length; ++i) {
         if (c[i].max == 0) {
             BigInteger ways = c[i].ways;
             zeroTotal = zeroTotal.multiply(ways.add(BigInteger.ONE));
         }
     }
     if (zeros == c.length) {
         return new Result(sum, zeroTotal);
     }
     // now the total number is nonzeroProduct * (zeroTotal) since non-zero components together form a valid
     // combination without any zero components involved.
     return new Result(sum, nonzeroProduct.multiply(zeroTotal));
 }&lt;/p&gt;

&lt;p&gt;Once we’ve accounted for singletons and forest, we need to solve the independent set problem for each connected component. This would the topic of the next post.&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Dec 2016 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2016/12/06/maximum-weighted-independent-set-singletons-and-forest/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/12/06/maximum-weighted-independent-set-singletons-and-forest/</guid>
        
        
      </item>
    
      <item>
        <title>Rational numbers in decimal</title>
        <description>&lt;p&gt;In decimal representation, &lt;a href=&quot;https://en.wikipedia.org/wiki/Rational_number&quot;&gt;rational numbers&lt;/a&gt; either terminate after a finite number of digits or produce a repeating sequence. Conversely, any repeating decimal can be &lt;a href=&quot;http://mathcentral.uregina.ca/QQ/database/QQ.09.06/h/lil1.html&quot;&gt;converted&lt;/a&gt; into a rational number e.g. (10 * 0.333.. - 0.333…) / 9 = 1/3.&lt;/p&gt;

&lt;p&gt;How can one generate this representation in code with the repeating digits, if any, parenthesized? Find values 0 &amp;lt;= n &amp;lt; b, the period of repeating decimal,  and 0 &amp;lt;= m &amp;lt; b, the length of the period’s prefix, such that (10^n - 1) * 10^m / b is an integer. E.g. 1 / 3 = 0.(3) has n = 1 and m = 0 while 89/26 = 3.4(230769) has n = 6 and m = 1.&lt;/p&gt;

&lt;p&gt;Here’s code that avoids using floating-point division and shortest repeating substring to find the decimal representation. Note that the method used to find n and m have linear complexity but can be implemented using binary search. See note at the end for another way to find m, the length of the prefix.&lt;/p&gt;

&lt;p&gt;[code language=”java”] private static String printRational(long num, long den) { StringBuilder sb = new StringBuilder();&lt;/p&gt;

&lt;p&gt;// early return for finite-length strings if (!isRepeating(sb, num, den)) { return sb.toString(); }&lt;/p&gt;

&lt;p&gt;// find the period of the repeating part int period = 1; long rem = 0; long numMult = 0; for (long mult = 10; period &amp;lt; den; ++period, mult *= 10) { numMult = (mult - 1) * num; long quot = numMult / den; rem = numMult - quot * den;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;if (rem == 0&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;!isRepeating(null, numMult, den)) { break; } }&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;// return if the decimal has no prefix if (rem == 0) { return sliceString(sb, 0, period); }&lt;/p&gt;

&lt;p&gt;// otherwise, find the length of the prefix int prefix = 0; rem = 1; for (; (prefix &amp;lt; den) &amp;amp;&amp;amp; (rem != 0); ++prefix) { numMult = numMult * 10; rem = numMult - (numMult / den) * den; }&lt;/p&gt;

&lt;p&gt;return sliceString(sb, prefix, period); } // long division - return true iff given number is repeating private static boolean isRepeating(StringBuilder sb, long num, long den) { long quot = num / den; long rem = num - quot * den; if (sb != null) { sb.append(quot); } if (rem == 0) { return false; } if (sb != null) { sb.append(‘.’); } for (long idx = 1; (idx &amp;lt; den) &amp;amp;&amp;amp; (rem != 0); ++idx) { rem = rem * 10; quot = rem / den; rem = rem - quot * den; if (sb != null) { sb.append(quot); } } return rem != 0; }&lt;/p&gt;

&lt;p&gt;private static String sliceString(StringBuilder sb, int prefixLength, int period) { int idx = sb.indexOf(“.”) + prefixLength + 1; return sb.substring(0, idx) + “(“ + sb.substring(idx, idx + period) + “)”; } [/code]&lt;/p&gt;

&lt;p&gt;All rational numbers with prime denominators and even length periods  have the ‘nines property’ i.e. the first and second half-periods of the repeating part add up to 9…9 (Proved in W. G. Leavitt, &lt;em&gt;A Theorem on Repeating Decimals&lt;/em&gt;, 1967 [&lt;a href=&quot;http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1047&amp;amp;context=mathfacpub&quot;&gt;paper&lt;/a&gt;]). Also, an interesting &lt;a href=&quot;http://mathoverflow.net/questions/41736/how-do-you-calculate-prove-the-length-of-n-the-number-of-non-repeating-digits-p&quot;&gt;lemma&lt;/a&gt; on the length of the prepend to the period (it is the number of times the denominator is divisible by either 2 or 5).&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Oct 2016 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2016/10/27/rational-numbers-in-decimal/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/27/rational-numbers-in-decimal/</guid>
        
        
      </item>
    
      <item>
        <title>Generalized heaps</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2016/10/screen-shot-2016-10-27-at-10-31-39-am.png&quot; alt=&quot;screen-shot-2016-10-27-at-10-31-39-am&quot; /&gt;Min-max heaps were introduced in [ASSS86] as an efficient way to support heap operations for both minimum and maximum values. Structurally, the min-max heap levels alternate between min-heap condition and max-heap, and hence evaluates grandchildren/grandparents during insertion or search. Min-max heaps can also be generalized to find the k-th smallest element in O(1) time.&lt;/p&gt;

&lt;p&gt;An interesting application is finding the running median of a stream of numbers. [ASSS86] describe a simple extension called &lt;em&gt;min-max-median heap&lt;/em&gt; that can find the running median in log-linear time complexity (indexed skip lists can too in amortized time complexity). The following code implements a method for finding the running median on each insertion. The trick is to maintain a min-max and a max-min heap such that either heap has at most one more element than the other.&lt;/p&gt;

&lt;p&gt;[code language=”java”] public double add(int a) { if (minHeap.size() == 0) { minHeap.add(a); return a; } // add new element to appropriate heap if (a &amp;lt; minHeap.findMax()) { minHeap.add(a); } else { maxHeap.add(a); } int minSize = minHeap.size(); int maxSize = maxHeap.size(); // resize heaps to enforce size constraint if (maxSize == minSize - 2) { maxHeap.add(minHeap.removeMax()); } else if (minSize == maxSize - 2) { minHeap.add(maxHeap.removeMin()); } minSize = minHeap.size(); maxSize = maxHeap.size(); // calculate median if (minSize &amp;gt; maxSize) { return minHeap.findMax(); } else if (maxSize &amp;gt; minSize) { return maxHeap.findMin(); } return (minHeap.findMax() + maxHeap.findMin()) / 2.0; } [/code]&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://www.akira.ruc.dk/~keld/teaching/algoritmedesign_f03/Artikler/02/Atkinson86.pdf&quot;&gt;ASSS86&lt;/a&gt;] M. D. Atkinson, J.-R. Sack, N. Santoro, and T. Strothotte. &lt;em&gt;Min-max Heaps and Generalized Priority Queues&lt;/em&gt;. Communications of the ACM, Vol. 29 No. 10, 1986.&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Oct 2016 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2016/10/27/generalized-heaps/</link>
        <guid isPermaLink="true">http://localhost:4000/2016/10/27/generalized-heaps/</guid>
        
        
      </item>
    
      <item>
        <title>Obituaries: Herbert Scarf (1930 - 2015)</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2015/12/scarf-230.jpg&quot; alt=&quot;Herbert Scarf&quot; /&gt;In addition to inventory policy, Scarf had at least four more major breakthroughs. Perhaps his most famous discovery is the Scarf algorithm.  Arrow and Debreu had proved that the equations describing economic equilibrium always have a solution when goods are divisible, but they were baffled by the problem of how to find one, except in special cases. The Scarf algorithm always finds an equilibrium, no matter how complicated the economy. This gave applied economists the ability to work with much more realistic models of the economy and thus to predict the consequences of major policy reforms including NAFTA and the U.S. tax system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://news.yale.edu/2015/12/01/memoriam-herbert-scarf-pioneering-economist-and-inspiring-teacher&quot;&gt;In memoriam: Herbert Scarf, pioneering economist and inspiring teacher&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The four breakthroughs:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Computation of equilibria (Scarf algorithm)&lt;/li&gt;
  &lt;li&gt;Production sets with indivisibilities&lt;/li&gt;
  &lt;li&gt;Core allocation existence and computation&lt;/li&gt;
  &lt;li&gt;Equivalence of core allocation and competitive equilibrium allocation (Debreu-Scarf Theorem, Edgeworth’s conjecture)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;http://dido.econ.yale.edu/~hes/talks/fixed-point.mov&quot;&gt;Here’s&lt;/a&gt; Scarf presenting “Fixed Point Theorems and Economic Equilibrium” at “The Economics of Kenneth J. Arrow,” The Institute for Advanced Studies, The Hebrew University, June 30, 2008:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.newschool.edu/nssr/het/profiles/scarf.htm&quot;&gt;The major works of Herbert Scarf&lt;/a&gt; &lt;a href=&quot;http://dido.econ.yale.edu/~hes/pubs.htm&quot;&gt;Publications&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Dec 2015 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2015/12/06/obituaries-herbert-scarf-1930-2015/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/12/06/obituaries-herbert-scarf-1930-2015/</guid>
        
        
      </item>
    
      <item>
        <title>A Terrible Summary - The Risks of Reporting on Research</title>
        <description>&lt;p&gt;Two reasons why I think that &lt;a href=&quot;http://www.news.virginia.edu/content/beautiful-algorithm-risks-automating-online-transactions&quot;&gt;A Beautiful Algorithm? The Risks of Automating Online Transactions&lt;/a&gt; is way off in its report on an otherwise interesting paper [&lt;a href=&quot;http://arxiv.org/pdf/1505.00720.pdf&quot;&gt;Econometrics for Learning Agents&lt;/a&gt;].&lt;a href=&quot;https://umayrh.files.wordpress.com/2015/07/econom-learning.png&quot;&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2015/07/econom-learning.png?w=300&quot; alt=&quot;Ratio distribution for one account&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The paper is concerned with generalized second-price auction, which is common in e-commerce, online advertising in particular. The aim is to estimate how inefficient such auctions are by accurately inferring play valuation (how much would an agent bid for an item, e.g.) with minimally restrictive assumptions on agent behavior. So, it doesn’t quite address “risks of automating online transactions.”&lt;/li&gt;
  &lt;li&gt;Without quoting verbatim, the report says that, according one of the paper’s authors, “the algorithms behind such ads could lead to an unforeseen financial crash.” At least the paper itself doesn’t use the terms ”crash” or “financial”. ”Risk-averse bidders” is the only time the paper mentions risk, and that too in ‘Further Related Work.”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An advertising platform like Bing might be losing money because bidders are not bidding truthfully, i.e. according to their valuation of an item. Since the valuation is private, it’s impossible to know for sure. On the other hand, since the valuation is constrained by a multi-agent environment with repeated games (i.e. auctions) - hence an opportunity to learn - it should be possible to infer valuation under some assumptions on agent/player behavior.&lt;/p&gt;

&lt;p&gt;A previous paper by the first author, &lt;a href=&quot;http://people.virginia.edu/~dn4w/&quot;&gt;Denis Nekipelov&lt;/a&gt;, discussed player valuation under the assumption of a static Nash equilibrium where all player respond independently and with their best strategies. That the auctions are already and/or constantly in equilibrium is a strong - if popular - assumption in dynamic environments like online advertising. The current paper instead assumes that player learn over time using “no-regret strategies” (i.e. responses that &lt;em&gt;over time&lt;/em&gt; are close to optimal), and then sets out to estimate the number of data samples required to approximate the &lt;em&gt;rationalizable set&lt;/em&gt; ”consisting of the set of values and error parameters (v, ε) such that with value v the sequence of bid by the player would have at most ε regret.”&lt;/p&gt;
</description>
        <pubDate>Thu, 23 Jul 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2015/07/23/a-terrible-summary-the-risks-of-reporting-on-research/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/07/23/a-terrible-summary-the-risks-of-reporting-on-research/</guid>
        
        
      </item>
    
      <item>
        <title>Continued Fractions</title>
        <description>&lt;p&gt;[caption id=”attachment_1948” align=”alignright” width=”172”]&lt;img src=&quot;https://umayrh.files.wordpress.com/2015/05/fareypoincaremovie.gif&quot; alt=&quot;fareypoincaremovie&quot; /&gt; &lt;a href=&quot;http://www-bcf.usc.edu/~fbonahon/STML49/FareyFord.html&quot;&gt;Farey tessellation&lt;/a&gt; in complex plane[/caption]&lt;/p&gt;

&lt;p&gt;In fact, the matrix formulation of Fibonacci numbers mentioned &lt;a href=&quot;https://umayrh.wordpress.com/2014/08/08/jiri-matousek-miniatures-fibonacci-numbers/&quot; title=&quot;Fibonacci Numbers&quot;&gt;before&lt;/a&gt; can be generalized to represent any 2-D matrix and, by way of continued fractions, any real number - not just the golden mean. This post is inspired from David Austin’s AMS &lt;a href=&quot;http://www.ams.org/samplings/feature-column/fcarc-stern-brocot&quot;&gt;feature column&lt;/a&gt; and draws on Phillipe Flajolet’s beautiful &lt;a href=&quot;http://www.lix.polytechnique.fr/Labo/Ilan.Vardi/continued_fractions.ps&quot;&gt;survey&lt;/a&gt; on continued fractions to set the stage for a future post on &lt;a href=&quot;http://en.wikipedia.org/wiki/Diophantine_approximation&quot;&gt;Diophantine approximation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;“&lt;em&gt;Every matrix A of determinant one with non-negative integer coefficients will have a unique factorization…corresponding to a continued fraction expansion.&lt;/em&gt;” [1]&lt;/p&gt;

&lt;p&gt;[latex]A = \left[ \begin{array}{cc} a &amp;amp; b \\ c &amp;amp; d \end{array} \right] = U^{\alpha_0}L^{\alpha_1}U^{\alpha_2}L^{\alpha_3}… \\ where \ U = \left[ \begin{array}{cc} 1 &amp;amp; 1 \\ 0 &amp;amp; 1 \end{array} \right], \\ \ L = \left[ \begin{array}{cc} 1 &amp;amp; 0 \\ 1 &amp;amp; 1 \end{array} \right], \ and \\ \frac{b}{d} = a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3 + \dotsb}}}[/latex]&lt;/p&gt;

&lt;p&gt; The Fibonacci numbers can be derived as&lt;/p&gt;

&lt;p&gt;[latex]\left[ \begin{array}{cc} F_{n-1} &amp;amp; F_{n} \\ F_{n-2} &amp;amp; F_{n-1} \end{array} \right] = ULULUL… \\ \phi(n) = \frac{F_{n}}{F_{n-1}} = 1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{1 + \dotsb}}}[/latex]&lt;/p&gt;

&lt;p&gt;Of course, both the factorization series and the fraction terminate for finite values of n i.e. rational approximations of the golden mean. Already this formulation can be used to calculate the n-th Fibonacci number in log(n) steps.&lt;/p&gt;

&lt;p&gt;While ”every positive rational number appears in the Stern-Brocot tree,” [2] such factorization also represents a specific path in the tree whose nodes provide the &lt;em&gt;optimal&lt;/em&gt; rational approximation to a real number within a given error.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[1] P. Flajolet, B. Vallee, and I. Vardi. Continued fractions from Euclid to present day. Preprint, March 2000. [2] D. Austin. Trees, Teeth, and Time: The mathematics of clock making. AMS Feature Column, December 2008.&lt;/p&gt;
</description>
        <pubDate>Tue, 26 May 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2015/05/26/continued-fractions/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/05/26/continued-fractions/</guid>
        
        
      </item>
    
      <item>
        <title>First-order methods for stochastic optimization</title>
        <description>&lt;p&gt;Optimization, particularly deterministic (convex) optimization, is essential to many learning algorithms (regression, support vector machines, matrix factorization etc). This post discusses first-order/gradient-based optimization approaches that may be more suitable for stochastic problems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Robbins-Munro algorithm: stochastic gradient root-finding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;- Assumptions, convergence rate - The original algorithm assumes that the dimension of input and output are the same. This does’t work for overdetermined systems such as those in least-squares linear regression. Maeda-Kanata extend RM to handle the case where output dimension is greater than input.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kiefer-Wolfowitz algorithm: finite differences instead of gradients&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;-&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Polyak-Juditsy averaging: a&lt;/strong&gt;&lt;strong&gt;ccelerating stochastic approximation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;-&lt;/p&gt;

&lt;p&gt;References&lt;/p&gt;

&lt;p&gt;[Borkar08] V. S. Borkar. Stochastic Approximation - A Dynamical Systems Viewpoint. Cambridge University Press, 2008. [&lt;a href=&quot;http://leon.bottou.org/publications/pdf/online-1998.pdf&quot;&gt;Bottou98&lt;/a&gt;] Online Learning and Stochastic Approximation. Online Learning and Neural Networks, ed. D. Saad, Cambridge University Press, 1998. [&lt;a href=&quot;http://castlelab.princeton.edu/ORF569.htm&quot;&gt;CastleLab&lt;/a&gt;] W. B. Powell. Computational Stochastic Optimization. Course Notes. [&lt;a href=&quot;http://lsc.amss.ac.cn/paper-pdf/hfchen-1.pdf&quot;&gt;Chen99&lt;/a&gt;] H. F. Chen, T. E. Duncan, and B. Pasik-Duncan. A Kiefer–Wolfowitz Algorithm with Randomized Differences. IEEE Transactions on Automatic Control, Vol. 44, No. 3, March 1999. [&lt;a href=&quot;http://www.jhuapl.edu/spsa/PDF-SPSA/Hill_TechDig05.pdf&quot;&gt;Hill05&lt;/a&gt;] S. D. Hill. Discrete Stochastic Approximation with Application to Resource Allocation. Johns Hopkins APL Technical Digest, Vol. 26, No. 1, 2005. [Kushner98] H. J. Kushner and G. G. Yin. Stochastic Approximation Algorithms and Applications. Springer-Verlag, 1998. [&lt;a href=&quot;http://projecteuclid.org/download/pdf_1/euclid.aoms/1177729392&quot;&gt;Kiefer52&lt;/a&gt;] J. Kiefer, and J. Wolfowitz. Stochastic Estimation of the Maximum of a Regression Function. The Annals of Mathematical Statistics, 1952. [&lt;a href=&quot;http://bigr.nl/files/publications/296_Kle07%20-%20Evaluation%20of%20optimization%20methods%20for%20nonrigid%20medical%20image%20registration%20using%20mutual%20information%20and%20b-splines.pdf&quot;&gt;Klein07&lt;/a&gt;] S. Klein, M. Staring, and J. P. W. Pluim. Evaluation of Optimization Methods for Nonrigid Medical Image Registration Using Mutual Information and B-Splines. IEEE Transactions on Image Processing, Vol. 16, No. 12, December 2007. [&lt;a href=&quot;http://www.dam.brown.edu/lcds/publications/documents/Kushner_1_000.pdf&quot;&gt;Kushner08&lt;/a&gt;] H. J. Kushner. Stochastic Approximation: A Survey, Nov. 2008. [&lt;a href=&quot;http://www.jhuapl.edu/spsa/PDF-SPSA/Maeda_Extended_Adaptive.pdf&quot;&gt;Maeda94&lt;/a&gt;] Y. Maeda, and Y. Kanata. Extended Adaptive Robbins-Munro Procedure Using Simultaneous Perturbation for a Least-Square Approximation Problem. Proceedings of the Asian Control Conference, July 1994. [&lt;a href=&quot;http://www.jhuapl.edu/spsa/PDF-SPSA/Maryak_Some_Guidelines.PDF&quot;&gt;Maryak97&lt;/a&gt;] J. L. Maryak. Some Guidelines for Using Iterate Averaging in Stochastic Approximation. Conference on Decision and Control, December 1997. [&lt;a href=&quot;http://projecteuclid.org/download/pdfview_1/euclid.aos/1188405629&quot;&gt;Mokkadem07&lt;/a&gt;] A. Mokkadem, and Mariane Pelletier. A Companion for the Kiefer-Wolfowitz-Blum Stochastic Approximation Algorithm. The Annals of Statistics, Vol. 35. No. 4, 2007. [&lt;a href=&quot;http://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586&quot;&gt;Munro51&lt;/a&gt;]  H. Robbins, and S. Monro. A Stochastic Approximation Method. The Annals of Mathematical Statistics, 1951. [&lt;a href=&quot;http://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf&quot;&gt;Nemirovski09&lt;/a&gt;]  A. Nemirovski, A. Juditsky, G. Lan, A. Shapiro. Robust Stochastic Approximation Approach to Stochastic Programming. SIAM Journal on Optimization, 2009. [&lt;a href=&quot;http://www.meyn.ece.ufl.edu/archive/spm_files/Courses/ECE555-2011/555media/poljud92.pdf&quot;&gt;Polyak92&lt;/a&gt;] B. T. Polyak, and A. B. Juditsky. Acceleration of Stochastic Approximation By Averaging. SIAM Journal of Control and Optimization, Vol. 30, No. 4, July 1992.[&lt;a href=&quot;http://vserver1.cscs.lsa.umich.edu/~crshalizi/notabene/stochastic-approximation.html&quot;&gt;Shalizi&lt;/a&gt;] C. R. Shalizi. Stochastic Approximation Algorithms. Notes, 2010. [&lt;a href=&quot;http://webee.technion.ac.il/people/shimkin/LCS11/ch5_SA.pdf&quot;&gt;Shimkin11&lt;/a&gt;] N. Shimkim. The Stochastic Approximation Algorithm. Lecture Notes, Learning in Complex Systems, 2011. [&lt;a href=&quot;http://jmlr.csail.mit.edu/proceedings/papers/v28/zhang13e.pdf&quot;&gt;Zhang13&lt;/a&gt;] L. Zhang, T. Yang, R. Jin, and X. He. O(logT) Projections for Stochastic Optimization of Smooth and Strongly Convex Functions. Journal of Machine Learning Research, Vol. 28, 2013. []&lt;/p&gt;
</description>
        <pubDate>Fri, 28 Nov 2014 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2014/11/28/first-order-methods-for-stochastic-optimization/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/11/28/first-order-methods-for-stochastic-optimization/</guid>
        
        
      </item>
    
      <item>
        <title>Obituaries: Alexander Grothendieck (1928–2014)</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://mortdhomme.hautetfort.com/media/02/00/1044718658.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;More will be told of this story as his voluminous writings from the hinterland are being read. But between 1945 and 1970 he published mathematics of unparalleled sweep and power, conveying escalations of abstraction to the solution of concrete problems, and this is the part we wish to appreciate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[Alexander Grothendieck 1928–2014&lt;/td&gt;
      &lt;td&gt;Gödel’s Lost Letter and P=NP](http://rjlipton.wordpress.com/2014/11/16/alexander-grothendieck-1928-2014/).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        <pubDate>Mon, 17 Nov 2014 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2014/11/17/obituaries-alexander-grothendieck-1928-2014/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/11/17/obituaries-alexander-grothendieck-1928-2014/</guid>
        
        
      </item>
    
      <item>
        <title>Nonnegative Matrix Factorization, 1</title>
        <description>&lt;p&gt;The aim of this post is to highlight the utility of non-negative factorization (NMF) in data analysis through examples. In a different post, we’ll talk theory and implementation by thinking of NMF as constrained optimization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning parts of a whole&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When Lee and Seung [Lee99] re-introduced non-negative matrix factorization (NMF), they emphasized on the algorithm’s ability to learn parts of a whole. That is, a good and interpretable low-rank approximation of a function or data e.g. features of a face or the semantic components of text. Moreover, in interpreting the algorithm as a neural network, they argue that the part-based learning is a consequence of the non-negativity constraint (neuron firing rates and synaptic strengths are non-negative). This is contrasted with well-known techniques such as Principle Component Analysis (&lt;a href=&quot;http://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;PCA&lt;/a&gt;) and Vector Quantization (&lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_quantization&quot;&gt;VQ&lt;/a&gt;), which learn by creating archetypes of objects. In all three cases, the algorithms model data as a linear and additive combination of “basis” functions or vectors - the difference lying in the  constraints imposed on the model.&lt;/p&gt;

&lt;p&gt;Thus, given an &lt;em&gt;n x m&lt;/em&gt; data matrix V, we seek matrix factors W and H, which are &lt;em&gt;n x k&lt;/em&gt; and k_ x m_, respectively such that some loss function (one below is for Frobenius norm)  is minimized for a given value of k:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\mathbf{V} \approx \mathbf{W} \mathbf{H} \\ min_{W,H} \frac{1}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\mathbf{V} - \mathbf{W}\mathbf{H}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_{F}\\ s.t.\ \mathbf{W},\ \mathbf{H} \ge 0[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In some ways, the issues raised by [Lee99] were not new. In chemometrics and environmetrics, NMF was already being used for analyzing molecular spectra [Juvela94] and &lt;a href=&quot;http://www.epa.gov/scram001/receptorindex.htm&quot;&gt;receptor modeling&lt;/a&gt; [Hopke00]. This was motivated by the (1) lack of interpretation for factors produced by PCA (which, when addressed by matrix rotations can cause the problem to have non-unique solutions), and  (2) the sensitivity of PCA to data scaling. The latter issue is connected with the need to account for uncertainty in data, which is harder to achieve with PCA yet important for modeling in those areas:&lt;/p&gt;

&lt;p&gt;[latex]min_{W,H} \sum_i \sum_j \frac{v_{ij} - w_{ij} h_{ij}}{s_{ij}}[/latex]&lt;/p&gt;

&lt;p&gt;Here’s R code for latent semantic indexing using the excellent &lt;a href=&quot;http://cran.r-project.org/web/packages/NMF/index.html&quot;&gt;NMF&lt;/a&gt; package. The dataset used is AssociatedPress (from topicmodel package), which is available as a DocumentTermMatrix (see the &lt;a href=&quot;http://www.cran.r-project.org/web/packages/tm/index.html&quot;&gt;TM&lt;/a&gt; package) encoding the &lt;a href=&quot;http://en.wikipedia.org/wiki/Tf–idf&quot;&gt;TF-IDF&lt;/a&gt; of terms in various documents. NMF is calculated for a vector of four factors and then the terms closet to each factor are drawn as a word cloud (see the &lt;a href=&quot;http://cran.r-project.org/web/packages/wordcloud/index.html&quot;&gt;wordcloud&lt;/a&gt; package).&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false” collapse=”true”] library(topicmodels) library(tm) library(NMF) library(wordcloud)&lt;/p&gt;

&lt;p&gt;data(AssociatedPress) dtm &amp;lt;- AssociatedPress[1:20,] dtm &amp;lt;- removeSparseTerms(dtm, 0.9) dm &amp;lt;- as.matrix(dtm) dim(dm)&lt;/p&gt;

&lt;p&gt;k &amp;lt;- 4 nmf.res &amp;lt;- nmf(dm, k, “snmf/r”) basismap(nmf.res) coefmap(nmf.res)&lt;/p&gt;

&lt;p&gt;# top basis and coefficients res.coef &amp;lt;- coef(nmf.res) res.bas &amp;lt;- basis(nmf.res)&lt;/p&gt;

&lt;p&gt;set.seed(1234) for (n in seq(1, k, 1)) { freq &amp;lt;- res.coef[n,(order(res.coef[n,], decreasing = TRUE) [1:40])] wordcloud(names(freq), round(freq), scale = c(0.1, 3), colors = brewer.pal(6, “Dark2”)) print(freq) print(“==========================”) } [/code]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/09/nmf6_lsi_ap_k4_wc.png&quot;&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/09/nmf6_lsi_ap_k4_wc.png?w=660&quot; alt=&quot;nmf6_lsi_ap_k4_wc&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Summary&lt;/em&gt;: NMF is useful because some applications (e.g. in physical sciences and signal processing) naturally restrict the data and hence latent factor to be non-negative, and NMF can satisfy this constraint.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collaborative filtering&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While NMF steadily found new applications in diverse fields such as signal processing and data mining [Cichoki09], perhaps matrix factorization’s role in solving the &lt;a href=&quot;http://en.wikipedia.org/wiki/Netflix_Prize&quot;&gt;Netflix prize&lt;/a&gt; problem [Koren09, or this &lt;a href=&quot;http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/&quot;&gt;summary&lt;/a&gt;] made it more prominent within machine learning communities. [Koren09] starts out with distinguishing two types of learning models for &lt;a href=&quot;http://en.wikipedia.org/wiki/Collaborative_filtering&quot;&gt;collaborative filtering&lt;/a&gt;: neighborhood and latent factor. Neighborhood models find similarity between users or between items, whereas latent factor models find variables that can explain both user preferences and item characteristics. Within latent factor models, the authors focus on &lt;a href=&quot;http://en.wikipedia.org/wiki/Singular_value_decomposition&quot;&gt;SVD&lt;/a&gt; (instead of NMF, perhaps because, unlike physical science, negative ratings are not much of a concern here). Classical SVD’s disadvantage seems to lies in not being able to handle missing entries in the data (user-item matrix). Drawing on previous work, they argue for the need to (1) fit model based on known data value alone, and (2) avoid overfitting using regularization.&lt;/p&gt;

&lt;p&gt;The basic model, then, according to [Koren09] is the following optimization problem:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\min_{W,H} \sum_{(i,j) \in K} (v_{ij} - w_{i}^{T} h_{j})^2 + \lambda (&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;w_i&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 +&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;h_j&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2) = [/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;where vij is the rating for item j by user i, wi is the user’s factor vector, hj the item’s factor vector, and λ is the regularization parameter.&lt;/p&gt;

&lt;p&gt;The paper also highlights two interesting extensions to the basic model:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Biases: [latex]\hat{v}_{ij} = \mu + b_i + b_j + w_{i}^{T}h_{j}[/latex]&lt;/li&gt;
  &lt;li&gt;Temporal dynamics: [latex]\hat{v}_{ij}(t) = \mu + b_{i}(t) + b_{j}(t) + w_{i}^{T}h_{j}[/latex]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Netflix prize is also a &lt;a href=&quot;http://en.wikipedia.org/wiki/Matrix_completion&quot;&gt;Matrix Completion&lt;/a&gt; problem that we can solve using NMF (though factorizing first might be more inefficient). Here’s R code for collaborative filtering based on the &lt;a href=&quot;http://grouplens.org/datasets/movielens/&quot;&gt;MovieLens&lt;/a&gt; 100K dataset (“100,000 ratings from 1000 users on 1700 movies”). Much of the code is involved with reading and parsing the MovieLens data and metadata, and draws on &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt; and &lt;a href=&quot;http://directlabels.r-forge.r-project.org&quot;&gt;directlabels&lt;/a&gt; for visualization.&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false” collapse=”true”] # read the Movie Lens data from file u1.base &amp;lt;- read.table(file=”~/Desktop/mlearn/Rcode/ml-100k/u1.base”,sep=’\t’,header=F, col.names=c(“userId”, “itemId”, “rating”, “timestamp”), colClasses = c(“integer”, “integer”, “integer”, “integer”))&lt;/p&gt;

&lt;p&gt;# get all unique users and items unq.users &amp;lt;- sort(unique(u1.base$userId)) unq.items &amp;lt;- sort(unique(u1.base$itemId)) library(bit64) unq.users.i64 &amp;lt;- as.integer64(unq.users) unq.items.i64 &amp;lt;- as.integer64(unq.items)&lt;/p&gt;

&lt;p&gt;# hashmaps store the index of each user and item users.hm &amp;lt;-hashmap.integer64(unq.users.i64, nunique = length(unq.users.i64)) items.hm &amp;lt;-hashmap.integer64(unq.items.i64, nunique = length(unq.items.i64))&lt;/p&gt;

&lt;p&gt;# populate the ratings matrix u1.base.mat &amp;lt;- matrix(data = 0, nrow = length(unq.users.i64), ncol = length(unq.items.i64)) for (i in 1:nrow(u1.base)) { u1.base.mat[hashpos(users.hm, u1.base[i,1]), hashpos(items.hm, u1.base[i,2])] &amp;lt;- u1.base[i,3] } rownames(u1.base.mat) &amp;lt;- unq.users colnames(u1.base.mat) &amp;lt;- unq.items&lt;/p&gt;

&lt;p&gt;# factorize, with as many factors as movie genres given in the ML data library(NMF) k &amp;lt;- 19 set.seed(8888) nmf.res &amp;lt;- nmf(u1.base.mat, nrun = 5, rank = k, method = “snmf/r”) basismap(nmf.res) coefmap(nmf.res)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;# top basis and coefficients, and metadata res.coef &amp;lt;- coef(nmf.res) res.bas &amp;lt;- basis(nmf.res) item.col.names = c(“movieId”, “movieTitle”, “releaseDate”, “vidReleaseDate”, “imdbUrl”, “unknown”, “Action”, “Adventure”, “Animation”, “Children”, “Comedy”, “Crime”, “Documentary”, “Drama”, “Fantasy”, “FilmNoir”, “Horror”, “Musical”, “Mystery”, “Romance”, “SciFi”, “Thriller”, “War”, “Western”) item.col.classes = c(“integer”, “character”, “character”, “character”, “character”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”, “integer”) # read.table does not work without “latin1” encoding and disabling quotes u.item.txt &amp;lt;- readLines(“~/Desktop/mlearn/Rcode/ml-100k/u.item”, encoding = “latin1”) u.items &amp;lt;- read.table(text=u.item.txt,sep=’&lt;/td&gt;
      &lt;td&gt;‘,header=F, col.names=item.col.names, colClasses = item.col.classes, encoding = “latin1”, quote = “”) u.items[1,] u.items[order(res.coef[1,], decreasing = TRUE) [1:20], 2]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;# scatterplot: one factor against another (as in Koren09) factor1.idx &amp;lt;- order(res.coef[1,], decreasing = TRUE) [1:20] factor2.idx &amp;lt;- order(res.coef[2,], decreasing = TRUE) [1:20] plot.idx &amp;lt;- union(factor1.idx, factor2.idx) qplot.dat &amp;lt;- data.frame(factor1 = res.coef[1, plot.idx], factor2 = res.coef[2, plot.idx], labels = u.items[plot.idx,2]) library(ggplot2) library(directlabels) plot.obj &amp;lt;-qplot(factor1, factor2, data=qplot.dat, colour = labels, main=”Factor1 vs Factor2”) direct.label(plot.obj)&lt;/p&gt;

&lt;p&gt;# plot hierarchical clusters for two factors u.item.factor &amp;lt;- t(res.coef) rownames(u.item.factor) &amp;lt;- as.list(u.items[1:nrow(u.item.factor),2]) u.item.factor.sampled &amp;lt;- u.item.factor[plot.idx,1:2] u.item.factor.dist = dist(u.item.factor.sampled, method = “manhattan”) u.item.factor.clust = hclust(u.item.factor.dist, method = “ward”) plot(u.item.factor.clust) [/code]&lt;/p&gt;

&lt;p&gt;The scatterplot and dendogram outputs of the code:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/10/nmf7_cf_ml_k19_hclust.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/10/nmf7_cf_ml_k19_qplot.png?w=300&quot; alt=&quot;nmf7_cf_ml_k19_qplot&quot; /&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/10/nmf7_cf_ml_k19_hclust.png?w=300&quot; alt=&quot;nmf7_cf_ml_k19_hclust&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Caveat&lt;/em&gt;: while NMF itself can be used for matrix completion, the NMF package in R cannot since it cannot account for missing values. An alternative is to use &lt;a href=&quot;http://cran.r-project.org/web/packages/softImpute/&quot;&gt;softImpute&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Summary&lt;/em&gt;: another reason for the success of NMF is the ability to extend the basic model for use in specific applications (like collaborative filtering).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cluster analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Non-negative matrix factorization is essentially a form of cluster analysis - the critical difference being that the clusters are derived from linear, additive latent factors instead of item-to-item similarity/distance metrics/divergences. So, it’s not surprising that researchers were interested in the connections between traditional unsupervised learning methods like K-means and NMF. Two interesting papers in this line are [Kim07] and [Kim08]. Apart from analyzing the relationship between K-mean and NMF, they highlight (though, not introduce):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the importance of sparsity,&lt;/li&gt;
  &lt;li&gt;utility of &lt;em&gt;purity&lt;/em&gt; and &lt;em&gt;entropy&lt;/em&gt; metrics to evaluate clustering quality, and&lt;/li&gt;
  &lt;li&gt;the utility of of &lt;em&gt;consensus maps&lt;/em&gt; [Burnet04] for model selection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NMF, contrary to Lee and Seung’s intuition and experiments, doesn’t always produce a part-based representation. In this, [Kim07] and [Kim08] followed the arguments and counter-examples of [Li01] and [Hoyer04]. Since, as [Hoyer04] states, ”the sparseness given by NMF is somewhat of a side-effect rather than a goal,” regularization needs to be explicitly introduced to control the degree of sparseness. [Li07] does that by penalizing the energy of the factors in the optimization objective (similar to the [Koren09] basic model); [Hoyer04] introduces sparseness constraints separately on each factor; while [Kim07, Kim08] mix L1 and L2 norms to impose sparsity on one of the factors. Sparseness may not only improve the quality of the result but, as [Kim08] show, also result in better execution time. The two algorithms, SNMF/R and SNMF/L, introduced in [Kim07] are available in the R &lt;a href=&quot;http://cran.r-project.org/web/packages/NMF/index.html&quot;&gt;NMF&lt;/a&gt; package.&lt;/p&gt;

&lt;p&gt;Purity and entropy are two traditional &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html&quot;&gt;clustering metrics&lt;/a&gt;. Purity measures the accuracy of assignment (n data point, k clusters and l classes) - larger value implies better clustering. Entropy measures the amount of information-theoretic order - smaller value is better.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]purity = \frac{1}{n}\sum_{k}\max_{l}&lt;/td&gt;
      &lt;td&gt;c_k \cap C_l&lt;/td&gt;
      &lt;td&gt;[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]entropy = \frac{-1}{n\log_{2}l} \sum_{k} \sum_{l}&lt;/td&gt;
      &lt;td&gt;c_k \cap C_l&lt;/td&gt;
      &lt;td&gt;\log_{2}\frac{&lt;/td&gt;
      &lt;td&gt;c_k \cap C_l&lt;/td&gt;
      &lt;td&gt;}{c_k}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For model selection (i.e. the number of factors to use), [Burnet04] introduced &lt;em&gt;consensus matrix&lt;/em&gt; and the related &lt;em&gt;dispersion coefficient&lt;/em&gt;. Since NMF may not converge to the same solution on each run, consensus matrix (C) encodes the probability of assignment agreement over multiple runs. The dispersion coefficient is calculated as the “Pearson correlation of two distance matrices: the first, I-C , is the distance between samples induced by the consensus matrix, and the second is the distance between samples induced by the linkage used in the reordering of C.” [Kim07] described a more comprehensible version of dispersion coefficient that only uses the consensus matrix. It’s value also lies between 0 and 1, and the higher the better (1 indicates complete consensus). The NMF package implements this version.&lt;/p&gt;

&lt;p&gt;[latex]dispersion = \frac{1}{n^2}\sum_{i}\sum_{j}4(C_{ij} - \frac{1}{2})^2[/latex]&lt;/p&gt;

&lt;p&gt;Here’s R code to analyze the &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Iris&quot;&gt;iris dataset&lt;/a&gt; using the &lt;a href=&quot;http://cran.r-project.org/web/packages/NMF/index.html&quot;&gt;NMF&lt;/a&gt; package:&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false” collapse=”true”] data(iris) library(NMF) ir &amp;lt;- t(as.matrix(iris[, 1:4]));&lt;/p&gt;

&lt;p&gt;ir.res.k2 &amp;lt;- nmf(ir, 2, nrun =10, seed=12345, method = “lee”) ir.res.k3 &amp;lt;- nmf(ir, 3, nrun =10, seed=12345, method = “lee”) ir.res.k4 &amp;lt;- nmf(ir, 4, nrun =10, seed=12345, method = “lee”)&lt;/p&gt;

&lt;p&gt;p.k2 &amp;lt;- purity(ir.res.k2, iris[,5]) p.k3 &amp;lt;- purity(ir.res.k3, iris[,5]) p.k4 &amp;lt;- purity(ir.res.k4, iris[,5]) plot(2:4, c(p.k2, p.k3, p.k4), xlab = “factors”, ylab = “purity”)&lt;/p&gt;

&lt;p&gt;e.k2 &amp;lt;- entropy(ir.res.k2, iris[,5]) e.k3 &amp;lt;- entropy(ir.res.k3, iris[,5]) e.k4 &amp;lt;- entropy(ir.res.k4, iris[,5]) plot(2:4, c(e.k2, e.k3, e.k4), xlab = “factors”, ylab = “entropy”)&lt;/p&gt;

&lt;p&gt;par(mfrow=c(2,2)) consensusmap(ir.res.k2) consensusmap(ir.res.k3) consensusmap(ir.res.k4)&lt;/p&gt;

&lt;p&gt;d.k2 &amp;lt;- dispersion(ir.res.k2) d.k3 &amp;lt;- dispersion(ir.res.k3) d.k4 &amp;lt;- dispersion(ir.res.k4) plot(2:4, c(d.k2, d.k3, d.k4), xlab = “factors”, ylab = “dispersion”)&lt;/p&gt;

&lt;p&gt;ir.res.k2.s &amp;lt;- nmf(ir, 2, nrun =10, seed=12345, method = “snmf/r”) ir.res.k3.s &amp;lt;- nmf(ir, 3, nrun =10, seed=12345, method = “snmf/r”) ir.res.k4.s &amp;lt;- nmf(ir, 4, nrun =10, seed=12345, method = “snmf/r”)&lt;/p&gt;

&lt;p&gt;d.k2.s &amp;lt;- dispersion(ir.res.k2.s) d.k3.s &amp;lt;- dispersion(ir.res.k3.s) d.k4.s &amp;lt;- dispersion(ir.res.k4.s) plot(2:4, c(d.k2.s, d.k3.s, d.k4.s), xlab = “factors”, ylab = “dispersion (snmf/r)”) [/code]&lt;/p&gt;

&lt;p&gt;This code uses the package’s heatmap tools: &lt;em&gt;basismap&lt;/em&gt;, &lt;em&gt;coefmap&lt;/em&gt; and &lt;em&gt;consensusmap&lt;/em&gt;. If samples are taken to be the rows of an_ n x m_ data matrix V and features are taken to be its columns, then basismap draws the &lt;em&gt;n x k&lt;/em&gt; matrix factor W, which represents the contribution of each factor in each sample. Similarly, coefmap helps visualize the &lt;em&gt;k x m&lt;/em&gt; matrix factor H, which represents the contribution of each feature in each factor. Here are the rank-2 and rank-3 maps:&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_1079” align=”aligncenter” width=”300”]&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/09/k_3.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/09/k_3.png?w=300&quot; alt=&quot;k_3&quot; /&gt;&lt;/a&gt; Basis and coefficient maps for k = 3[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_1082” align=”aligncenter” width=”300”]&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/09/k_2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/09/k_2.png?w=300&quot; alt=&quot;Basis and coefficient maps for k = 2&quot; /&gt;&lt;/a&gt; Basis and coefficient maps for k = 2[/caption]&lt;/p&gt;

&lt;p&gt;Not surprisingly, purity is maximized at k = 3 while entropy is minimized. Surprisingly, though, dispersion decreases as factors increase (also obvious from the consensusmap plots). Though [Kim07, Kim08] don’t seem to discuss this, it may be that dispersion on its own is not reliable for model selection.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/10/nmf3_iris_k2_4_entropy.png&quot;&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/10/nmf3_iris_k2_4_entropy.png?w=300&quot; alt=&quot;nmf3_iris_k2_4_entropy&quot; /&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/10/nmf3_iris_k2_4_purity.png?w=300&quot; alt=&quot;nmf3_iris_k2_4_purity&quot; /&gt;&lt;/a&gt;  &lt;a href=&quot;https://umayrh.files.wordpress.com/2014/10/nmf3_iris_k2_4_sm.png&quot;&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/10/nmf3_iris_k2_4_sm.png?w=300&quot; alt=&quot;nmf3_iris_k2_4_sm&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Summary&lt;/em&gt;: NMF lends well to cluster analysis though model selection seems tricky.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1111.0952v1.pdf&quot;&gt;Arora12a&lt;/a&gt;] S. Arora, R. Ge, R. Kannan, and A. Moitra. Computing a Nonnegative Matrix Factorization – Provably. STOC, 2012 [&lt;a href=&quot;http://arxiv.org/abs/1204.1956&quot;&gt;Arora12b&lt;/a&gt;] S. Arora, R. Ge, A. Moitra. Learning Topic Models - Going Beyond SVD. FOCS, 2012 [&lt;a href=&quot;http://www.pnas.org/content/101/12/4164.full.pdf+html&quot;&gt;Brunet04&lt;/a&gt;] J. Brunet, P. Tamayo, T. Golub, and J. Mesirov. Metagenes and molecular pattern discovery using matrix factorization. PNAS, 2004. [&lt;a href=&quot;http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470746661.html&quot;&gt;Cichoki09&lt;/a&gt;] A. Cichoki, R. Zdunek, A. H. Phan, S. Ammari. Nonnegative Matrix and Tensor Factorizations: Applications to exploratory multi-way data analysis and blind source separation, 2009. [&lt;a href=&quot;https://web.stanford.edu/~vcs/papers/NMFCDP.pdf&quot;&gt;Donoho03&lt;/a&gt;] D. Donoho and V. Stodden. When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts? NIPS, 2003. [&lt;a href=&quot;http://www.epa.gov/ttnamti1/files/ambient/pm25/workshop/laymen.pdf&quot;&gt;Hopke00&lt;/a&gt;] P. K. Hopke. A guide to positive matrix factorization.Workshop on UNMIX and PMF as Applied to PM2, 2000. [&lt;a href=&quot;http://jmlr.org/papers/volume5/hoyer04a/hoyer04a.pdf&quot;&gt;Hoyer04&lt;/a&gt;] P. O. Hoyer. Non-negative matrix factorization with sparseness constraints. JMLR, 2004. [&lt;a href=&quot;http://www.mrao.cam.ac.uk/yerac/juvela/juvela.html&quot;&gt;Juvela94&lt;/a&gt;] M. Juvela, K. Lehtinen, and P. Paatero. The use of positive matrix factorization in the analysis of molecular line spectra from the thumbprint nebula. D. P. Clemens and R. Barvainis, eds., &lt;em&gt;Clouds, Cores, and Low Mass Stars&lt;/em&gt;, volume 65 of &lt;em&gt;ASP Conference Series&lt;/em&gt;, 1994. [&lt;a href=&quot;http://adsabs.harvard.edu/abs/1996MNRAS.280..616J&quot;&gt;Juvela96&lt;/a&gt;] M. Juvela, K. Lehtinen, and P. Paatero. The use of positive matrix factorization in the analysis of molecular line spectra. &lt;em&gt;MNRAS&lt;/em&gt;, 1996. [&lt;a href=&quot;http://bioinformatics.oxfordjournals.org/content/23/12/1495.full.pdf&quot;&gt;Kim07&lt;/a&gt;] H. Kim and H. Park. Sparse non-negative matrix factorizations via alternating non-negativity-constrained least squares for microarray data analysis. Bioinformatics, 2007. [&lt;a href=&quot;http://www.cc.gatech.edu/~hpark/papers/GT-CSE-08-01.pdf&quot;&gt;Kim08&lt;/a&gt;] J. Kim and H. Park. Sparse Nonnegative Matrix Factorization for Clustering. Georgia Tech Technical Report, GT-CSE-08-01, 2008. [&lt;a href=&quot;https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf&quot;&gt;Koren09&lt;/a&gt;] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization for recommender systems. IEEE Computer Society, 2009. [&lt;a href=&quot;research.yahoo.com/files/korenBellChapterSpringer.pdf&quot;&gt;Koren11&lt;/a&gt;] Y. Koren, and R. Bell. Advances in collaborative filtering. Recommender Systems Handbook, 2011. [&lt;a href=&quot;http://hebb.mit.edu/people/seung/papers/ls-lponm-99.pdf&quot;&gt;Lee99&lt;/a&gt;] D. D. Lee, and H. S. Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 1999. [&lt;a href=&quot;http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf&quot;&gt;Lee01&lt;/a&gt;] D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. NIPS, 2001. [&lt;a href=&quot;http://www.ai.mit.edu/courses/6.899/papers/3B_04.PDF&quot;&gt;Li01&lt;/a&gt;] S. Z. Li, X. Hou, H. Zhang, and Q. Cheng. Learning spatially localized parts-based representations. Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2001. [&lt;a href=&quot;http://www.cs.berkeley.edu/~jordan/papers/li-ding-jordan-icdm07.pdf&quot;&gt;Li07&lt;/a&gt;] T. Li, C. Ding, M. I. Jordan. Solving Consensus and Semi-supervised Clustering Problems Using Nonnegative Matrix Factorization. ICDM, 2007.&lt;/p&gt;
</description>
        <pubDate>Tue, 07 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/10/07/nonnegative-matrix-factorization-1/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/10/07/nonnegative-matrix-factorization-1/</guid>
        
        
      </item>
    
      <item>
        <title>Obituaries: Harold Kuhn (1925–2014)</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Kuhn enrolled at Princeton in the fall of 1947. He wrote his doctoral dissertation in group theory under the direction of Ralph Fox. Concurrently, he joined mathematics professor A.W. Tucker and fellow graduate student David Gale in a hastily organized summer project to study the suspected equivalence between linear programming and matrix game theory. That project, he later wrote, “set the course of my subsequent academic career, which has centered around the applications of mathematics to economics.” In 1980, the three shared the John von Neumann Theory Prize of the Operations Research Society of America (now part of INFORMS) for their pioneering work in game theory and optimization.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://sinews.siam.org/DetailsPage/tabid/607/ArticleID/212/Obituaries-Harold-Kuhn-1925-ndash-2014.aspx&quot;&gt;Obituaries: Harold Kuhn (1925–2014)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[embed width=300 height=150]https://www.youtube.com/watch?v=SZ0tzt54Mlc[/embed]&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/10/06/obituaries-harold-kuhn-1925-2014/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/10/06/obituaries-harold-kuhn-1925-2014/</guid>
        
        
      </item>
    
      <item>
        <title>3-Manifolds</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://abel.math.harvard.edu/~ctm/index.html&quot;&gt;Curtis McMullen&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[embed]https://www.youtube.com/watch?v=ZY50V_d4wok[/embed]&lt;/p&gt;

&lt;p&gt;[embed]https://www.youtube.com/watch?v=ZU_ATH9Vc6I[/embed]&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/08/21/3-manifolds/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/08/21/3-manifolds/</guid>
        
        
      </item>
    
      <item>
        <title>Fibonacci Numbers</title>
        <description>&lt;p&gt;Two notes from &lt;a href=&quot;http://kam.mff.cuni.cz/~matousek/&quot;&gt;Jiřì Matoušek&lt;/a&gt;’s book &lt;em&gt;Thirty-three Miniatures: Mathematical and Algorithmic Applications of Linear Algebra&lt;/em&gt; [&lt;a href=&quot;http://www.ams.org/bookstore?fn=20&amp;amp;arg1=stmlseries&amp;amp;ikey=STML-53&quot;&gt;1&lt;/a&gt;,&lt;a href=&quot;http://kam.mff.cuni.cz/~matousek/la-ams.html&quot;&gt;2&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fibonacci numbers in O(lg_n_) steps&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1.1 Matrix formulation for recursive calculation&lt;/p&gt;

&lt;p&gt;[latex]\left(\begin{array}{c}F_{n+2}\\ F_{n+1}\end{array}\right) = M\left(\begin{array}{c}F_{n+1}\\ F_{n}\end{array}\right)\\for\ M\ =\left(\begin{array}{cc}1 &amp;amp; 1 \\ 1 &amp;amp; 0\end{array}\right)\\ \therefore \left(\begin{array}{c}F_{n+1}\\ F_{n}\end{array}\right) = M^{n}\left(\begin{array}{c}1\\ 0\end{array}\right)[/latex]&lt;/p&gt;

&lt;p&gt;1.2 At most log2n multiplications needed size z &amp;lt;= log2n&lt;/p&gt;

&lt;p&gt;[latex]n = 2^a + 2^b +\ …+ 2^z\ for\ a &amp;lt; b &amp;lt;\ …,\ M^n=M^{2^a}M^{2^b}…M^{2^z}[/latex]&lt;/p&gt;

&lt;p&gt;This can be extended to any recursive formula.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fibonacci formula&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2.1 Given the formula&lt;/p&gt;

&lt;p&gt;[latex]F_{n+2} = F_{n+1} + F_{n}[/latex]&lt;/p&gt;

&lt;p&gt;2.2 If we start with the ansatz for either of the two sequences, un and vn, that compose Fn&lt;/p&gt;

&lt;p&gt;[latex]u_n = \tau^{n} \\ \therefore \tau^{n+2} = \tau^{n+1} + \tau^{n} \\ \Rightarrow \tau^{2} = \tau + 1[/latex]&lt;/p&gt;

&lt;p&gt;2.3 This yields two distinct roots&lt;/p&gt;

&lt;p&gt;[latex]\tau = (1 \pm \sqrt{5}) / 2[/latex]&lt;/p&gt;

&lt;p&gt;2.4 The two roots individually form two sequences, &lt;strong&gt;u&lt;/strong&gt; and &lt;strong&gt;v&lt;/strong&gt;, that are linearly independent. Thus Fibonacci numbers can be written in terms of these basis vectors.&lt;/p&gt;

&lt;p&gt;[latex]\mathbf{F}=\alpha \mathbf{u}+\beta \mathbf{v}[/latex]&lt;/p&gt;

&lt;p&gt;2.5 The values of α and β can be evaluation by solving the linear systems, and eventually&lt;/p&gt;

&lt;p&gt;[latex]F_n = \frac{1}{\sqrt{5}}\left\{(\frac{1+\sqrt{5}}{2})^{n}-(\frac{1-\sqrt{5}}{2})^n\right\}[/latex]&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/08/08/jiri-matousek-miniatures-fibonacci-numbers/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/08/08/jiri-matousek-miniatures-fibonacci-numbers/</guid>
        
        
      </item>
    
      <item>
        <title>Physical Review Letters, Past</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;As part of the celebration of PRL’s 50th anniversary, we will be presenting throughout 2008 a series of milestone Letters that made long-lived contributions to physics, either by announcing significant discoveries, or by initiating new areas of research. A number of these articles report on work that was later recognized with a Nobel Prize for one or more of the authors. Starting the week of January 2, we will present a few important Letters from PRL in 1958, and the next week from 1959, etc., continuing up through the year 2000.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;http://journals.aps.org/prl/50years/milestones&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/08/01/physical-review-of-letters-past/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/08/01/physical-review-of-letters-past/</guid>
        
        
      </item>
    
      <item>
        <title>Accelerated first-order methods for regularization</title>
        <description>&lt;p&gt;&lt;strong&gt;FISTA&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) [Beck09] was one of the first algorithms to use Nesterov’s accelerated gradient descent to speed up the convergence of iterative shrinkage-thresholding (ISTA) from O(β/ε) to O(√(β/ε)).  The algorithm and proof sketch for in the previous post based were based on [Bubeck14] and [Beck09] so we’ll skip them. Instead give an R implementation and results that compares ISTA and FISTA performance (in terms of number of iterations) for various step sizes (iterations increase and step size decreases).&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false” collapse=”true”]&lt;/p&gt;

&lt;p&gt;## ISTA ista &amp;lt;- function(A, x, beta, iter = 100) { ## parameters eta &amp;lt;- 1 / beta lambda &amp;lt;- 1 xx &amp;lt;- c(0, 0, 0, 0, 0, 0) ## helpers Axx &amp;lt;- A %*% x Axn &amp;lt;- norm(A %*% x) error &amp;lt;- vector(length = iter) iters &amp;lt;- vector(length = iter)&lt;/p&gt;

&lt;p&gt;## main loop for (i in 1:iter) { gradient_x &amp;lt;- t(A) %*% ( A %*% xx - y ) xx_tmp &amp;lt;- xx - eta * gradient_x v &amp;lt;- eta * lambda # L1 prox/shrinkage-thresholding xx &amp;lt;- pmax(xx_tmp - v, 0) - pmax(- xx_tmp - v, 0) error[i] &amp;lt;- norm(A %*% xx - Axx) / Axn iters[i] &amp;lt;- i }&lt;/p&gt;

&lt;p&gt;return(list(xx, error, iters)) }&lt;/p&gt;

&lt;p&gt;## FISTA fista &amp;lt;- function(A, x, beta, iter = 100) { ## parameters eta &amp;lt;- 1 / beta lambda &amp;lt;- 1 x_next &amp;lt;- c(0, 0, 0, 0, 0, 0) z_prev &amp;lt;- x_next z_next &amp;lt;- x_next mu_prev &amp;lt;- 0 mu_next &amp;lt;- 0 ## helpers Ax &amp;lt;- A %*% x Ax_norm &amp;lt;- norm(Ax) error &amp;lt;- vector(length = iter) iters &amp;lt;- vector(length = iter)&lt;/p&gt;

&lt;p&gt;## main loop for (i in 1:iter) { mu_next &amp;lt;- 0.5 * (1 + sqrt(1 + 4 * mu_prev^2)) gamma &amp;lt;- (1 - mu_prev) / mu_next gradient_x_n &amp;lt;- t(A) %*% ( A %*% x_next - y ) z_tmp &amp;lt;- x_next - eta * gradient_x_n v &amp;lt;- eta * lambda # L1 prox/shrinkage-thresholding z_next &amp;lt;- pmax(z_tmp - v, 0) - pmax(- z_tmp - v, 0) x_next &amp;lt;- z_next + gamma * (z_prev - z_next) z_prev &amp;lt;- z_next mu_prev &amp;lt;- mu_next error[i] &amp;lt;- norm(A %*% x_next - Ax) / Ax_norm iters[i] &amp;lt;- i }&lt;/p&gt;

&lt;p&gt;return(list(x_next, error, iters)) }&lt;/p&gt;

&lt;p&gt;max_iter &amp;lt;- 500; beta &amp;lt;- norm(A, type=”F”)^2&lt;/p&gt;

&lt;p&gt;res1 &amp;lt;- ista(A, x, beta, max_iter) res2 &amp;lt;- fista(A, x, beta, max_iter)&lt;/p&gt;

&lt;p&gt;plot(res1[[3]], res1[[2]], col = “red”, xlab = “iterations”, ylab = “error”, type = ‘l’, lty = 1) lines(res2[[3]], res2[[2]], col = “blue”, type = ‘l’, lty = 1) [/code]&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_868” align=”aligncenter” width=”300” class=” “]&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/07/ista500.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/07/ista500.png?w=300&quot; alt=&quot;ISTA vs FISTA, 500 iterations&quot; /&gt;&lt;/a&gt; ISTA vs FISTA, 500 iterations[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_869” align=”aligncenter” width=”300” class=” “]&lt;a href=&quot;https://umayrh.files.wordpress.com/2014/07/ista5000.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/07/ista5000.png?w=300&quot; alt=&quot;ISTA vs FISTA, 5000 iterations&quot; /&gt;&lt;/a&gt; ISTA vs FISTA, 5000 iterations[/caption]&lt;/p&gt;

&lt;p&gt;Note the non-monotonic convergence in FISTA’s case - [Beck09b, Teboulle10] describe a simple change to the algorithm to fix that. Another interesting problem with FISTA is the dependence on the worst-case smoothness parameter β in the algorithm, which can substantially reduce convergence rate for large β. This is addressed in [Katya14] using a backtracking strategy that  to improve the dependence from worst-case to average “local composite Lipschitz constant for ∇f”, which can have a much smaller value, implying a larger step size. Another solution is presented in [Baes12].&lt;/p&gt;

&lt;p&gt;Recall that ISTA, and hence FISTA, solve the following optimization problems:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\min{(\frac{1}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ax - b&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 + \lambda&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;)}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;FISTA works for non-smooth objectives as long as they can be formulated as the sum of a smooth and a non-smooth function [Section 2, Beck09; Section 3, Tseng08]. Are there efficient first-order algorithms for a larger class of non-smooth problems?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NESTA&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;NESTA [Becker09] solves the following optimization problem that FISTA cannot since the objective function is non-composite non-smooth:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\min{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_1} \\&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ax - b&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2 \le \epsilon[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This algorithm draws on [Nesterov05], which introduces a way to create smooth approximations of certain non-smooth function. This approximation, coupled with an accelerated gradient descent method, gives good convergence for optimizing a large class of non-smooth functions (though not as good as FISTA or Nesterov07). We’ll review [Nesterov05] via [Becker09] before returning to NESTA.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Smoothing non-smooth functions&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Nesterov considers a class of functions that can be represented as [Section 2, Nesterov05; Section 2, Becker09; Nesterov08]&lt;/p&gt;

&lt;p&gt;[latex]\max_{u \in Q_d}\{(Ax - b)^{T}u - \phi{(u)}\}[/latex]&lt;/p&gt;

&lt;p&gt;where φ(u) is a convex function and Qd is the dual domain (convex, closed) of a function f(x) minimized over a domain Qp. The representation is similar to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Convex_conjugate&quot;&gt;convex conjugate&lt;/a&gt;, f*(u), of this function. Indeed Nesterov considers using φ(u) = f*(u), but then argues that such φ(u) might not be a simple enough function. This might be true in general, but as we’ll see that in the special case of L1 regularization, φ(u) = f*(u) will work.&lt;/p&gt;

&lt;p&gt;Nesterov then presents a smooth approximation of the function&lt;/p&gt;

&lt;p&gt;[latex]f_{\mu}(x) = \max_{u \in Q_d}\{(Ax - b)^{T}u - \phi{(u)} - \mu\ prox_{\alpha}(u)\}[/latex]&lt;/p&gt;

&lt;p&gt;where μ is the smoothness parameter, proxα(u) is an α-strongly convex proximal function over the dual domain Qd. In the original paper [Nesterov05], Nesterov actually allows for a composite function approximation, that is f(x) = fº(x) + fμ(x) where fº(x) is some smooth convex function. We’ll follow [Becker09] in assuming that fº(x) = 0. [Beck12] extends this smoothing framework to optimize an even broader class of non-smooth functions.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The important upshot is that (1) this function is smooth with factor [latex]\frac{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;}{\mu \alpha}[/latex] [Theorem 1, Nesterov05], where&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;is the operator norm of A, and (2) that fμ(x) is a uniform smooth approximation of f(x) for μ &amp;gt; 0. So now we can use an optimal gradient descent for smooth optimization to minimize fμ(x).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Smooth optimization&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Section 3 in [Nesterov05] describes an optimal first-order algorithm to minimize a β-smooth convex function f(x) using an α-strongly convex proximal function proxα(x).&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]y_k = \mathrm{argmin}_{y}(\nabla{f(x_k)}^{T} + \frac{1}{2}\beta&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;y - x_k&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2)) \\ z_k=\mathrm{argmin}_{x}(\frac{\beta}{\alpha}\ prox_{\alpha}(x)+\sum_{i=0}^{k}(\frac{i+1}{2}[\nabla{f(x_i)} + \nabla{f(x_i)}^{T}(x - x_i)])) \\ x_{k+1} = \frac{2}{k+1}z_k + \frac{k+1}{k+3}y_k[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This is shown [Theorem 2, Nesterov05] to converge at a rate&lt;/p&gt;

&lt;p&gt;[latex]f(y_k) - f(x*) \le \frac{4 \beta\ prox_{\alpha}(x*)}{\alpha (k+1)(k+2)}[/latex]&lt;/p&gt;

&lt;p&gt;This algorithm is more complicated than the earlier ones [Nesterov83, Nesterov88] - especially when compared to the version FISTA uses (see &lt;a href=&quot;http://umayrh.wordpress.com/2014/07/21/accelerating-first-order-methods/#more-756&quot;&gt;previous post&lt;/a&gt;). The only advantage seems to be a somewhat better convergence rate by a factor of α at the cost of solving two minimization problems (instead of one as in FISTA).&lt;/p&gt;

&lt;p&gt;Applying this algorithm to optimize  fμ(x) [Theorem 3, Nesterov05] gives O(1/k) convergence for the optimal value of μ since&lt;/p&gt;

&lt;p&gt;[latex]f(y_k) - f(x*) \le O(1)\mu + \frac{O(1)}{\mu (k+1)^2} + \frac{O(1)}{(k+1)^2}[/latex]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Nesterov’s Algorithm&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;[Becker09] call their application of [Nesterov05] to L1 regularization, NESTA. They show that&lt;/p&gt;

&lt;p&gt;1. Optimizing over the convex conjugate of L1 norm when combined with an appropriate proximal function yields a simple, well-known function called the &lt;a href=&quot;http://en.wikipedia.org/wiki/Huber_loss_function&quot;&gt;&lt;em&gt;Huber loss&lt;/em&gt;&lt;/a&gt; function. It is analytic and can be computed very efficiently, which makes it trivial to implement gradient descent (quite like the shrinkage-thresholding operation in ISTA/FISTA).&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_1 = \max_{u \in Q_d}{(u^{T}x)} \\ where\ Q_d = {u :&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;u&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_{\infty} \le 1}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Choosing proxα(u) to be the squared Euclidean distance with α = 1 (see also [cf. Section 4.2, Nesterov05]),&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f_{\mu}(x) = \max_{u \in Q_d}\{(u^{T}x) - \frac{\mu}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;u&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2^2\} = \begin{cases}\frac{x^2}{2\mu}, &amp;amp;&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;&amp;lt; \mu \\&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;- \frac{\mu}{2}, &amp;amp; otherwise\end{cases} \\ \nabla{f(x)[i]} = \begin{cases}\frac{x[i]}{\mu}, &amp;amp;&lt;/td&gt;
      &lt;td&gt;x[i]&lt;/td&gt;
      &lt;td&gt;&amp;lt; \mu \\ sgn(x[i]), &amp;amp;otherwise\end{cases}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2. yk and zk updates in the original algorithm need to be modified taking into account the L2 constraint. This is done using the Lagrangian form of each minimization that, under certain assumptions, allows expressing Lagrangian variables in terms of ε.&lt;/p&gt;

&lt;p&gt;3. Another interesting idea is the use of “continuation.” Starting with a large value of the smoothing parameter and multiplicatively decreasing after each iteration helps converge more quickly (although the theoretical convergence rate stays the same).&lt;/p&gt;

&lt;p&gt;Here’s R code for the unconstrained version of NESTA based on FISTA’s version of accelerated gradient descent:&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false” collapse=”true”] nesta &amp;lt;- function(A, x, beta, iter = 100) { ## parameters eta &amp;lt;- 1 / beta lambda &amp;lt;- 1 x_next &amp;lt;- c(0, 0, 0, 0, 0, 0) z_prev &amp;lt;- x_next z_next &amp;lt;- x_next mu_prev &amp;lt;- 0 mu_next &amp;lt;- 0 smooth &amp;lt;- 0.9 * norm(A, &quot;I&quot;) ## helpers Ax &amp;lt;- A %*% x Ax_norm &amp;lt;- norm(Ax) error &amp;lt;- vector(length = iter) iters &amp;lt;- vector(length = iter)&lt;/p&gt;

&lt;p&gt;## main loop for (i in 1:iter) { mu_next &amp;lt;- 0.5 * (1 + sqrt(1 + 4 * mu_prev^2)) gamma &amp;lt;- (1 - mu_prev) / mu_next # grad_huber1 + grad_huber2 = gradient of Huber function   grad_huber1 &amp;lt;- (abs(x_next) &amp;lt; smooth) / smooth grad_huber2 &amp;lt;- (abs(x_next) &amp;gt;= smooth) * ifelse(x_next==0, 0, (x_next / abs(x_next))) gradient_x_n &amp;lt;- t(A) %*% ( A %*% x_next - y ) + grad_huber1 + grad_huber2 z_next &amp;lt;- x_next - eta * gradient_x_n x_next &amp;lt;- z_next + gamma * (z_prev - z_next) z_prev &amp;lt;- z_next mu_prev &amp;lt;- mu_next smooth &amp;lt;- 0.5 * smooth error[i] &amp;lt;- norm(A %*% x_next - Ax) / Ax_norm iters[i] &amp;lt;- i }&lt;/p&gt;

&lt;p&gt;return(list(x_next, error, iters)) } [/code]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Postscript [02/09/2014]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Building on the message-passing (aka belief propagation) algorithms introduced in [Donoho09], [Mousavi13] improve the convergence rate of iterative-shrinkage thresholding algorithm (ISTA) to O(e-t). This was made possible by finding the optimal values of the regularization parameter, λ, at each iteration under the assumption of Gaussian error distribution (which is probably why it escapes the upper-bounds for first-order methods).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt; [&lt;a href=&quot;http://arxiv.org/pdf/1207.3951v1.pdf&quot;&gt;Baes12&lt;/a&gt;] M. Baes, M. Burgisser. An acceleration procedure for optimal first-order methods. 2012 [&lt;a href=&quot;http://mechroom.technion.ac.il/~becka/papers/71654.pdf&quot;&gt;Beck09&lt;/a&gt;] A. Beck, M. Teboulle. A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM Journal of Imaging Sciences, 2009 [&lt;a href=&quot;http://www.math.tau.ac.il/~teboulle/papers/tlv.pdf&quot;&gt;Beck09b&lt;/a&gt;] A. Beck, M. Teboulle. Fast Gradient-Based Algorithms for Constrained Total Variation Image Denoising and Deblurring Problems. IEEE Transactions on Image Processing, 2009. [&lt;a href=&quot;https://iew3.technion.ac.il/Home/Users/becka/smoothing.pdf&quot;&gt;Beck12&lt;/a&gt;] A. Beck, M. Teboulle. Smoothing and First Order Methods: A Unified Approach. SIAM Journal of Optimization, 2012. [&lt;a href=&quot;http://statweb.stanford.edu/~candes/nesta/NESTA.pdf&quot;&gt;Becker09&lt;/a&gt;] S. Becker, J. Bobin, E. Candes. NESTA: A Fast and Accurate First-Order Method for Sparse Recovery. Technical Report, Caltech, 2009 [&lt;a href=&quot;http://www.princeton.edu/~sbubeck/Bubeck14.pdf&quot;&gt;Bubeck14&lt;/a&gt;] S. Bubeck, Theory of Convex Optimization for Machine Learning [&lt;a href=&quot;http://www.ece.rice.edu/~mam15/amp_pnas.pdf&quot;&gt;Donoho09&lt;/a&gt;] D. Donoho, A. Maleki, A. Montanari. Message-passing algorithms for compressed sensing. Proceedings of National Academy of Sciences, 2009. [&lt;a href=&quot;http://arxiv.org/pdf/1311.0035v1.pdf&quot;&gt;Mousavi13&lt;/a&gt;] A. Mousavi, A. Maleki, R. Baranuick. Parameterless optimal approximate message passing. CoRR, 2013 [Nesterov83] Y. Nesterov. A method for solving a convex programming problem with convergence rate O(1/k2). Dokaldy AN SSR, 1983 [Nesterov88] Y. Nesterov. On an approach to the construction of optimal methods of minimization of smooth convex functions. Ekonom. i. Mat. Metody, 1988 [Nesterov04] Y. Nesterov. Introductory Lectures On Convex Programming: A Basic Course. Kluwer Academic Publishers, 2004 [&lt;a href=&quot;http://luthuli.cs.uiuc.edu/~daf/courses/Optimization/MRFpapers/nesterov05.pdf&quot;&gt;Nesterov05&lt;/a&gt;] Y. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 2005. [&lt;a href=&quot;http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=10&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0CHkQFjAJ&amp;amp;url=http%3A%2F%2Fwww.ecore.be%2FDPs%2Fdp_1191313936.pdf&amp;amp;ei=2PPNU7nmEoaT8QHOioGwCA&amp;amp;usg=AFQjCNFLHxemWvAoXMH4NdWlKh8d9sQOrw&amp;amp;bvm=bv.71198958,d.b2U&quot;&gt;Nesterov07&lt;/a&gt;] Y. Nesterov. Gradient methods for minimizing composite objective function. Report, CORE, 2007 [&lt;a href=&quot;http://galton.uchicago.edu/~lekheng/courses/31060s13/nesterov.pdf&quot;&gt;Nesterov08&lt;/a&gt;] Y. Nesterov. How to advance in Structural Convex Optimization. Optima, 2008 [&lt;a href=&quot;http://www.optimization-online.org/DB_FILE/2011/04/3004.pdf&quot;&gt;Katya14&lt;/a&gt;] K. Scheinberg, D. Goldfarb, X. Bai. Fast First-Order Methods for Composite Convex Optimization with Backtracking. Foundations of Computational Mathematics, 2014. [&lt;a href=&quot;https://www.ipam.ucla.edu/publications/optut/optut_9300.pdf&quot;&gt;Teboulle10&lt;/a&gt;]. M. Teboulle. First-Order Methods for Optimization. IPAM Optimization Tutorials, 2010 [&lt;a href=&quot;http://www.mit.edu/~dimitrib/PTseng/papers/apgm.pdf&quot;&gt;Tseng08&lt;/a&gt;] P. Tseng. On Accelerated Proximal Gradient Algorithms for Convex-Concave Optimization. SIAM Journal of Optimization, 2008&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implementations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[1] http://web.stanford.edu/~boyd/papers/prox_algs/lasso.html [2] https://github.com/gpeyre/numerical-tours/tree/master/matlab/solutions [3] https://www.ceremade.dauphine.fr/~peyre/numerical-tour/tours/optim_4_fb/#54 [4] http://www.caam.rice.edu/~optimization/disparse/LASSO/FISTA/pFistaLasso.html [5] http://www.mathworks.com/matlabcentral/fileexchange/16204-toolbox-sparse-optmization/content/toolbox_optim/perform_fb.m [6] http://slipguru.disi.unige.it/Software/L1L2Py/algorithms.html [7] http://www.eecs.berkeley.edu/~yang/software/l1benchmark/ [8] http://www.ece.rice.edu/~tag7/Tom_Goldstein/CGIST.html [9] http://users.ece.gatech.edu/%7Esasif/index.html [10] https://www.ceremade.dauphine.fr/~peyre/numerical-tour/ [11] http://www.mit.edu/~dimitrib/PTseng/papers/apg_alg.m [12] http://www.ece.rice.edu/~tag7/Tom_Goldstein/CGIST.html [13] http://www.math.ucla.edu/~wotaoyin/software.html&lt;/p&gt;
</description>
        <pubDate>Thu, 24 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/24/accelerated-first-order-methods-for-regularization/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/24/accelerated-first-order-methods-for-regularization/</guid>
        
        
      </item>
    
      <item>
        <title>Accelerating first-order methods</title>
        <description>&lt;p&gt;The lower bound on the oracle complexity of continuously differentiable, β-smooth convex function is O(1/√ε) [Theorem 2.1.6, Nesterov04; Theorem 3.8, Bubeck14; Nesterov08]. General first-order gradient descent does not achieve this - e.g. L1-Prox, or ISTA, achieves O(1/ε). Nesterov, in a series of papers [Nesterov83, Nesterov88, Nesterov07], proposed techniques to improve the convergence rate for smooth functions to O(1/t2). In this post, we discuss Nesterov acceleration.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Accelerated gradient descent:&lt;/strong&gt;&lt;strong&gt; α-strongly convex, β-smooth&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Algorithm&lt;/em&gt;: Given a starting point x1 = y1,  then for t ≥ 1&lt;/p&gt;

&lt;p&gt;[latex]y_{k+1} = x_k - \frac{1}{\beta}\nabla{f(x_k)} \\ x_{k+1} = (1 + \frac{\sqrt{Q}-1}{\sqrt{Q}+1})y_{k+1}-(\frac{\sqrt{Q}-1}{\sqrt{Q}+1})y_{k}[/latex]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Theorem&lt;/em&gt;: For α-strongly convex, β-smooth functions with condition number Q = β/α, Nesterov’s accelerated gradient descent satisfies [Theorem 3.11, Bubeck14], which comes close to the lower bound [Theorem 2.1.13, Nesterov04]:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(x_k) - f(x*) \le \frac{\alpha + \beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_1 - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 \exp{(-\frac{k - 1}{\sqrt{Q}})}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Proof sketch&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;1. Following [Bubeck14], one can define an α-strongly convex quadratic approximation to f(x) that improves with each iteration:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\Phi_1(x) = f(x_1) + \frac{\alpha}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - x_1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 \\ \Phi_{k+1}(x) = (1 - \frac{1}{\sqrt{Q}}) \Phi_k(x) + \frac{1}{\sqrt{Q}}(f(x_k) + \nabla{f(x_k)}(x - x_k) + \frac{\alpha}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_k - x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2)[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Then, using the definition of α-strong convexity, one can show that&lt;/p&gt;

&lt;p&gt;[latex]\Phi_{k+1}(x) \le f(x) + (1 - \frac{1}{\sqrt{Q}})^k (\Phi_1(x) - f(x)) [/latex]&lt;/p&gt;

&lt;p&gt;2. Now, assuming the following inequality is true,&lt;/p&gt;

&lt;p&gt;[latex]f(y_k) \le \min_x{\Phi_k(x)}[/latex]&lt;/p&gt;

&lt;p&gt;3. Then one can argue that&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(y_k) - f(x*) \le \Phi_k(x*) - f(x*) \\ \le (1 - \frac{1}{\sqrt{Q}})^{t-1}(\Phi_1(x*) - f(x*)) \\ \le \frac{\alpha + \beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_1 - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 (1 - \frac{1}{\sqrt{Q}})^{t-1}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;**Accelerated gradient descent: &lt;/strong&gt;β-smooth**&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Algorithm&lt;/em&gt;: Given a starting point x1 = y1,  then for t ≥ 1&lt;/p&gt;

&lt;p&gt;[latex]\lambda_0 = 0, \lambda_k = \frac{1+\sqrt{1 + 4\lambda_{k-1}^2}}{2}, \gamma_k = \frac{1 - \lambda_k}{\lambda_{k+1}} \\ y_{k+1} = x_k - \frac{1}{\beta}\nabla{f(x_k)} \\ x_{k+1} = (1 - \gamma_k)y_{k+1} + \gamma_k y_k[/latex]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Theorem&lt;/em&gt;: For non-strictly convex functions, where α = 0, gradient descent satisfies [Theorem 3.12, Bubeck14], which is within a constant factor of the lower bound [Theorem 2.1.7 in Nesterov04]:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(x_k) - f(x*) \le \frac{2\beta&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_1 - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2}{k^2}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Proof sketch&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;1. In a gradient descent scheme for β-smooth functions [Lemma 3.4, Bubeck14]&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(y_{k+1}) - f(y_k) \le \nabla{f(x_k)(x_k - y_k) - \frac{1}{2\beta}}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\nabla{f(x_k)}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 \\ = \beta (x_k - y_{k+1})(x_k - y_k) - \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_k - y_{k+1}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 \\ f(y_{k+1}) - f(x*) \le \beta (x_k - y_{k+1})(x_k - y_k) - \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_k - y_{k+1}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2.  Let δs = f(ys) - f(x*), then scaling the first inequality by (λs - 1) and adding the result to second&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\lambda_k \delta_{k+1} - (\lambda_k - 1) \delta_k \\ \le \beta (x_k - y_{k+1})(\lambda_k x_k - (\lambda_k - 1)y_k - x*) - \frac{\beta}{2} \lambda_k&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_k - y_{k+1}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;3. Scaling by λs and after some manipulation&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\lambda_k^2 \delta_{k+1} - \lambda_{k-1}^2 \delta_k \\ \le \frac{\beta}{2}(&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\lambda_k x_k - (\lambda_k - 1)y_k - x*^2&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 -&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\lambda_k y_{k+1} - (\lambda_k - 1)y_k - x*^2&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2) \\ = \frac{\beta}{2}(&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;u_s&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 -&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;u_{k+1}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2) \ where\ u_k=\lambda_k x_k- (\lambda_k - 1)y_k - x*[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;4. Summing these inequalities from k = 1 to k = t - 1, yields&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\delta_t \le \frac{\beta}{2\lambda_{t-1}^2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;u_1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2, \ and\ \lambda_{t-1} \ge \frac{t}{2}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Interpretation: Chebychev polynomials&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Moritz Hardt elegantly describes an interpretation of accelerated gradient descent based on function interpolation [Hardt13]. Gradient descent can be seen as approximating a function using a degree-k polynomial. For strongly convex functions, the derivative can be expressed as a linear combination of previous steps i.e.&lt;/p&gt;

&lt;p&gt;[latex]x_{k+1} = x_k + \eta_k \nabla{f(x_k)} \\ = A^{T}x + b[/latex]&lt;/p&gt;

&lt;p&gt;Assuming that ∑λs = 1,&lt;/p&gt;

&lt;p&gt;[latex]x_{k+1} - x* \\ = \sum_{s=1}^{k}(\lambda_s (x_s - x*)) \\ = \sum_{s=1}^{k}(\lambda_s A^s) (x_1 - x*) \\ = P_{k}(A)(x_1 - x*) \\ where\ P_{k}(A) = \sum_{s=1}^{k}(\lambda_s A^s)[/latex]&lt;/p&gt;

&lt;p&gt;Thus given that&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_{k+1} - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;P_{k}(\mu)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_A\&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_1 - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;P(μ) needs to be chosen over all eigenvalues of A so that (1) Pk(μ) = 1, for μ = 0, and (2) its maximum norm is minimized. This is hard since it requires knowing all eigenvalues but can be achieved, under certain conditions, if the domain is assumed to be continuous [Kelner09]. In short, a scaled and shifted &lt;a href=&quot;http://en.wikipedia.org/wiki/Chebyshev_polynomials&quot;&gt;Chebychev polynomial&lt;/a&gt; is the unique polynomial that minimizes this approximation error. For Chebychev polynomial, the maximum error is&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\max{(&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;P_{k}(\mu)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;)} = (\frac{\sqrt{Q}-1}{\sqrt{Q} + 1})^k[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Moreover, since Chebychev polynomials can be expressed recursively, required only the two previously calculated polynomials, the gradient descent update only depends on last two values.&lt;/p&gt;

&lt;p&gt;This method seems to be well known in Numerical Analysis, where it is used to speed up iterative linear solvers [chapter 4, Kincaid02; section 7.4,  Saad11]. It also seems to predate Nesterov’s work [Manteuffel77].&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Extension: Bregman Divergence&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Paul Tseng uses &lt;a href=&quot;http://mark.reid.name/blog/meet-the-bregman-divergences.html&quot;&gt;Bregman Divergences&lt;/a&gt; to give a unified framework for Nesterov’s methods across different classes of problems [Tseng08].&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;See also [Taboulle10, Candes11, Hao11, Gordon12] for a good overview of first-order acceleration methods. Next post discusses techniques that utilize accelerated gradient descent to solve regularization problems [Nesterov07, Beck09, Becker09].&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://mechroom.technion.ac.il/~becka/papers/71654.pdf&quot;&gt;Beck09&lt;/a&gt;] A. Beck, M. Teboulle. A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM Journal of Imaging Sciences, 2009 [&lt;a href=&quot;http://statweb.stanford.edu/~candes/nesta/NESTA.pdf&quot;&gt;Becker09&lt;/a&gt;] S. Becker, J. Bobin, E. Candes. NESTA: A Fast and Accurate First-Order Method for Sparse Recovery. Technical Report, Caltech, 2009 [&lt;a href=&quot;http://www.princeton.edu/~sbubeck/Bubeck14.pdf&quot;&gt;Bubeck14&lt;/a&gt;] S. Bubeck, Theory of Convex Optimization for Machine Learning [&lt;a href=&quot;http://statweb.stanford.edu/~candes/math301/Lectures/fast_proximal_methods.pdf&quot;&gt;Candes11&lt;/a&gt;] E. Candes. Math 301, Lectures Notes. [&lt;a href=&quot;http://statweb.stanford.edu/~candes/math301/Lectures/acc_nesterov.pdf&quot;&gt;Chen11&lt;/a&gt;] H. Chen, X. Ming. Accelerating Nesterov’s Method for Strongly Convex Functions. Course presentation, 2011. [&lt;a href=&quot;http://mrtz.org/blog/the-zen-of-gradient-descent/&quot;&gt;Hardt13&lt;/a&gt;] M. Hardt. The Zen of Gradient Descent. Blog, 2013. [&lt;a href=&quot;http://www.cfm.brown.edu/people/gk/chap7/node21.html&quot;&gt;Karniadakis00&lt;/a&gt;] G. E. Karniadakis. R. M. Kirby. Parallel Scientific Computing in C++ and MPI. 2000 [&lt;a href=&quot;http://ocw.mit.edu/courses/mathematics/18-409-topics-in-theoretical-computer-science-an-algorithmists-toolkit-fall-2009/lecture-notes/MIT18_409F09_scribe22.pdf&quot;&gt;Kelner09&lt;/a&gt;] J. Kelner. Lecture Notes. MIT 18.409, Lecture 22, 2009 [&lt;a href=&quot;http://books.google.com/books?id=x69Q226WR8kC&amp;amp;pg=PA224&amp;amp;lpg=PA224&amp;amp;dq=numerical+analysis+chebyshev+acceleration&amp;amp;source=bl&amp;amp;ots=J7e8egYnwg&amp;amp;sig=gT-vbe7DtdAWvcUkFwHEIwNWiZw&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=iUHPU5K-GobE8AHgtIHQBQ&amp;amp;ved=0CFoQ6AEwBg#v=onepage&amp;amp;q=numerical%20analysis%20chebyshev%20acceleration&amp;amp;f=false&quot;&gt;Kincaid02&lt;/a&gt;] D. R. Kincaid, E. W. Cheney. Numerical Analysis: Mathematics of Scientific Computing. AMS, 2002 [Nesterov83] Y. Nesterov. A method for solving a convex programming problem with convergence rate O(1/k2). Dokaldy AN SSR, 1983 [Nesterov88] Y. Nesterov. On an approach to the construction of optimal methods of minimization of smooth convex functions. Ekonom. i. Mat. Metody, 1988 [Nesterov04] Y. Nesterov. Introductory Lectures On Convex Programming: A Basic Course. Kluwer Academic Publishers, 2004 [&lt;a href=&quot;http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=10&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0CHkQFjAJ&amp;amp;url=http%3A%2F%2Fwww.ecore.be%2FDPs%2Fdp_1191313936.pdf&amp;amp;ei=2PPNU7nmEoaT8QHOioGwCA&amp;amp;usg=AFQjCNFLHxemWvAoXMH4NdWlKh8d9sQOrw&amp;amp;bvm=bv.71198958,d.b2U&quot;&gt;Nesterov07&lt;/a&gt;] Y. Nesterov. Gradient methods for minimizing composite objective function. Report, CORE, 2007 [&lt;a href=&quot;http://galton.uchicago.edu/~lekheng/courses/31060s13/nesterov.pdf&quot;&gt;Nesterov08&lt;/a&gt;] Y. Nesterov. How to advance in Structural Convex Optimization. Optima, 2008 [&lt;a href=&quot;http://link.springer.com/article/10.1007%2FBF01389971#page-1&quot;&gt;Manteuffel77&lt;/a&gt;] T. A. Manteuffel. The Tchebyshev iteration for nonsymmetric linear systems. Numer. Math, 1977. [&lt;a href=&quot;http://www-users.cs.umn.edu/~saad/eig_book_2ndEd.pdf&quot;&gt;Saad11&lt;/a&gt;] Y. Saad. Numerical Methods for Large Eigenvalue Problems. SIAM, 2011 [&lt;a href=&quot;https://www.ipam.ucla.edu/publications/optut/optut_9300.pdf&quot;&gt;Taboulle10&lt;/a&gt;]. M. Taboulle. First-Order Methods for Optimization. IPAM Optimization Tutorials, 2010 [&lt;a href=&quot;https://www.cs.cmu.edu/~ggordon/10725-F12/slides/09-acceleration.pdf&quot;&gt;Gordon12&lt;/a&gt;] G. Gordon, R. Tibshirani. Course Notes, 10-725 Optimization, Fall 2012 [&lt;a href=&quot;http://www.mit.edu/~dimitrib/PTseng/papers/apgm.pdf&quot;&gt;Tseng08&lt;/a&gt;] P. Tseng. On Accelerated Proximal Gradient Algorithms for Convex-Concave Optimization. SIAM Journal of Optimization, 2008&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/21/accelerating-first-order-methods/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/21/accelerating-first-order-methods/</guid>
        
        
      </item>
    
      <item>
        <title>Subgradient</title>
        <description>&lt;p&gt;Subgradient generalizes the notion of gradient/derivative and quantifies the rate of change of non-differentiable/non-smooth function ([1], section 8.1 in [2]). For a real-valued function, the &lt;em&gt;subgradients&lt;/em&gt; of the function at a point x0 are all values of c such that:&lt;/p&gt;

&lt;p&gt;[latex]f(x) - f(x_0) \ge c (x - x_0)[/latex]&lt;/p&gt;

&lt;p&gt;Unlike derivative of smooth function, which is a singleton value, the subgradients form a set (e.g. an interval of points). The set of all subgradients is called the &lt;em&gt;subdifferential&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Subdifferential always exists if f(x) is a convex function with a convex domain X, and vice versa (proposition 1.1 in [3]):&lt;/p&gt;

&lt;p&gt;[latex]\forall x,y\in X,f(tx + (1-t)y) \le tf(x) + (1-t)f(y)\leftrightarrow \partial f \not\in \emptyset[/latex]&lt;/p&gt;

&lt;p&gt;The generalized subgradient descent scheme is given as:&lt;/p&gt;

&lt;p&gt;[latex]x_{k+1} = x_k - \lambda \nabla{f(x_k)}[/latex]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Subgradient#The_subgradient&quot;&gt;[1]&lt;/a&gt; Wikipedia, Subgradient [2] J. F. Bonnan, J. C. Gilbert, C. Lemaréchal, C. A. Sagastizábal. Numerical Optimization: Theoretical and Practical Aspects. Second Edition, Springer, 2006 &lt;a href=&quot;http://www.princeton.edu/~sbubeck/Bubeck14.pdf&quot;&gt;[3]&lt;/a&gt; S. Bubeck. Theory of Convex Optimization for Machine Learning. Lecture Notes, 2014&lt;/p&gt;
</description>
        <pubDate>Thu, 17 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/17/subgradient/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/17/subgradient/</guid>
        
        
      </item>
    
      <item>
        <title>First-order methods for regularization</title>
        <description>&lt;p&gt;General first-order methods use only the values of objective/constraints and their subgradients to optimize non-smooth (including constrained) function [5]. Such methods that are oblivious to the structure of the problem are termed &lt;em&gt;black-box optimization&lt;/em&gt; techniques.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why first-order?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Primarily because the computation cost, per iteration, of high-accuracy methods like interior-point generally increases non-linearly, which is prohibitively expensive for very large data-sets (&amp;gt; 100K variables).&lt;/p&gt;

&lt;p&gt;Though the cost per iteration of general methods is low, these methods cannot exploit the structure of the problem. This post discusses two first-order optimization techniques for regularization problems that can exploit the structure of the problem to give better convergence rate than general methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Regularization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Regularization problems in statistics and machine learning, or denoting problems in signal processing, take one of the following forms:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\min{(\frac{1}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ax - b&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2 + \lambda&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;)}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; [latex]\min{f(x)} \\[/latex] [latex]&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;b - Ax&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\le \epsilon[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;indicates some kind of a norm (or seminorm), e.g. L1 or L2 in statistics and Total Variation norm in imaging, and λ is a real-valued regularization parameter. Optimization of such composite convex functions - often with a smooth component, f(x), and a non-smooth component, g(x) - can be expressed as:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;[latex]\min_{x \in \mathbb{R}} {f(x) + \lambda g(x)}[/latex]&lt;/p&gt;

&lt;p&gt;Regularization imposes a structure, using a specific norm, on the solution. For example, using L1 norm encourages sparsity, which often results in more noise-tolerant solutions. This was the motivation behind ridge regression and LASSO [8] in statistical estimation. Unconstrained regularization problems can be solved using (constrained) linear programming while constrained problems may be solved using second-order cone program. Both programs are variants of interior-points algorithms, and too slow for very large data sets. Various first-order methods may be used to solve regularization problem. In fact, for the specific case of regularization problems, first-order method can be shown to converge to an ε-solution at an optimal rate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Complexity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The complexity of first-order methods is often measured in terms of the number of calls to a first-order oracle (section 5.1 in [5]) required to reach an ε-solution. Conversely, the convergence rate gives the approximation error after &lt;em&gt;t&lt;/em&gt; iterations. Nemirovski and Yudin’s work [5] established a lower bound for the information-based complexity of black-box optimization techniques: O(1/ε2) iterations (alternatively, an O(1/√t)-precise solution after t iterations). Furthermore, in many cases, the complexity is still dependent on the dimension, n, of the problem - O(n), in the worst case. For very large dimensional problems, such black-box schemes would converge too slowly.&lt;/p&gt;

&lt;p&gt;Nonetheless, there are large classes of problems - including regularization - for which the complexity is O(1/ε) or, in some cases, O(1/√ε) (theorem 3.8 in [7], section 5.1 in [9] [10, 12]). In such cases, the complexity is also either independent of or only sublinearly dependent on problem dimension, making them feasible for very large dimensional but medium-accuracy problems (such as those in machine learning).&lt;/p&gt;

&lt;p&gt;Why not use polynomial-time interior-point methods for convex optimization?&lt;/p&gt;

&lt;p&gt;While interior-point methods converge rapidly - Ο(e-Ο(t)) - to an ε-solution, the complexity of each iteration is super-linear - O(nk), k &amp;gt; 1. For very large dimensional problems, these methods are prohibitively expensive.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proximal algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;[latex]\min_{x \in \mathbb{R}} {f(x) + \lambda g(x)}[/latex]&lt;/p&gt;

&lt;p&gt;For the composite function optimization problem, we assume that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the problem has a unique minimizer&lt;/li&gt;
  &lt;li&gt;f(x) is β-smooth, convex and differentiable&lt;/li&gt;
  &lt;li&gt;g(x) is convex, subdifferentiable and “simple” (to be clarified later)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the definition of β-smooth convex function, f(x):&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(x_{k+1}) \le f(x_k)+ \nabla{f(x_k)}(x_{k+1} - x_k) + \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_{k+1} - x_k&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For subgradient descent from a given a point xk, we need to find the next point xk+1 such that f(xk+1) is minimized i.e [3].&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]x_{k+1} = \mathrm{argmin}_{x \in \mathbb{R}} f(x_k)+ \nabla{f(x_k)}(x - x_k) + \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - x_k&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For the composite function, f(x) + λg(x), this becomes&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]x_{k+1} = \mathrm{argmin}_{x \in \mathbb{R}} \lambda g(x)+ \nabla{f(x_k)}(x - x_k) + \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - x_k&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;which can be reduced to&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]x_{k+1} = \mathrm{argmin}_{x \in \mathbb{R}} \lambda g(x)+\frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - (x_k - \frac{1}{\beta}\nabla{f(x_k)})&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Despite the fact the each iteration here involves another optimization, a wide class of problems in this form can be solved with &lt;em&gt;proximal minimization algorithms&lt;/em&gt; [13, 14]&lt;em&gt;.&lt;/em&gt;  Proximal algorithms minimizing a β-smooth function f(x) can in general be represented as:&lt;/p&gt;

&lt;p&gt;[latex]x_{k+1} = prox_{\eta,f}(x_k)[/latex]&lt;/p&gt;

&lt;p&gt;where η = 1/β and the proximity operator, proxηf(y), of a scaled function η f(x) is defined as&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\mathrm{argmin}_{x \in \mathbb{R}} f(x) + \frac{1}{2\eta}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For the composite function, f(x) + λg(x), this implies&lt;/p&gt;

&lt;p&gt;[latex]x_{k+1} = prox_{\lambda\eta,g(x)}(x_k - \frac{1}{2\eta\lambda}\nabla{f(x_k)})[/latex]&lt;/p&gt;

&lt;p&gt;Proximal algorithms are useful when the optimization subproblems either admit a closed-form solution or can be rapidly solved numerically. If this is the case, then g(x) is considered “simple.” For example, g(x) in regularization problems is an Lp norm, where p = {1, 2, ∞}. Using the calculus of proximity operators, it is possible to evaluate the closed-form solutions for these norm:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]prox_{\eta,&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_{1}}(y)= \begin{cases} y-\eta, &amp;amp; y\ge \eta\\ 0, &amp;amp;&lt;/td&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt;&amp;lt; \eta\\ y+\eta, &amp;amp; y\le \eta\end{cases}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This operation, for L1 norm, is also called &lt;em&gt;soft thresholding__.&lt;/em&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]prox_{\eta,&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_{2}}(y)= \begin{cases} (1-\frac{\eta}{&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2})y, &amp;amp;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2\ge \eta\\ 0, &amp;amp;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2 &amp;lt; \eta\end{cases}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The operation for L2 norm is also called &lt;em&gt;b__lockwise soft thresholding&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;How rapidly would this scheme converge for composite functions compared to subgradient descent (since g(x) is non-smooth)? Since the proximal algorithm does not need to evaluate the subgradient of g(x) - only the gradient of f(x), which is β-smooth - the convergence rate should the same as that f(x). Following Theorem 3.3 in [7], given the minimum x*,&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex](f(x_k) + \lambda g(x_k)) - (f(x*) + \lambda g(x*)) \le \O(1)\frac{\beta&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x_0 - x*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;}{k}[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;which is much faster than subgradient descent’s O(1/√k). Improving convergence rate to O(1/k2) [1,2] will be the topic of our next post.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;L1-Prox in R&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We give sample code for a basic Iterative Shrinkage-Thresholding Algorithm in R to solve the LASSO problem:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\min_{x \in \mathbb{R}^n}(\frac{1}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ax - b&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_2^2 + \lambda&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_1)[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;which can be reformulated as&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]x_{k+1}=prox_{\frac{\lambda}{\beta},&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;_{1}}(x_k- A^T(Ax - b))[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The smoothness parameter, β, can be evaluated directly since&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]\beta \le&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\nabla^2{f(x)}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;[code language=”r”] ## Corrupted signal and model&lt;/p&gt;

&lt;p&gt;x &amp;lt;- c(1, 2, 3, 4, 5, 6) t &amp;lt;- seq(from = 0, by = 0.02, to = 2*pi) A &amp;lt;- cbind(sin(t), sin(2*t), sin(3*t), sin(4*t), sin(5*t), sin(6*t)) e &amp;lt;- -4+8*rnorm(length(t),0,1) #e[100:115] &amp;lt;- 30 y &amp;lt;- A %*% x + e&lt;/p&gt;

&lt;p&gt;plot(t, A %*% x, ‘l’, col=’blue’, ylab = “signal”, xlab = “time”) lines(t, y)&lt;/p&gt;

&lt;p&gt;## Proximal algorithm for l1&lt;/p&gt;

&lt;p&gt;## parameters iter &amp;lt;- 1000 beta &amp;lt;- norm(A, type=”F”)^2 eta &amp;lt;- 1 / beta lambda &amp;lt;- 1 xx &amp;lt;- c(0, 0, 0, 0, 0, 0)&lt;/p&gt;

&lt;p&gt;## main loop for (i in 1:iter) { gradient_x &amp;lt;- t(A) %*% ( A %*% xx - y ) xx_tmp &amp;lt;- xx - eta * gradient_x v &amp;lt;- eta * lambda # L1 prox/shrinkage-thresholding xx &amp;lt;- pmax(xx_tmp - v, 0) - pmax(- xx_tmp - v, 0) }&lt;/p&gt;

&lt;p&gt;xx&lt;/p&gt;

&lt;p&gt;lines(t, A %*% xx, col=”red”)&lt;/p&gt;

&lt;p&gt;legend(“topright”, legend=c(“original signal”, “corrupted signal”, “recovered signal”), col=c(“black”, “blue”, “red”), lwd=c(1, 1, 1)) [/code]&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;[caption id=”attachment_736” align=”aligncenter” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2014/07/l1prox1.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2014/07/l1prox1.png?w=300&quot; alt=&quot;Signal recovery using L1-Prox&quot; /&gt;&lt;/a&gt; Signal recovery using L1-Prox[/caption]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mechroom.technion.ac.il/~becka/papers/71654.pdf&quot;&gt;[1]&lt;/a&gt; A. Beck, M. Teboulle. A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM J. Imaging Sciences, 2009 &lt;a href=&quot;http://statweb.stanford.edu/~candes/nesta/NESTA.pdf&quot;&gt;[2]&lt;/a&gt; S. Becker, J. Bobin, E. Candes. NESTA: A Fast and Accurate First-Order Method for Sparse Recovery. Technical Report, Caltech, 2009 &lt;a href=&quot;http://blogs.princeton.edu/imabandit/2013/04/11/orf523-ista-and-fista/&quot;&gt;[3]&lt;/a&gt; http://blogs.princeton.edu/imabandit/2013/04/11/orf523-ista-and-fista/ &lt;a href=&quot;https://www.ipam.ucla.edu/publications/optut/optut_9300.pdf&quot;&gt;[4]&lt;/a&gt; M. Teboulle. First-Order Algorithms for Convex Optimization. IPAM, 2010 &lt;a href=&quot;http://www2.isye.gatech.edu/~nemirovs/Lect_ModConvOpt.pdf&quot;&gt;[5]&lt;/a&gt; A. Ben-Tal, A. Nemirovski. Lectures on Modern Convex Optimization. Lecture Notes, 2013 &lt;a href=&quot;http://en.wikipedia.org/wiki/Subgradient#The_subgradient&quot;&gt;[6]&lt;/a&gt; http://en.wikipedia.org/wiki/Subgradient#The_subgradient &lt;a href=&quot;http://www.princeton.edu/~sbubeck/Bubeck14.pdf&quot;&gt;[7]&lt;/a&gt; S. Bubeck. Theory of Convex Optimization for Machine Learning. Lecture Notes, 2014 [8] T. Hastie, R. Tibshirani, J. Friedman. Elements of Statistical Learning. Second Edition. &lt;a href=&quot;http://www.ecore.be/DPs/dp_1329823186.pdf&quot;&gt;[9]&lt;/a&gt; Y. Nesterov. Subgradient Methods for Huge-Scale Optimization Problems. ECORE Discussion Paper, 2012 &lt;a href=&quot;http://www2.isye.gatech.edu/~nemirovs/MLOptChapterI.pdf&quot;&gt;[10]&lt;/a&gt; A. Juditsky, A. Nemirovski. First-Order Methods for Non-Smooth Convex Large-Scale Optimization, 1. Optimization for Machine Learning, [11] J. F. Bonnan, J. C. Gilbert, C. Lemaréchal, C. A. Sagastizábal. Numerical Optimization: Theoretical and Practical Aspects. Second Edition, Springer, 2006 &lt;a href=&quot;https://iew3.technion.ac.il/Home/Users/becka/smoothing.pdf&quot;&gt;[12]&lt;/a&gt; A. Beck, M. Teboulle. Smoothing and First Order Methods: A Unified Framework. SIAM Journal Of Optimization, 2012 &lt;a href=&quot;http://web.stanford.edu/~boyd/papers/prox_algs.html&quot;&gt;[13]&lt;/a&gt; N. Parrikh, S. Boyd. Proximal Algorithms. Foundations and Trends in Optimization, 2014 &lt;a href=&quot;http://www.ljll.math.upmc.fr/~plc/mms1.pdf&quot;&gt;[14]&lt;/a&gt; P. L. Combette, V. R. Wajs. Signal Recovery by Proximal Forward-Backward Splitting. Multiscale Modeling and Simulation, 2005&lt;/p&gt;
</description>
        <pubDate>Thu, 17 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/17/first-order-methods-for-regularization/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/17/first-order-methods-for-regularization/</guid>
        
        
      </item>
    
      <item>
        <title>α-strong convexity, β-strong smoothness</title>
        <description>&lt;p&gt;Strong convexity often allows for optimization algorithms that converge very quickly to an ε-optimum (rf. &lt;a href=&quot;http://mechroom.technion.ac.il/~becka/papers/71654.pdf&quot;&gt;FISTA&lt;/a&gt; and &lt;a href=&quot;http://statweb.stanford.edu/~candes/nesta/NESTA.pdf&quot;&gt;NESTA&lt;/a&gt;). This post will cover some fundamentals of strongly convex functions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convexity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For a convex function, [latex]f: \mathbf{R} \to \mathbf{R}[/latex] and [latex]\forall \gamma \in [0, 1][/latex],&lt;/p&gt;

&lt;p&gt;[latex] f(tx + (1-t)y) \le tf(x) + (1-t)f(y) [/latex]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Strict convexity&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;For a &lt;em&gt;strictly&lt;/em&gt; convex function,&lt;/p&gt;

&lt;p&gt;[latex] f(tx + (1-t)y) &amp;lt; tf(x) + (1-t)f(y) [/latex]&lt;/p&gt;

&lt;p&gt;Geometrically, the definition of convexity implies that all points on any straight line connecting any two points in a convex set also lie in the set. Strict convexity excludes linear and affine functions, or functions with linear/affine subsets in their boundaries. (How would this extend to non-Euclidean geometries?)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;α-strong convexity&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A function is α-strongly convex with respect to a norm&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;if, for α &amp;gt; 0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(tx + (1-t)y) &amp;lt; tf(x) + (1-t)f(y) - \frac{\alpha}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Alternatively,&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex](\nabla{f(x)} - \nabla{f(y)})(x - y) \ge \alpha&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;or,&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(y) \ge f(x)+ \nabla{f(x)}(y - x) + \frac{\alpha}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Strongly convexity extends strict convexity. For twice-differentiable functions, this implies that [latex]\nabla^2f(x) \ge \alpha[/latex]. As Bubeck explains [1], strongly convex functions speed up convergence of first-order methods. Larger values of α imply larger gradient, and hence step size, when further away from the optimum.&lt;/p&gt;

&lt;p&gt;Strong smoothness is another property of certain convex functions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;β-smoothness&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A function is β-smoothly convex with respect to a norm&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;if, for β &amp;gt; 0, [4]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(y) \le f(x)+ \nabla{f(x)}(y - x) + \frac{\beta}{2}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x - y&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This definition gives an lower bound on the improvement in one step of (sub)gradient descent [1]:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(x - \frac{1}{\beta}\nabla{f(x)})- f(x) \le \frac{-1}{2 \beta}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\nabla{f(x)}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Alternatively, β-smoothly convex function [lemma 3.3, 1]:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex]f(x) - f(y) \le \nabla{f(x)}(y - x) - \frac{1}{2 \beta}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\nabla{f(x)} - \nabla{f(y)}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;^2[/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Strong/smooth duality&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Under certain conditions, a-strong convexity and β-smoothness are dual notions. For now, we’ll state the result without discussion.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;If &lt;em&gt;f&lt;/em&gt; is a closed and convex function, then f is α-strongly convex function with respect to a norm&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;if and only if &lt;em&gt;f*&lt;/em&gt; is 1/α-strongly smooth with respect to the dual norm&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;* (corollary 7 in [4]).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.princeton.edu/~sbubeck/Bubeck14.pdf&quot;&gt;[1]&lt;/a&gt; S. Bubeck, Theory of Convex Optimization for Machine Learning, section 3.4 &lt;a href=&quot;http://en.wikipedia.org/wiki/Convex_function#Strongly_convex_functions&quot;&gt;[2]&lt;/a&gt; Wikipedia, Convex function &lt;a href=&quot;http://en.wikipedia.org/wiki/Convex_function#Strongly_convex_functions&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://web.stanford.edu/~boyd/cvxbook/&quot;&gt;[3]&lt;/a&gt; S. Boyd and G. Vandenberghe, Convex Optimization, section 9.1.2 &lt;a href=&quot;http://ttic.uchicago.edu/~shai/papers/KakadeShalevTewari09.pdf&quot;&gt;[4]&lt;/a&gt; S. M. Kakade, S. Shalev-Schwartz, A. Tiwari. On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization. Technical Report, 2009&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/09/strong-convexity/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/09/strong-convexity/</guid>
        
        
      </item>
    
      <item>
        <title>Geometric Median &amp; Robust Estimation</title>
        <description>&lt;p&gt;[caption id=”attachment_1971” align=”alignright” width=”245”]&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/07/geometric_proof.png&quot; alt=&quot;geometric_proof&quot; /&gt; Fermat-Weber &lt;a href=&quot;https://mgje.github.io/presentations/Budapest2014/#/13&quot;&gt;problem&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;Stanislav Minsker addresses the following question:&lt;/p&gt;

&lt;p&gt;Problem: Given X1, …, Xk that are i.i.d. random variables, how can we estimate the mean of the distribution so that the confidence interval still has a coverage probability ≥ 1 - O(e-t)? Note: the smaller the confidence interval, the better the estimator.&lt;/p&gt;

&lt;p&gt;1. Assuming the variables from normal distribution N(μ, σ2). If the estimator is constructed as&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex] \hat{\mu}_n = \Sigma_i X_i / n [/latex] [latex] Pr (&lt;/td&gt;
      &lt;td&gt;\mu_n - \hat{\mu}_n&lt;/td&gt;
      &lt;td&gt;\ge \sigma \sqrt{2t/n} ) \le e^{-t} [/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For non-normal distribution, the confidence interval is much different:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex] Pr (&lt;/td&gt;
      &lt;td&gt;\mu_n - \hat{\mu}_n&lt;/td&gt;
      &lt;td&gt;\ge \sigma \sqrt{e^t/n} ) \le e^{-t} [/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Since the length of this interval depends on et, can we do better?&lt;/p&gt;

&lt;p&gt;2. If we split the sample into k = floor(t) + 1 groups G1, …, Gk each of size approximate n /t, then median-of-means estimator has the following confidence interval (result due to Nemirovskii and Yudin, 1983):&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[latex] \hat{\mu}_{n,k} = median(\hat{\mu}_1, …, \hat{\mu}_k) [/latex] [latex] Pr (&lt;/td&gt;
      &lt;td&gt;\mu_n - \hat{\mu}_n&lt;/td&gt;
      &lt;td&gt;\ge \sigma C \sqrt{t/n} ) \le e^{-t} [/latex]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Where C is a constant. The length of confidence interval for median-of-means is much smaller than for the naive mean estimator.&lt;/p&gt;

&lt;p&gt;3. Minsker’s work extends this to multi-dimensional distributions in Banach space using &lt;em&gt;geometric median&lt;/em&gt; to obtain confidence intervals of sub-exponential length with high coverage.&lt;/p&gt;

&lt;p&gt;More in the paper &lt;a href=&quot;http://sminsker.files.wordpress.com/2013/11/geometric_median_minsker_2.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/08/geometric-median-robust-estimation/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/08/geometric-median-robust-estimation/</guid>
        
        
      </item>
    
      <item>
        <title>EC'14 - some intriguing papers</title>
        <description>&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1402.5758v1.pdf&quot;&gt;1&lt;/a&gt;] &lt;strong&gt;Bandits with concave rewards and convex knapsacks,&lt;/strong&gt; Shipra Agrawal and Nikhil R. Devanur&lt;/p&gt;

&lt;p&gt;Introduces and gives polynomial-time near-optimal algorithms for a general model for bandit exploration-exploitation. The algorithm is an extension of the Upper Confidence Bound (UCB) algorithm for the multi-armed bandits problem. The new framework allows them to give more efficient algorithms for other problems such as Blackwell approachability, online convex optimization and conditional-gradient/projection-free/Frank-Wolfe algorithm.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2427960&quot;&gt;2&lt;/a&gt;] &lt;strong&gt;Managing congestion in decentralized matching markets,&lt;/strong&gt; Nick Arnosti, Ramesh Johari and Yash Kanoria&lt;/p&gt;

&lt;p&gt;Shows that in decentralized two-sided markets with asynchronous arrivals and departures and no information about seller availability, limited seller visibility can improve general welfare.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1404.5127v1.pdf&quot;&gt;3&lt;/a&gt;] &lt;strong&gt;Optimising Trade-offs Among Stakeholders in Ad Auctions,&lt;/strong&gt; Yoram Bachrach, Sofia Ceppi, Ian Kash, Peter Key and David Kurokaw&lt;/p&gt;

&lt;p&gt;Optimizes linear combinations of the utilities of competing stakeholders (auctioneer, user, advertiser) in ad auctions using a generalized second-price (GSP) auction with per-click reserve prices.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1404.6727v1.pdf&quot;&gt;4&lt;/a&gt;] &lt;strong&gt;Multiplicative Bidding in Online Advertising,&lt;/strong&gt; MohammadHossein Bateni, Jon Feldman, Vahab Mirrokni and Sam Chiu-wai Wong&lt;/p&gt;

&lt;p&gt;Establishes the optimization problem behind multiplicative bidding, a bid adjustment technique used by many search engines. They also study the complexity of approximating the solution and give algorithms under various assumptions.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://www.scu.edu/business/economics/upload/YellowPad-TomBlake.pdf&quot;&gt;5&lt;/a&gt;] &lt;strong&gt;Why Marketplace Experimentation is Harder than it Seems: The Role of Test-Control Interference,&lt;/strong&gt; Dominic Coey and Thomas Blake&lt;/p&gt;

&lt;p&gt;Discusses role of and conditions for test-control (A/B) interference in determining the effectiveness of marketplace campaigns&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1404.2750v2.pdf&quot;&gt;6&lt;/a&gt;] &lt;strong&gt;Incentivized Optimal Advert Assignment via Utility Decomposition,&lt;/strong&gt; Frank Kelly, Peter Key and Neil Walton&lt;/p&gt;

&lt;p&gt;Kelly extends his primal-dual optimization framework (originally introduced for communication networks) to formulate a network utility maximization framework for platform and advertisers together. The mechanism introduced is also incentive compatible.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1312.6249v2.pdf&quot;&gt;7&lt;/a&gt;] &lt;strong&gt;The Complexity of Fairness through Equilibrium,&lt;/strong&gt; Abraham Othman, Christos Papadimitriou and Aviad Rubinstein&lt;/p&gt;

&lt;p&gt;Discusses the complexity of approximating Competitive Equilibrium with Equal Income (CEEI, a particular market clearing mechanism that offers efficiency, feasibility and fairness. In short, approximating CEEI in general is hard.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://arxiv.org/pdf/1311.2625v1.pdf&quot;&gt;8&lt;/a&gt;] &lt;strong&gt;Asymptotically Truthful Equilibrium Selection in Large Congestion Games,&lt;/strong&gt; Ryan Rogers and Aaron Roth&lt;/p&gt;

&lt;p&gt;For congestion games with large number of players and incomplete information, this paper introduces mechanism that guarantees a Nash equilibrium improving on previous mechanisms that could only guarantee correlated equilibrium.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;http://www.cs.cmu.edu/~nkshah/papers/euclidean_voting.ec14.pdf&quot;&gt;9&lt;/a&gt;] &lt;strong&gt;Neutrality and Geometry of Mean Voting,&lt;/strong&gt; Sébastien Lahaie and Nisarg Shah&lt;/p&gt;

&lt;p&gt;Integrates the neutrality axiom into mean proximity framework for voting to achieve consensus amongst agents, and shows that the new axiom allows a more compact representation for every mean proximity rule.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;A complete list of papers is available &lt;a href=&quot;http://www.sigecom.org/ec14/accepted_papers.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/07/07/ec14-some-intriguing-papers/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/07/07/ec14-some-intriguing-papers/</guid>
        
        
      </item>
    
      <item>
        <title>Congestion control as optimization, 1</title>
        <description>&lt;h5&gt;&lt;img src=&quot;https://umayrh.files.wordpress.com/2014/06/ss-ca-phases.png&quot; alt=&quot;ss-ca-phases&quot; /&gt;&lt;/h5&gt;

&lt;p&gt;The Internet of 1986 underwent a congestion collapse as available bandwidth dropped by factor of 1000 (1). Transmission Control Protocol (TCP) was then enhanced with various algorithms, two in particular, to ensure that the network reached and stayed close to equilibrium. The algorithms were called “Slow-start” and “Congestion avoidance.” TCP, with these enhancements, has kept the Internet afloat, and spurred much research on the design and analysis of network protocols. Although the initial justifications for these algorithms were control-theoretic - concerned with stability, and, to some extent, efficiency and fairness of allocation - it was only much later that more sophisticated mathematical models for congestion control were developed. In this note, we will focus on the connections between optimization and congestion control. The aim is to try and apply concepts and techniques from congestion control to computational ad serving, especially distributed ad optimization.&lt;/p&gt;

&lt;p&gt;After a brief overview of TCP, we’ll discuss four topics in congestion control:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Increase/decrease algorithms, and linear control systems (2)&lt;/li&gt;
  &lt;li&gt;Online search, and competitive analysis (3)&lt;/li&gt;
  &lt;li&gt;Network optimization, and primal-dual algorithms (4)&lt;/li&gt;
  &lt;li&gt;Network games, and non-cooperative equilibria (5)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(1) V. Jacobson, M. Karels. Congestion Control and Avoidance. Proceedings of SIGCOMM, 1988. (2) D. Chiu, R. Jain. Analysis of the increase and decrease algorithms for congestion avoidance in computer networks. Computer Networks and ISDN Systems, 1989. (3) R. Karp, E. Koutsoupias, C. Papadimitriou, S. Shenker.  Optimization Problems in Congestion Control. Proceedings of FOCS, 2000. (4) F. P. Kelly, A. Maulloo, D. Tan. Rate control in communication networks: shadow prices, proportional fairness and stability. Journal of the Operations Research Society, 1998. (5) C. Papadimitriou. Algorithms, Games and the Internet. Proceedings of STOC, 2001.&lt;/p&gt;

&lt;h5 id=&quot;tcp-congestion-control-overview&quot;&gt;TCP congestion control: overview&lt;/h5&gt;

&lt;p&gt;Two variables are essential for congestion control: the congestion window (CWND) and round-trip time (RTT) (6). CWND controls the number of packets transmitted at a given point in time. RTT indicates the time it takes to receive acknowledgement for a packet. Thus the ratio of CWND to RTT indicates the sender’s instantaneous sending rate. Another parameter, receiver window (RWND), indicates the number of packets that the receiver is willing to receive. Hence the sender needs to send the minimum of RWND and CWND. We’ll assume that the receiver bandwidth is not restrictive and hence RWND » CWND.&lt;/p&gt;

&lt;p&gt;RTT is assumed to be a property of the network, and can be decomposed into a fixed component (propagation delay) and a variable component (queuing delay). It is used primarily to estimate the timeout (RTO) span after which an unacknowledged packet is considered lost, which in turn is interpreted as a binary congestion signal. Although, in some cases (TCP Vegas, FAST TCP e.g.), it is also used directly as  multi-bit congestion signal since queuing delays are usually due to congestion.&lt;/p&gt;

&lt;p&gt;CWND itself is determined or limited by various other parameters such as initial window (IW), slow-start threshold (SSTHRESH). Initial window sets the initial size of the CWND, while SSTHRESH is the maximum value of CWND beyond which TCP enters “congestion avoidance” phase.&lt;/p&gt;

&lt;p&gt;There are two congestion control phases in TCP: slow-start and congestion avoidance. The aim of slow-start is to ramp up the sending rate so that the algorithm reaches close to equilibrium value of available bandwidth as soon as possible. Congestion avoidance, on the other hand, allows staying close to equilibrium without causing congestion.&lt;/p&gt;

&lt;p&gt;Slow-start works by doubling the CWND  for every packet acknowledged (hence once every RTT), which implies exponential increase in CWND size (2, 4, 8, 16…). This is akin to binary search and allows the sender overshoot the equilibrium value by a factor of at most 2 in log(N)*RTT time, where N is the number of packets sent. The first slow-start ends when - because of excessive sending rate, and hence congestion at the gateway/router - a packet is lost. At this point, the sender sets its new SSTHRESH value to be max(FlightSize, 2), where FlightSize is the number of unacknowledged packets (which is generally CWND until unless CWND &amp;gt; RWND). The sender then restarts slow-start till another loss is encountered or CWND = SSTHRESH. If latter, the algorithm moves into congestion avoidance.&lt;/p&gt;

&lt;p&gt;In congestion avoidance, the CWND is increased incrementally. For example, if N packets were sent and acknowledged, then the sender may send (N+1) packets next. In case of severe packet loss (indicated by RTO timeout) slow-start is restarted. Otherwise, CWND keeps growing till packet loss (indicate by duplicate ACKs) is experienced, at which point the CWND is reset to half of SSTHRESH.&lt;/p&gt;

&lt;p&gt;(6) M. Allman, V. Paxon, E. Blanton. TCP Congestion Control. RFC 5681, September 2009.&lt;/p&gt;

&lt;h5 id=&quot;increasedecrease-algorithms-and-linear-control-systems&quot;&gt;Increase/decrease algorithms, and linear control systems&lt;/h5&gt;

&lt;p&gt;[&lt;em&gt;to be concluded&lt;/em&gt;]&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Jun 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2014/06/24/congestion-control-as-optimization/</link>
        <guid isPermaLink="true">http://localhost:4000/2014/06/24/congestion-control-as-optimization/</guid>
        
        
      </item>
    
      <item>
        <title>Estimating uniques - sampling with replacement</title>
        <description>&lt;p&gt;While exploring ways to estimate multiset union and intersection cardinalities, I discovered an interesting result mentioned in a paper by Shukla [1], who in turn cites Feller [2]: If r elements are chosen uniformly and at random from a set of n elements, the expected number of distinct elements obtained is&lt;/p&gt;

&lt;p&gt;$latex n - n (1 - 1/n)^r$.&lt;/p&gt;

&lt;p&gt;Given an element &lt;em&gt;a&lt;/em&gt; from the set, the probability that there are none of the elements after r draws is &lt;em&gt;a&lt;/em&gt; is $latex (1 - 1/n)^r$. Thus the probability that there is at least one element is &lt;em&gt;a&lt;/em&gt; (or equivalently that there is at least one unique item) is $latex 1 - (1 - 1/n)^r$, and hence the expected number of uniques is $latex n - n (1 - 1/n)^r$. Alternatively, as Feller explains, the probability of a single unique at the ith step is $latex ((1 - 1/n)/n)^{i-1}$, hence the expected number of uniques after r draws is&lt;/p&gt;

&lt;p&gt; $latex \sum_{i=1}^{r} ((1 - 1/n)/n)^{i-1}$&lt;/p&gt;

&lt;p&gt;A geometric series that converges to $latex n - n (1 - 1/n)^r$.&lt;/p&gt;

&lt;p&gt;This is an instance of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Birthday_problem&quot;&gt;Birthday problem&lt;/a&gt;. &lt;a href=&quot;http://math.stackexchange.com/questions/72223/finding-expected-number-of-distinct-values-selected-from-a-set-of-integers&quot;&gt;Stackexchange&lt;/a&gt; has a couple of other more complicated but interesting solutions.&lt;/p&gt;

&lt;p&gt;[1] A. Shukla et al, Storage estimation for multidimensional aggregates in the presence of hierarchies [&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.7924&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;paper&lt;/a&gt;] [2] W. Feller, An introduction to probability theory and its applications, vol. 1, 1957&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Oct 2013 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2013/10/26/estimating-uniques-sampling-with-replacement/</link>
        <guid isPermaLink="true">http://localhost:4000/2013/10/26/estimating-uniques-sampling-with-replacement/</guid>
        
        
      </item>
    
      <item>
        <title>Linear Regression in R</title>
        <description>&lt;p&gt;[caption id=”” align=”alignright” width=”265”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/11/regresssolution.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/11/regresssolution.png?w=432&quot; alt=&quot;Image&quot; title=&quot;Regression using L1, L2 and LInf norms&quot; /&gt;&lt;/a&gt; Regression using L1, L2 and LInf norms [&lt;a href=&quot;http://users.isy.liu.se/johanl/yalmip/pmwiki.php?n=Tutorials.LinearAndQuadraticProgramming&quot;&gt;source&lt;/a&gt;][/caption]Given a set of noisy data points, such as the following, how can we find the best fitting linear model?&lt;/p&gt;

&lt;p&gt;[code language=”r” wraplines=”false”]&lt;/p&gt;

&lt;p&gt;x &amp;lt;- c(1, 2, 3, 4, 5, 6) t &amp;lt;- seq(from = 0, by = 0.02, to = 2*pi) A &amp;lt;- cbind(sin(t), sin(2*t), sin(3*t), sin(4*t), sin(5*t), sin(6*t)) e &amp;lt;- -4+8*runif(length(t),min=-1,max=1) e[100:115] &amp;lt;- 30 y = A%*%x + e plot(t, y, ‘l’)&lt;/p&gt;

&lt;p&gt;[/code]&lt;/p&gt;

&lt;p&gt;Various packages in R support linear regression models, such as stats (for least-squares) and quantreg (for quantile regression):&lt;/p&gt;

&lt;p&gt;[code language=”r”]&lt;/p&gt;

&lt;p&gt;library(stats) res1 &amp;lt;- lm(y ~ A) lines(t, res1$fitted.values, col=’green’) qr.solve(A, res1$fitted.values)&lt;/p&gt;

&lt;p&gt;library(MASS) res2 &amp;lt;- rlm(y ~ A) lines(t, res2$fitted.values, col=’red’) qr.solve(A, res2$fitted.values)&lt;/p&gt;

&lt;p&gt;library(quantreg) res3 &amp;lt;- rq(y ~ A) lines(t, res3$fitted.values, col=’darkred’) qr.solve(A, res3$fitted.values) [/code]&lt;/p&gt;

&lt;p&gt;How can we implement these techniques in R to better understand how they work?&lt;/p&gt;

&lt;p&gt;Here are two implementations that use convex optimization:&lt;/p&gt;

&lt;p&gt;[code language=”r”]&lt;/p&gt;

&lt;p&gt;# Ordinary Least Squares regression ols &amp;lt;- function(x, y) { obj &amp;lt;- rep(1, length(x) +2 ) obj[c(1,2)] &amp;lt;- 0 eye &amp;lt;- diag(length(x)) bvec &amp;lt;- y Amat &amp;lt;- cbind(x, rep(1, length(x)), eye) Dmat &amp;lt;- matrix(0, length(x)+2, length(x)+2) diag(Dmat) &amp;lt;- 1; Dmat[1,1] &amp;lt;- 1e-7 Dmat[2,2] &amp;lt;- 1e-7 dvec &amp;lt;- rep(0, length(x)+2) res &amp;lt;- solve.QP(Dmat,dvec,t(Amat),meq=length(x), bvec=bvec) yhat &amp;lt;- res$solution[1]*x +res$solution[2] lines(x, yhat, col=’blue’) }&lt;/p&gt;

&lt;p&gt;# Ordinary Least Absolute Deviation regression olad &amp;lt;- function(x, y) { obj &amp;lt;- rep(1, length(x)+2) obj[c(1,2)] &amp;lt;- 0 eye &amp;lt;- diag(length(x)); mat1 &amp;lt;- cbind(x, rep(1, length(x)), -1*eye) mat2 &amp;lt;- cbind(x, rep(1, length(x)), eye) mat &amp;lt;- rbind(mat1, mat2) dir &amp;lt;- c(rep(“&amp;lt;=”, length(x)), rep(“&amp;gt;=”, length(x))) rhs &amp;lt;- c(y, y) types &amp;lt;- c(rep(“C”, length(x)+2)) max &amp;lt;- F res &amp;lt;- Rglpk_solve_LP(obj, mat, dir, rhs, types = types, max = max) yhat &amp;lt;- res$solution[1]*x +res$solution[2] lines(x, yhat, col=’green’) } [/code]&lt;/p&gt;

&lt;p&gt;How do these implementation work? What are their limitations?&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Nov 2012 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2012/11/19/linear-regression-in-r/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/11/19/linear-regression-in-r/</guid>
        
        
      </item>
    
      <item>
        <title>IP possibilities</title>
        <description>&lt;p&gt;A problem I was asked: suppose a file that stored many valid IPv4 addresses was corrupted such that all dot in the addresses were removed. Given such a corrupt IP, infer all possible corresponding IP addresses. For example, given 12345, all possible addresses are: 12.3.4.5, 1.23.4.5, 1.2.34.5 and 1.2.3.45. The hint that recursion should be used made the problem easier:&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static final int MIN_TOKEN_SIZE = 1; public static final int MAX_TOKEN_SIZE = 3;&lt;/p&gt;

&lt;p&gt;public static List getValidIPs(String ip, int remTokens) { List result = new ArrayList(); double avgTokenSize = ip.length() / (double)remTokens ;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;if ((Double.compare(avgTokenSize, MIN_TOKEN_SIZE) &amp;lt; 0)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;(Double.compare(avgTokenSize, MAX_TOKEN_SIZE) &amp;gt; 0)) return result; else if (remTokens ip = getValidToken(ip); if (ip == null) return result; result.add(ip); return result; }&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;int maxTokenLen = Math.min(ip.length() - remTokens + 1, MAX_TOKEN_SIZE); int minTokenLen = Math.max(ip.length() - (remTokens - 1) * maxTokenLen, MIN_TOKEN_SIZE);&lt;/p&gt;

&lt;p&gt;for (int tokenLen = minTokenLen; tokenLen String prefix = ip.substring(0, tokenLen); String remainder = ip.substring(tokenLen);&lt;/p&gt;

&lt;p&gt;prefix = getValidToken(prefix); if (prefix == null) continue;&lt;/p&gt;

&lt;p&gt;List substrs = getValidIPs(remainder, remTokens-1);&lt;/p&gt;

&lt;p&gt;StringBuffer buf = new StringBuffer(); for (String substr : substrs) { buf.append(prefix); buf.append(‘.’); buf.append(substr); result.add(buf.toString()); buf.setLength(0); } } return result; }&lt;/p&gt;

&lt;p&gt;private static String getValidToken(String prefix) { if (prefix.length() &amp;lt; 1) return null; int val = Integer.parseInt(prefix); if (val &amp;gt; 255) return null; return String.valueOf(val); } [/sourcecode]&lt;/p&gt;

&lt;p&gt;Here a test result:&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static void main(String[] args) { String ip = “8880028”; int remTokens = 4; Set; results = getValidIPs(ip, remTokens); for (String res : results) { System.out.println(res); } } [/sourcecode]&lt;/p&gt;

&lt;p&gt;8.88.0.28 8.88.2.8 88.8.0.28 88.80.2.8 8.8.8.28 8.8.80.28 88.8.2.8 88.80.0.28&lt;/p&gt;

&lt;p&gt;Assuming we weren’t validating IP correctness and wanted to know the number of permutation possible for given number of digits, n, to be split in four IP tokens; how can we go about it? A simple trick is to use to program to find out the sizes, C, of result set for all possible inputs, n:&lt;/p&gt;

&lt;p&gt;n = 4, C = 1
n = 5, C = 4
n = 6, C = 10
n = 7, C = 16
n = 8, C = 19
n = 9, C = 16
n = 10, C = 10
n = 11, C = 4
n = 12, C = 1&lt;/p&gt;

&lt;p&gt;There are at most four recursive calls, one for each token. Each token offers at most three possibilities, but not all the time. Here’s a clumsy recursion to express this program:&lt;/p&gt;

&lt;p&gt;$latex \begin{array} {rcl} D(m, n) &amp;amp; = &amp;amp; \sum\limits_{j}^{k} D(m-i, n-1) \\ k &amp;amp; = &amp;amp; \min (m-n+1, 3) \\ j &amp;amp; = &amp;amp; \max (m+k-kn, 1), \\ D(1 \leq m \leq 3, 1) &amp;amp; = &amp;amp; 1, \\ D(m \geq 4, 1) &amp;amp; = &amp;amp; 0, \\ n &amp;amp; = &amp;amp; 4, \\ 4 \leq &amp;amp; m &amp;amp; \leq 12 \end{array} $&lt;/p&gt;

&lt;p&gt;Desperate to find a closed-form solution to this problem, I searched and found the series (1, 4, 10, 16, 19, 16, 10, 4, 1) in Pascal’s Pyramid [1], which is to trinomial numbers what Pascal’s Triangle is to binomials. Summing the numbers in each column of the layer 4 of Pascal’s pyramid gives:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;  &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;    &lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;     &lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;  &lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;  &lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;  &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;   &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;    &lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;    &lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;  &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For which we can derive a closed form. Given C(n, i, j), the trinomial coefficient for layer n, row i and column j; and C(i, j) the binomial coefficient for row i and column j:&lt;/p&gt;

&lt;p&gt;$latex \begin{array} {rcl} C(n, i, j) &amp;amp; = &amp;amp; C(n, i) \times C(i, j) \\ 0 \leq &amp;amp; i &amp;amp; \leq n \\ 0 \leq &amp;amp; j &amp;amp; \leq i \end{array}$&lt;/p&gt;

&lt;p&gt;A number at a given column (or position) in our desired sequence is the sum of trinomial coefficients for alternating rows (even numbered rows for even m, and odd for odd) and given column. The sequence is symmetric about the median column:&lt;/p&gt;

&lt;p&gt;$latex \begin{array} {rcl} D(m, n) &amp;amp; = &amp;amp; \sum\limits_{i=m-n,i-=2}^{i \geq 0} C(n, i, \lfloor \frac{i}{2} \rfloor) \\ n \leq &amp;amp; m &amp;amp; \leq 2n \\ D(m, n) &amp;amp; = &amp;amp; D(4n-m ,n) \end{array} $&lt;/p&gt;

&lt;p&gt;It turns out that this problem is also related to enumerating lattice paths: Find the set A(n, k) of all lattice paths, from point (0, 0) to (n, k) in a Cartesian plane that use either an up-step (1,1), level-step (0, 1) or down-step (1, -1) [2].&lt;/p&gt;

&lt;p&gt;Update (05/27/12): Corrected the closed-form equation.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;http://en.wikipedia.org/wiki/Pascal%27s_pyramid&quot;&gt;Pascal’s Pyramid&lt;/a&gt; [2] A &lt;a href=&quot;http://www.fq.math.ca/Scanned/40-1/woan.pdf&quot;&gt;Combinatorial Proof&lt;/a&gt; of a Recursive Relation of the Motzkin Sequence by Lattice Paths&lt;/p&gt;
</description>
        <pubDate>Thu, 24 May 2012 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2012/05/24/ip-possibilities/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/05/24/ip-possibilities/</guid>
        
        
      </item>
    
      <item>
        <title>Note on minimax optimization</title>
        <description>&lt;p&gt;At &lt;a href=&quot;http://www.adap.tv&quot; title=&quot;Adap.tv&quot;&gt;Adap.tv&lt;/a&gt;, one of my favorite projects is an ad delivery optimization feature that we internally call the “bid optimizer.” It allows an advertiser to achieve her impression, average CPM (cost per thousand impressions) and performance (click-through rate, completion rate and/or premium impression distribution) goals for a given ad. The ad bids in our second-price auction market-place to try and win impressions on selected sites.&lt;/p&gt;

&lt;p&gt;In general, the bid optimizer’s objective is to minimize the $ per impression that the advertiser has to pay. But our market-place is quite volatile - at least in terms of the winning price of an impression on a given site, with specific targeting, and relatively short forecasting horizon - so forecasting errors are usually large. This problem is exacerbated if the optimizer decides to select most of the impressions from a few sites, in which case forecast error can threaten ad’s impression goal. In this post, I’ll focus on a way that the optimizer can use to improve the diversity of its site portfolio without assuming anything about the forecast accuracy.&lt;/p&gt;

&lt;p&gt;If our ad was not constrained by cost and all the sites selected by the advertiser had the same number of forecasted impressions, then the optimizer would select impressions till it reaches the impression goal. For example, if each of the sites site1, site2 and site3 offered 10,000 impressions, then an optimizer with an impression goal of 18,000 can simply solve the following linear program (necessary if thousands of sites are actually involved) to see what fraction of impressions it needs from each site (there’s no objective since impression goal is fixed and there’s no cost goal):&lt;/p&gt;

&lt;p&gt;Maximize
 objective_function: + 0 site3&lt;/p&gt;

&lt;p&gt;Subject To
 impressions: + 10000 site3 + 10000 site2 + 10000 site1 = 18000&lt;/p&gt;

&lt;p&gt;Bounds
 0 &amp;lt;= site1 &amp;lt;= 1
 0 &amp;lt;= site2 &amp;lt;= 1
 0 &amp;lt;= site3 &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;End&lt;/p&gt;

&lt;p&gt;This formulation effectively only asks to see if the program has a feasible solution, or not, for a given goal and hence there’s no restriction that impressions must be bought from all sites, not just any two. The restriction to buy from as many distinct sites as possible (without violating any other, say cost or performance, constraints) would maximize our portfolio’s diversity, and is best expressed as a &lt;em&gt;maximin optimization&lt;/em&gt; objective: maximize the minimum number of impressions across sites.&lt;/p&gt;

&lt;p&gt;$latex \max [\min (f_1(x),…,f_n(x))] $&lt;/p&gt;

&lt;p&gt;where &lt;em&gt;fi(x)&lt;/em&gt; (i = 1…n) are linear functions of &lt;em&gt;x&lt;/em&gt;. In fact, for our purposes, &lt;em&gt;fi(x)&lt;/em&gt; = &lt;em&gt;Fi_xi__, where _Fi&lt;/em&gt; represents forecasted impressions for site i and &lt;em&gt;xi&lt;/em&gt; is the fraction that the optimizer is interested in.&lt;/p&gt;

&lt;p&gt;Maximin optimization, in general, is a non-linear convex program. Luckily, it’s possible to reformulate it as a linear program [1] by introducing an unbounded, slack variable &lt;em&gt;site0&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;$latex \max z $ $latex s. t. F_{i} x_{i} \ge z $&lt;/p&gt;

&lt;p&gt;Maximize
 objective_function: + site0&lt;/p&gt;

&lt;p&gt;Subject To
 impressions: + 10000 site3 + 10000 site2 + 10000 site1 = 18000
 maximin1: + 10000 site1 - site0 &amp;gt;= 0
 maximin2: + 10000 site2 - site0 &amp;gt;= 0
 maximin3: + 10000 site3 - site0 &amp;gt;= 0&lt;/p&gt;

&lt;p&gt;Bounds
 0 &amp;lt;= site1 &amp;lt;= 1
 0 &amp;lt;= site2 &amp;lt;= 1
 0 &amp;lt;= site3 &amp;lt;= 1
 site0 free&lt;/p&gt;

&lt;p&gt;End&lt;/p&gt;

&lt;p&gt;The maximin linear program would have an optimal solution when 6000 impressions are chosen from each site, thus minimizing the absolute impression difference between any two sites.&lt;/p&gt;

&lt;p&gt;But what if one of the sites could not be part of a feasible solution because otherwise it could violate other goals (e.g. if impression from a site are too expensive or vastly under-perform)? Such cases, which, unfortunately are likely to be the norm, cause this minimax formulation to fail since the minimum number of impressions across &lt;em&gt;all&lt;/em&gt; sites stays at zero to (no impressions selected from at least one site) regardless of the distribution of other fractions. It is tempting to solve this by recasting the problem as:&lt;/p&gt;

&lt;p&gt;$latex \max z $ $latex s. t. x^{T}_{j} F_{i} x_{i} \ge x_i z $&lt;/p&gt;

&lt;p&gt;But such a quadratically-constraint program is far less efficient to solve than a linear program.&lt;/p&gt;

&lt;p&gt;I hope to find a simpler solution to this problem soon.&lt;/p&gt;

&lt;p&gt;Note (05/23/12):&lt;/p&gt;

&lt;p&gt;While reading a StackExchange post [2], I realized that this problem could potentially be reformulated as a mixed integer linear program by introducing binary variables $latex t_1,…,t_n $ corresponding to $latex x_1,…,x_n $ such that&lt;/p&gt;

&lt;p&gt;$latex t_i = 1 \Rightarrow x_i \textgreater 0 $ $latex t_i = 0 \Rightarrow x_i = 0 $&lt;/p&gt;

&lt;p&gt;With the objective function being:&lt;/p&gt;

&lt;p&gt;$latex \max (\sum_i t_i) $&lt;/p&gt;

&lt;p&gt;But what are the right constraints for this formulation? These don’t work with the maximization objective (though will with minimization):&lt;/p&gt;

&lt;p&gt;$latex x_i \leq t_i $&lt;/p&gt;

&lt;p&gt;Note (05/27/12):&lt;/p&gt;

&lt;p&gt;The right constraints (thanks to [3] for showing the way) are:&lt;/p&gt;

&lt;p&gt;$latex x_i \geq \epsilon t_i $ $latex x_i \leq t_i $&lt;/p&gt;

&lt;p&gt;$latex \epsilon $ is the smallest possible non-zero value of $latex x_i $ and, in our case,  must be the inverse of the maximum impressions from any site.&lt;/p&gt;

&lt;p&gt;References: [1] &lt;a href=&quot;http://www.stanford.edu/~boyd/cvxbook/&quot;&gt;Convex Optimization&lt;/a&gt; [2] http://math.stackexchange.com/questions/16788/solution-technique-to-optimize-sets-of-constraint-functions-with-objective-funct [3] &lt;a href=&quot;http://www.aimms.com/aimms/download/manuals/aimms3om_integerprogrammingtricks.pdf&quot;&gt;Integer Programming Tricks&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 23 May 2012 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2012/05/23/note-on-minimax-optimization/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/05/23/note-on-minimax-optimization/</guid>
        
        
      </item>
    
      <item>
        <title>Sorting primer</title>
        <description>&lt;p&gt;A quick overview of several important comparison-based sorting algorithms:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sorting technique&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Time (avg)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Time (worst)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Memory&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Insertion sort&lt;/p&gt;

&lt;p&gt;O(N^2)&lt;/p&gt;

&lt;p&gt;O(N^2)&lt;/p&gt;

&lt;p&gt;O(1)&lt;/p&gt;

&lt;p&gt;Heap sort&lt;/p&gt;

&lt;p&gt;O(NlgN)&lt;/p&gt;

&lt;p&gt;O(NlgN)&lt;/p&gt;

&lt;p&gt;O(1)&lt;/p&gt;

&lt;p&gt;Merge sort&lt;/p&gt;

&lt;p&gt;O(NlgN)&lt;/p&gt;

&lt;p&gt;O(NlgN)&lt;/p&gt;

&lt;p&gt;O(N)&lt;/p&gt;

&lt;p&gt;Quick sort&lt;/p&gt;

&lt;p&gt;O(NlgN)&lt;/p&gt;

&lt;p&gt;O(n^2)&lt;/p&gt;

&lt;p&gt;O(lgN)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Insertion sort&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Iterate over the array, pick each element, and, if the given element is ‘smaller’ than previous; swaps all previous elements till an element even smaller than the given is found or there are no more elements to compare.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static void insertionSort(double[] a) { for (int i = 1; i &amp;lt; a.length; i++) { int k = i; int j = i-1; while ((j &amp;gt;= 0) &amp;amp;&amp;amp; (Double.comapre(a[j], a[k]) &amp;gt; 0)) { double tmp = a[j]; a[j] = a[k]; a[k] = tmp; j–; k–; } } } [/sourcecode]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Heap sort&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Similar to selection sort (iterate over unsorted array, selecting the minimum value in each pass, and placing it in sorted order). Instead of iterating in O(N) time to select the minimum value, a heap is used to do the same in (lgN) time. The following implementation, though, uses a max-heap and so moves the max element found to the right-end of the array.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static void heapSort(double[] a) { heapify(a); // max element as root for (int i = a.length-1; i &amp;gt; 0; i–) { swap(a, 0, i); // put max element at array end siftDown(a, 0, i); // find max from the rest } }&lt;/p&gt;

&lt;p&gt;private static void heapify(double[] a) { for (int i = a.length/2-1; i &amp;gt;= 0; i–) siftDown(a, i, a.length); }&lt;/p&gt;

&lt;p&gt;private static void siftDown(double[] a, int i, int n) { int j = 2*i + 1; while (j &amp;lt; n) { if (j+1 &amp;lt; n) { if (Double.compare(a[j+1], a[j]) &amp;gt; 0) j++; } if(a[i] &amp;gt;= a[j]) return; swap(a, i, j); i = j; j = 2*i+1; } }&lt;/p&gt;

&lt;p&gt;private static void swap(double[] a, int i, int j) { double tmp = a[i]; a[i] = a[j]; a[j] = tmp; } [/sourcecode]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Merge sort&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Repeatedly divide the array into two, almost equal, sorted sub-array and then merge them.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static void mergeSort(double[] a, int start, int end) { if (start &amp;gt;= end-1) { return; } int mid = (end+start) / 2;&lt;/p&gt;

&lt;p&gt;mergeSort(a, start, mid); mergeSort(a, mid, end); merge(a, start, mid, end); }&lt;/p&gt;

&lt;p&gt;private static void merge (double[] a, int start, int mid, int end) { double[] tmp = new double[a.length]; for (int i = 0; i &amp;lt; a.length; i++) tmp[i] = a[i];&lt;/p&gt;

&lt;p&gt;int i = start, j = mid, k = start;&lt;/p&gt;

&lt;p&gt;while ((i &amp;lt; mid) &amp;amp;&amp;amp; (j &amp;lt; end)) { if (tmp[i] &amp;lt;= tmp[j]) { a[k++] = tmp[i++]; } else { a[k++] = tmp[j++]; } } while (i &amp;lt; mid) { a[k++] = tmp[i++]; } } [/sourcecode]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Quick sort&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Recursively partition an array around a pivot element such that all elements less than or equal to pivot are in the left sub-array, and the rest in the right. The following version requires O(lgN) auxiliary space to support recursive calls.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public static void quickSort(double[] a) { qsort(a, 0, a.length); }&lt;/p&gt;

&lt;p&gt;private static void qsort (double[] a, int low, int high) { if (low &amp;gt;= high) return; double pivot = a[(low+high-1)/2]; int i = low-1, j = high; while (i &amp;lt; j) { i++; while (Double.compare(a[i], pivot) &amp;lt; 0) i++; j–; while (Double.compare(a[j], pivot) &amp;gt; 0) j–; if (i &amp;lt; j) swap(a, i, j); }&lt;/p&gt;

&lt;p&gt;qsort(a, low, j); qsort(a, j+1, high); } [/sourcecode]&lt;/p&gt;

&lt;p&gt;References&lt;/p&gt;

&lt;p&gt;[1] http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/heap/heapen.htm [2] http://www.vogella.com/articles/JavaAlgorithmsMergesort/article.html [3] http://www.augustana.ca/~jmohr/courses/2004.winter/csc310/source/QuickSort.java.html&lt;/p&gt;
</description>
        <pubDate>Sun, 20 May 2012 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2012/05/20/sorting-primer/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/05/20/sorting-primer/</guid>
        
        
      </item>
    
      <item>
        <title>Convex optimization in five easy steps</title>
        <description>&lt;p&gt;1. Install &lt;a href=&quot;http://numpy.scipy.org/&quot; title=&quot;NumPy&quot;&gt;NumPy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;sudo apt-get install python-numpy&lt;/p&gt;

&lt;p&gt;2. Install &lt;a href=&quot;http://www.scipy.org&quot; title=&quot;SciPy&quot;&gt;SciPy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;sudo apt-get install python-scipy&lt;/p&gt;

&lt;p&gt;3. Install &lt;a href=&quot;http://abel.ee.ucla.edu/cvxopt/&quot; title=&quot;CVXOPT&quot;&gt;CVXOPT&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;sudo apt-get install python-cvxopt&lt;/p&gt;

&lt;p&gt;4. Install &lt;a href=&quot;http://openopt.org/Welcome&quot; title=&quot;OpenOpt&quot;&gt;OpenOpt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;wget http://openopt.org/images/3/33/OpenOpt.zip
unzip OpenOpt.zip
cd OpenOpt
sudo python setup.py install –prefix=/usr/local/&lt;/p&gt;

&lt;p&gt;5. Run your second-order conic optimization program (&lt;a href=&quot;http://trac.openopt.org/openopt/browser/PythonPackages/OpenOpt/openopt/examples/socp_1.py&quot; title=&quot;source&quot;&gt;source&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/03/socp.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/03/socp.png?w=300&quot; alt=&quot;&quot; title=&quot;SOCP&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[sourcecode language=”python”] “”” OpenOpt SOCP example for the problem http://openopt.org/images/2/28/SOCP.png “””&lt;/p&gt;

&lt;p&gt;from numpy import * from openopt import SOCP&lt;/p&gt;

&lt;p&gt;f = array([-2, 1, 5]) C0 = mat(‘-13 3 5; -12 12 -6’) d0 = [-3, -2] q0 = array([-12, -6, 5]) s0 = -12&lt;/p&gt;

&lt;p&gt;C1 = mat(‘-3 6 2; 1 9 2; -1 -19 3’) d1 = [0, 3, -42] q1 = array([-3, 6, -10]) s1 = 27&lt;/p&gt;

&lt;p&gt;# you could add lb &amp;lt;= x &amp;lt;= ub, Ax &amp;lt;= b, Aeq x = beq constraints # via p = SOCP(f, …, A=A, b=b, Aeq=Aeq, beq=beq,lb=lb, ub=ub) p = SOCP(f,  C=[C0, C1],  d=[d0, d1], q=[q0, q1], s=[s0, s1]) r = p.solve(‘cvxopt_socp’)&lt;/p&gt;

&lt;p&gt;x_opt, f_opt = r.xf,  r.ff&lt;/p&gt;

&lt;p&gt;# f_opt: -38.346368 x_opt: [-5.01428121 -5.76680444 -8.52162517] print(‘ f_opt: %f    x_opt: %s’ % (f_opt, x_opt)) [/sourcecode]&lt;/p&gt;

&lt;p&gt;python socp.py&lt;/p&gt;

&lt;p&gt;————————- OpenOpt 0.38 ————————-
solver: cvxopt_socp   problem: unnamed    type: SOCP   goal: minimum
     pcost       dcost       gap    pres   dres   k/t
 0:  4.9969e+00 -1.7285e+01  6e+01  3e-01  4e+00  1e+00
 1: -1.6732e+00 -7.0431e+00  1e+01  7e-02  1e+00  6e-01
 2: -1.6221e+01 -3.5417e+01  2e+02  3e-01  5e+00  7e+00
 3: -2.1832e+01 -2.2849e+01  3e+01  4e-02  6e-01  2e+00
 4: -3.5265e+01 -3.5594e+01  1e+01  1e-02  2e-01  9e-01
 5: -3.8303e+01 -3.8314e+01  3e-01  4e-04  6e-03  2e-02
 6: -3.8342e+01 -3.8342e+01  1e-02  1e-05  2e-04  7e-04
 7: -3.8346e+01 -3.8346e+01  9e-04  1e-06  2e-05  7e-05
 8: -3.8346e+01 -3.8346e+01  4e-05  6e-08  9e-07  4e-06
 9: -3.8346e+01 -3.8346e+01  2e-06  3e-09  4e-08  2e-07
10: -3.8346e+01 -3.8346e+01  3e-07  4e-10  6e-09  3e-08
Optimal solution found.
istop: 1000 (optimal)
Solver:   Time Elapsed = 0.01     CPU Time Elapsed = 0.01
objFunValue: -38.346368
 f_opt: -38.346368    x_opt: [-5.01469912 -5.76690749 -8.52177183]&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Mar 2012 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2012/03/21/convex-optimization-in-five-easy-steps/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/03/21/convex-optimization-in-five-easy-steps/</guid>
        
        
      </item>
    
      <item>
        <title>Three forecasting techniques</title>
        <description>&lt;p&gt;How well are we doing when forecasting for online ads at &lt;a href=&quot;http://adap.tv/&quot; title=&quot;Adap.tv&quot;&gt;Adap.tv&lt;/a&gt;? Can we do better? To start answering such questions, I used &lt;a href=&quot;http://cran.r-project.org/&quot;&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/a&gt; to experiment with three well-known forecasting techniques and used an hourly metric (transformed for data privacy) across all ads for seven days (Feb 1-Feb 7) as my training data set. Then I use each of the techniques to predict for the eight day (Feb 8), and compare the predicted values with actual data. Here’s a synopsis of the three:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;1. Exponential Weighted Moving Average (EWMA)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Strictly speaking, the smoothing filter that we currently use at Adap.tv for forecasting is not EWMA, but more like Weighted Moving Average. EWMA is defined by:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/en/math/a/3/a/a3a63410a8db7ce3ffae2a78d9ff74c9.png&quot; alt=&quot;S_{t} = \alpha \times (Y_{t-1} + (1-\alpha) \times Y_{t-2} + (1-\alpha)^2 \times Y_{t-3} + ... + (1-\alpha)^k \times Y_{t-(k+1)}) + (1-\alpha)^{k+1} \times S_{t-(k+1)}&quot; /&gt; (&lt;a href=&quot;http://en.wikipedia.org/wiki/Moving_average&quot;&gt;ref&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;So, if a = 0.9, S[t] = 0.9 ( y[t-1] + 0.1*y[t-2] + 0.01*y[3] … 1e-6*y[t-7]) would be an implementation of EWMA. Instead, our implementation is be: S[t] = 0.9 ( y[t-1] + 0.9*y[t-2] + 0.81*y[3] … 0.531441*y[t-7]) / (0.9+…). The critical difference is in the way past data is weighted - with EWMA data in remote past is heavily penalized, whereas, comparatively, in our implementation it is not.&lt;/p&gt;

&lt;p&gt;Fig. 1 below shows a plot that forecasts our metric for Feb 8 using Weighted Moving Average akin to our implementation. The metric forecasted for Feb 8 was 68392533 whereas observed value was 63868927, giving an absolute difference of ~7.1%. The absolute hourly differences lie between 0.6-29%.&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_162” align=”alignnone” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/02/wma2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/02/wma2.png?w=300&quot; alt=&quot;&quot; title=&quot;Weighted moving average&quot; /&gt;&lt;/a&gt; Fig. 1[/caption]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;2. Harmonic regression&lt;/em&gt; Harmonic regression attempts to find the best-fitting periodic signals that can characterize a time series. For example, we a time series may be represented by a linear sum of sinusoids:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/en/math/2/7/3/27359a25f09cb3722c2300b6daa9890e.png&quot; alt=&quot;\frac{a_0}{2} + \sum_{n=1}^\infty \, [a_n \cos(nx) + b_n \sin(nx)]&quot; /&gt; (&lt;a href=&quot;http://en.wikipedia.org/wiki/Fourier_series&quot;&gt;ref&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Generally, a combination of Fourier transform and least-squares regression in used to find the harmonics who linear sum best fit training data. In my experiment, I used the top seven harmonics with highest power density (i.e. contribution to the model), and then used linear regression to find their amplitudes. Fig. 2 shows the model (in red) and actual data (in blue). The forecast for Feb 8 was 60476559 whereas the observed value was 63868927, giving an absolute difference of ~5.3%. The absolute hourly differences lie between 0.05-25%.&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_161” align=”alignnone” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/02/harmreg2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/02/harmreg2.png?w=300&quot; alt=&quot;&quot; title=&quot;Harmonic regression&quot; /&gt;&lt;/a&gt; Fig. 2[/caption]&lt;/p&gt;

&lt;p&gt;&lt;em&gt;3. Holt-Winters method&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Holt-Winters method augments EWMA to account for data trends and seasonality.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/en/math/f/9/5/f95f5a3f2a31fc46fbf0f719629ffc0c.png&quot; alt=&quot;\begin{align}&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
s_0&amp;amp; = x_0\&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
s_{t}&amp;amp; = \alpha \frac{x_{t}}{c_{t-L}} + (1-\alpha)F_t\&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
b_{t}&amp;amp; = \beta (s_t - s_{t-1}) + (1-\beta)b_{t-1}\&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
c_{t}&amp;amp; = \gamma \frac{x_{t}}{s_{t}}+(1-\gamma)c_{t-L}\&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
F_{t+m}&amp;amp; = (s_t + mb_t)c_{(t+m) \pmod L},&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;
\end{align}&quot; /&gt;(&lt;a href=&quot;http://en.wikipedia.org/wiki/Exponential_smoothing&quot;&gt;ref&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;The model I used assumes that the seasonal component is additive (instead of being multiplicative). Fig. 3 illustrates the breakdown of seasonality, trend and randomness in the data,  Fig. 4 contrasts observed data with predicted data (note that the prediction start after one period, and the phase lag in predicted data), while Fig. 5 shows Holt-Winters prediction for Feb 8 versus observed data. The forecasted metric for Feb 8 was 63801332 whereas observed value was 63868927, giving an absolute difference of ~0.11%. The absolute hourly differences lie between 1.3-20%.&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_159” align=”alignnone” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersdecomposition2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersdecomposition2.png?w=300&quot; alt=&quot;&quot; title=&quot;Holt-Winters decomposition&quot; /&gt;&lt;/a&gt; Fig. 3[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_157” align=”alignnone” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersfit2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersfit2.png?w=300&quot; alt=&quot;&quot; title=&quot;Holt-Winters observed/forecasted&quot; /&gt;&lt;/a&gt; Fig. 4[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_156” align=”alignnone” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersprediction2.png&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2012/02/holtwintersprediction2.png?w=300&quot; alt=&quot;&quot; title=&quot;Prediction using Holt-Winters&quot; /&gt;&lt;/a&gt; Fig. 5[/caption]&lt;/p&gt;

&lt;p&gt;TO-DO&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compare these models for other data set time ranges (weeks, months, quarters)&lt;/li&gt;
  &lt;li&gt;Compare these models for other metrics by sub-populations (e.g. by view domains)&lt;/li&gt;
  &lt;li&gt;Test for stationarity, or otherwise heteroscedasticity, across models and data sets. This may be critical since non-stationary time series should &lt;em&gt;not&lt;/em&gt; be modeled with moving average methods&lt;/li&gt;
  &lt;li&gt;Compare models when data is uniformly sampled&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 15 Feb 2012 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2012/02/15/three-forecasting-techniques/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/02/15/three-forecasting-techniques/</guid>
        
        
      </item>
    
      <item>
        <title>Shell scripts</title>
        <description>&lt;p&gt;1. Sorting du output by human-readable&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”bash” wraplines=”false”]du&lt;/td&gt;
      &lt;td&gt;sort -nr&lt;/td&gt;
      &lt;td&gt;cut -f2-&lt;/td&gt;
      &lt;td&gt;xargs du -hs[/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2. Listing number of tcp connections to servers&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”bash” wraplines=”false”]netstat -a&lt;/td&gt;
      &lt;td&gt;grep mysql&lt;/td&gt;
      &lt;td&gt;sort +3 -4&lt;/td&gt;
      &lt;td&gt;tr -s ‘ ‘&lt;/td&gt;
      &lt;td&gt;cut -d’ ‘ -f5&lt;/td&gt;
      &lt;td&gt;cut -d: -f1&lt;/td&gt;
      &lt;td&gt;uniq -c[/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;3. Regex match IP address&lt;/p&gt;

&lt;p&gt;[sourcecode language=”bash” wraplines=”false”]egrep -o “[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+:[0-9]+” /tmp/temp.txt[/sourcecode]&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;4. Sed for pattern matching - match any starting with “2011” and ending with “INFO&lt;/td&gt;
      &lt;td&gt;”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”bash” wraplines=”false”]cat adproc-diag.log&lt;/td&gt;
      &lt;td&gt;grep “:postprocess:”&lt;/td&gt;
      &lt;td&gt;sed “s/2011.*INFO&lt;/td&gt;
      &lt;td&gt;//”&lt;/td&gt;
      &lt;td&gt;grep “:postprocess:SamplingHandler”&lt;/td&gt;
      &lt;td&gt;awk -F: ‘{print $1,$4}’ &amp;gt; postprocess.sampling.log[/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;5. Find all directories inside a directory&lt;/p&gt;

&lt;p&gt;[sourcecode language=”bash” wraplines=”false”]find /market_data/* -type d[/sourcecode]&lt;/p&gt;

&lt;p&gt;6. Finding DB sizes&lt;/p&gt;

&lt;p&gt;[sourcecode language=”sql” wraplines=”false”]SELECT TABLE_SCHEMA AS ‘database’, TABLE_NAME AS ‘tables’, CONCAT(ROUND(((DATA_LENGTH + INDEX_LENGTH - DATA_FREE) / 1024 / 1024),2),” MB”) AS Size FROM INFORMATION_SCHEMA.TABLES where TABLE_SCHEMA like ‘%bonus_reporting%’;[/sourcecode]&lt;/p&gt;

&lt;p&gt;7. Calculate various percentiles given a file containing one numeric observation per line [1]:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”bash” wraplines=”false”]cat data.log&lt;/td&gt;
      &lt;td&gt;sort -n&lt;/td&gt;
      &lt;td&gt;awk ‘BEGIN {count=0} {arr[count]=$1;count++;} END{p[0]=0.5;p[1]=0.75;p[2]=0.9;p[3]=0.95;p[4]=0.99; for(i=0;i&amp;lt;=4;i++){v=int((p[i]*count)+0.5);print (p[i]*100) “th percentile: “ arr[v] “\n”}}’[/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;8. Skip downloading existing files&lt;/p&gt;

&lt;p&gt;[sourcecode language=”bash” wraplines=”false”]rsync -v –ignore-existing -n /source/ username@remote_machine:/dest/[/sourcecode]&lt;/p&gt;

&lt;p&gt;References&lt;/p&gt;

&lt;p&gt;[1] http://www.novell.com/communities/node/8706/check-mysql-database-size-using-sql-query&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Dec 2011 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2011/12/15/shell-scripts/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/12/15/shell-scripts/</guid>
        
        
      </item>
    
      <item>
        <title>Problem: The Dropbox Diet</title>
        <description>&lt;p&gt;Dropbox posed the following problem on their &lt;a href=&quot;http://www.dropbox.com/jobs/challenges&quot;&gt;website&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Of the boatload of perks Dropbox offers, the ones most threatening to our engineers’ waistlines are the daily lunches, the fully-stocked drink fridge, and a full-length bar covered with every snack you could want. All of those calories add up. Luckily, the office is also well-equipped with ping-pong, a DDR machine, and a subsidized gym right across the street that can burn those calories right back off. Although we often don’t, Dropboxers should choose the food they eat to counterbalance the activities they perform so that they don’t end up with caloric deficit or excess.&lt;/p&gt;

  &lt;p&gt;Help us keep our caloric intake in check. You’ll be given a list of activities and their caloric impact. Write a program that outputs the names of activities a Dropboxer should choose to partake in so that the sum of their caloric impact is zero. Once an activity is selected, it cannot be chosen again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;sample-input&quot;&gt;Sample Input&lt;/h5&gt;

&lt;p&gt;2
red-bull 140
coke 110&lt;/p&gt;

&lt;h5 id=&quot;sample-output&quot;&gt;Sample Output&lt;/h5&gt;

&lt;p&gt;no solution&lt;/p&gt;

&lt;p&gt;12
free-lunch 802
mixed-nuts 421
orange-juice 143
heavy-ddr-session -302
cheese-snacks 137
cookies 316
mexican-coke 150
dropballers-basketball -611
coding-six-hours -466
riding-scooter -42
rock-band -195
playing-drums -295&lt;/p&gt;

&lt;p&gt;coding-six-hours
cookies
mexican-coke&lt;/p&gt;

&lt;p&gt;Here is a linear program in Octave that solves it:&lt;/p&gt;

&lt;p&gt;c = [1 1 1 1 1 1 1 1 1 1 1 1];
a = [802 421 143 -302 137 316 150 -611 -466 -42 -195 -295];
b = [0]’;
lb = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
ub = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1];
ctype = “S”;
vartype = “IIIIIIIIIIII”;
sense = -1; % maximize&lt;/p&gt;

&lt;p&gt;param.msglev = 3;
param.itlim = -1;&lt;/p&gt;

&lt;p&gt;[xmin, fmin, status, extra] = glpk (c, a, b, lb, ub, ctype, vartype, sense, param)&lt;/p&gt;

&lt;p&gt;% see also:
% [1] http://bs2.tugraz.at/irt-stud/EOS/glpkmex/glpkmex.m
% [2] http://mosaic.cnfolio.com/B324CW2010A105&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Aug 2011 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2011/08/17/problem-the-dropbox-diet/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/08/17/problem-the-dropbox-diet/</guid>
        
        
      </item>
    
      <item>
        <title>Notes on databases: max allowed packet size</title>
        <description>&lt;p&gt;1. The max.allowed.packet size limits the size of query packet from client. It may be specified at both client and server side. JDBC clients may need to pass “sessionVariables=maxAllowedPacket=…” during connection setup since the driver may not support changing session properties once the session has been established.See also &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/packet-too-large.html&quot;&gt;this post&lt;/a&gt;. On server side, “&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql --max_allowed_packet=32M&lt;/code&gt;&lt;/strong&gt;” to set the property and “show variables like ‘max_allowed_packet” to query it.&lt;/p&gt;

&lt;p&gt;Note that max allowed packet property is distinct from the fetch size property, which limits the number of rows fetched from the database.&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Aug 2011 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2011/08/17/notes-on-database-and-sql/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/08/17/notes-on-database-and-sql/</guid>
        
        
      </item>
    
      <item>
        <title>Fast File Comparison</title>
        <description>&lt;p&gt;[caption id=”attachment_132” align=”aligncenter” width=”300”]&lt;a href=&quot;http://umayrh.files.wordpress.com/2011/07/blog1910sortingmail.jpg&quot;&gt;&lt;img src=&quot;http://umayrh.files.wordpress.com/2011/07/blog1910sortingmail.jpg?w=300&quot; alt=&quot;&quot; title=&quot;Sorting mail&quot; /&gt;&lt;/a&gt; Sorting mail at the Federal Building post office, circa 1910.[/caption]&lt;/p&gt;

&lt;p&gt;Problem: Given a very large number of files, many of whom are &lt;em&gt;exact&lt;/em&gt; replicas, how can we group all files by replicas?&lt;/p&gt;

&lt;p&gt;There are several interesting cases of this problem:&lt;/p&gt;

&lt;p&gt;- Files usually fit in memory - Files are very large, and can only be read in blocks - Most files belong to one or few replica groups&lt;/p&gt;

&lt;p&gt;The obvious and correct solution is to directly compare each file with every other. Generally, this solution should be the best possible only if each file is known to contain a number. If the files contain long binary strings, then a better solution would reduce the number of file comparisons (and memory accesses in case files are very large) as far as possible. One such solution is the following three-pass algorithm:&lt;/p&gt;

&lt;p&gt;1. Iterate over all files and group by file size. In general, we can use any auxiliary information (such as file extension or type etc) that is known to be consistent across replicas.&lt;/p&gt;

&lt;p&gt;2. For each group with at least two files obtained from first pass, we now obtain an numeric representation of its contents. Such representation may be a hash, fingerprint or message digest of the file contents.&lt;/p&gt;

&lt;p&gt;For example, if files are known to contain short strings, then a perfect hash representation of each string may be calculated, and each hash stored in hash-map that contains all files with the same hash. In this case, we don’t need a third pass since the hash completely and uniquely represents file contents. Moreover, comparing files is more efficient since we avoid comparing each string with every other string by only comparing hashes.&lt;/p&gt;

&lt;p&gt;If files are very large, then we can use incremental hash functions to gradually calculate the numeric representation of a file while simultaneously grouping files based on the hash value calculated so far. In the first round, we read a block from each file in the group, calculate the block’s hash using an incremental hash function and group by all files that have the same hash (using, e.g., a hashmap). In the subsequent round, we only read the next block from files with the same previous-round incremental hash value, and calculate and group by the new block’s hash, till there are no more blocks left to read.&lt;/p&gt;

&lt;p&gt;3. A third pass is needed if we have not used a perfect hash function in the second pass, which means that there is non-zero collision probability for hashes and thus different blocks with different content may have had the same hash value. In this case, we have groups containing files with on same hash values across all blocks, and must compare all files with each other. If we consider each file as a queue of blocks, then we can reduce the number of comparisons using an algorithm similar to the one use to merge multiple sorted lists. Instead of merging nodes (i.e. blocks) that are same across lists, we only continue comparing files as long as their blocks are the equal. During each pass, we should be able to find all replicas (if any) of the file being compared with others.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;- INITIALIZE: all files belong to group G1
FOR ALL groups G1, G2 …&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;WHILE file F1 has more blocks
– read a block b1 from F1
– compare b1 with each block read from all other files (F2, F3…) in G1
– IFF for some file F_i, b1 is not equals to b_i, then try inserting F_i based on b_i in all groups other than G1; otherwise create a new group (if it doesn’t exist) G_j and add F_i to G_&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above algorithm, in the worst case, requires O(n^2) block compares.&lt;/p&gt;

&lt;p&gt;The first and second passes might incur unnecessary overhead if it is known &lt;em&gt;a priori&lt;/em&gt; that almost all the files are exact replicas of each other.&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Jul 2011 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2011/07/22/fast-file-comparison/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/07/22/fast-file-comparison/</guid>
        
        
      </item>
    
      <item>
        <title>Perl: split tricks</title>
        <description>&lt;p&gt;Why does the following Perl script give an incorrect field count?&lt;/p&gt;

&lt;p&gt;[sourcecode language=”perl”]#!/bin/perl&lt;/p&gt;

&lt;p&gt;use strict; use warnings; use Data::Dumper;&lt;/p&gt;

&lt;p&gt;my $str = “a\t\t\tb\t\t\t\t6\t\t”; my @fields = split( /\t/, $str); my $n = 0; print Dumper @fields; while ($fields[$n]) { print “$n: $fields[$n]\n”; $n++; } print “Field count: “ . scalar(@fields) . “\n”; print “done!\n”;[/sourcecode]&lt;/p&gt;

&lt;p&gt;Simply because split() function discards trailing null characters when splitting argument string. There are two ways to avoid this:&lt;/p&gt;

&lt;p&gt;1. Force the split() function to map the results to a predefined number of fields, e.g.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”perl”](split( /\t/, $str))[0..8];[/sourcecode]&lt;/p&gt;

&lt;p&gt;2. Append the string to be parsed with a non-delimiter character, e.g. newline, and then remove it:&lt;/p&gt;

&lt;p&gt;[sourcecode language=”perl”]$str = “$str” . “\n”; my @array = split( /\t/, $str); splice(@array, $#array, 1)[/sourcecode]&lt;/p&gt;
</description>
        <pubDate>Fri, 14 Jan 2011 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2011/01/14/perl-split-tricks/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/01/14/perl-split-tricks/</guid>
        
        
      </item>
    
      <item>
        <title>Awk: comparing numbers in two files</title>
        <description>&lt;p&gt;Given two files, each with the first column serving as a key and the second column as value; how can we obtain the percentage difference between corresponding keys in the file?&lt;/p&gt;

&lt;p&gt;For example, if a.txt has data:&lt;/p&gt;

&lt;p&gt;key1 10 key2 20 key3 30&lt;/p&gt;

&lt;p&gt;While b.txt has data:&lt;/p&gt;

&lt;p&gt;key1 5 key2 10 key3 20&lt;/p&gt;

&lt;p&gt;We might be interested in percentage difference between the values, i.e.:&lt;/p&gt;

&lt;p&gt;key1 50 key2 50 key3 33.3&lt;/p&gt;

&lt;p&gt;The following awk script can achieve this, while also skipping any keys not common to both files:&lt;/p&gt;

&lt;p&gt;awk ‘
BEGIN {
   while (getline &amp;lt; “a.txt”) {arr[$1] = $2}
} {
   if (length(arr[$1])==0)
      { print FILENAME”:” $0 }
   else arr2[$1]=$2
}
END {
for (key in arr)
   if (arr2[key]&amp;gt;0)
      { print (arr2[key]-arr[key])*100/arr2[key] }
}’ b.txt&lt;/p&gt;

&lt;p&gt;To achieve the same for more than two files, we can modify the while loop in BEGIN to read the contents of all but the last file into a distinct array and then, in END, comparing the last file’s current key to see if it exists in all arrays before processing the array’s contents.&lt;/p&gt;

&lt;p&gt;To find the number of columns in the last line of all files in a directory:&lt;/p&gt;

&lt;p&gt;#!/bin/bash&lt;/p&gt;

&lt;p&gt;for file in *
  do
    awk -F”\t” ‘END {print FILENAME, NF}’ $file
  done
#&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Jan 2011 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2011/01/10/awk-comparing-numbers-in-two-files/</link>
        <guid isPermaLink="true">http://localhost:4000/2011/01/10/awk-comparing-numbers-in-two-files/</guid>
        
        
      </item>
    
      <item>
        <title>Note on databases: mass deletion, aggregation and migration</title>
        <description>&lt;p&gt;&lt;em&gt;Scenario&lt;/em&gt;: Our company stores ad statistics (e.g. ads viewed) and properties (e.g. homepage) in a database so that marketing folks can query the database according to their needs. The database is MS SQL since it was thought that it would provide better performance for certain queries. This year, the database size grew rapidly such that secondary memory had to be supplemented with USB-based 2TB Flash memory. Eventually, even that filled up and the database was unable to load new data. Thus, our goals are to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Delete all data before January 01, 2010, since it’s too old to be useful&lt;/li&gt;
  &lt;li&gt;Upload the backlog of data into the data base&lt;/li&gt;
  &lt;li&gt;Modify the database update script to aggregate all incoming data over certain keys&lt;/li&gt;
  &lt;li&gt;Migrate the database to a new one with an updated schema&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Observation 1&lt;/em&gt;: Significant differences between SQL scripts written for MS-SQL and MySQL. For example, &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/load-data.html&quot;&gt;LOAD DATA INFILE&lt;/a&gt; queries in MySQL are replaced by &lt;a href=&quot;http://msdn.microsoft.com/en-us/library/ms188365.aspx&quot;&gt;BULK INSERT&lt;/a&gt; queries in MS-SQL. Moreover, bulk queries in MS-SQL may requires explicit permissions from the DBA to be carried out.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Observation 2&lt;/em&gt;: The company actually maintains two databases: the primary database stores the various statistics and properties, while the &lt;a href=&quot;http://www.microsoft.com/sqlserver/2008/en/us/Analysis-Services.aspx&quot;&gt;Cube&lt;/a&gt; is a &lt;a href=&quot;http://en.wikipedia.org/wiki/MOLAP&quot;&gt;MOLAP&lt;/a&gt; that processes (using XML queries) the data (partitioned by the month) in the primary database and then stores the results, to make certain queries (now made using an ODC-based &lt;a href=&quot;http://msdn.microsoft.com/en-us/library/ms178798.aspx&quot;&gt;PivotTable&lt;/a&gt;) much faster and easy to invoke. Before issuing bulk delete, we needed ensure that modifying data did not crash the Cube.&lt;/p&gt;

&lt;p&gt;Bulk delete was nearly disastrous. It seems that the MS SQL Server was writing to C drive while deleting data from the Flash memory. The available space on C drive fell from &amp;lt;100GB to 24Gb in an hour. This was primarily because the database log file kept on increasing. We had better luck deleting rows in batches. How large should a batch be? For example, a batch of 500000 rows took ~2.5min while five batches of 50 million rows took more than five hours. After running the deletion query, we &lt;a href=&quot;http://technet.microsoft.com/en-us/library/ms190757.aspx&quot;&gt;shrank the log files&lt;/a&gt; (located on C drive), as well as the &lt;a href=&quot;http://technet.microsoft.com/en-us/library/ms189035.aspx&quot;&gt;database&lt;/a&gt; (on the Flash-based U drive), to reclaim free space.&lt;/p&gt;

&lt;p&gt;Another problem is determining the number of batches, which would requires us to know the total number of rows being deleted beforehand. Given that this number is very large (in billions), a count query might take too long. We roughly estimated the number of batches by counting the rows being affected for ten days and then using the fact that we had around six months of data to be deleted. Here’s a script to automate the process:&lt;/p&gt;

&lt;p&gt;[sourcecode language=”sql”] Set rowcount to 50000000 to limit number of deletes per batch SET ROWCOUNT 50000000&lt;/p&gt;

&lt;p&gt;DECLARE @innerCount INT SET @innerCount = 0&lt;/p&gt;

&lt;p&gt;DECLARE @outerCount INT SET @outerCount = 0&lt;/p&gt;

&lt;p&gt;WHILE (@outerCount &amp;lt; 3) BEGIN WHILE (@innerCount &amp;lt; 5) BEGIN BEGIN TRANSACTION – Use tablockx and holdlock to obtain and hold – an immediate exclusive table lock. This unusually – speeds the update because only one lock is needed. DELETE [reporting].[dbo].[stats] WITH (tablockx, holdlock) WHERE [stats_date] &amp;lt; 14610 – Commit the transaction COMMIT SET @innerCount = (@innerCount + 1) END – Shrink log files to free up space for future transactions – Note that reporting_log is the name of the log file DBCC SHRINKFILE (reporting_log, 1); – Reclaim free space in the database. This might take a while. – Note that reporting is the name of the database being shrunk DBCC SHRINKDATABASE (reporting);&lt;/p&gt;

&lt;p&gt;SET @outerCount = (@outerCount + 1) END&lt;/p&gt;

&lt;p&gt;-- Remove rowcount limitation SET ROWCOUNT 0&lt;/p&gt;

&lt;p&gt;-- Delete the rest of rows, less than ROWCOUNT BEGIN TRANSACTION DELETE [reporting].[dbo].[stats] WITH (tablockx, holdlock) WHERE [stats_date] &amp;lt; 14610 COMMIT – Validate no rows are left to be deleted SELECT COUNT(*) FROM [reporting].[dbo].[stats] WHERE [stats_date] &amp;lt; 14610 – Shrink again DBCC SHRINKFILE (reporting_log, 1); DBCC SHRINKDATABASE (reporting); [/sourcecode]&lt;/p&gt;

&lt;p&gt;On our system, this query deleted 750 million rows, took 11.5hr to complete, freed up 227GB of memory on U: drive and returned the free space in C: to its normal state. We needed to runs this query a couple more times to delete all rows, taking up 22hr more and finally freeing up ~450GB on U: drive.&lt;/p&gt;

&lt;p&gt;It is now trivial to write a &lt;a href=&quot;http://baishui.info/orelly/linux/dbi/ch08_02.htm&quot;&gt;Perl script&lt;/a&gt; that can remotely connect to a database server (using DBD::Proxy, DBI and DBD::ODBC modules), and execute this query.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Observation 3&lt;/em&gt;: Once deletion is complete, we may start aggregation data over certain columns to further reduce database size. In our case, the table in question is composed of two kinds of columns: keys and values. We may aggregate values (e.g. sum them) for given keys. Thus, assuming that (key_i+1…key_N) are the keys we are aggregating on, this yields an aggregation query with the following format:&lt;/p&gt;

&lt;p&gt;[sourcecode language=”sql”] INSERT INTO aggregated_table (key1…key_i, value1…value_M) ( SELECT key1…key_i, SUM(value1)…SUM(value_M) FROM unaggregated_table GROUP BY key1…key_i ) [/sourcecode]&lt;/p&gt;

&lt;p&gt;Finally, as for migration, which is need to change the number of columns in the database, we need to ensure that the aggregated_table above, when created, include the new columns.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Observation 4&lt;/em&gt;: What if one accidentally truncates a table? It seems that that only way to undo truncation is by ensuring that it is carried out within a transaction. More information on code and limitations available &lt;a href=&quot;http://blog.sqlauthority.com/2010/03/04/sql-server-rollback-truncate-command-in-transaction/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Aug 2010 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2010/08/26/notes-on-databases-mass-deletion-aggregation-and-migration/</link>
        <guid isPermaLink="true">http://localhost:4000/2010/08/26/notes-on-databases-mass-deletion-aggregation-and-migration/</guid>
        
        
      </item>
    
      <item>
        <title>Data Structure Problems: Binary Trees</title>
        <description>&lt;p&gt;1. Mapping a binary tree into a list&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public BinNode treeList(BinNode root) { if (root == null) return null; BinNode left = treeList(root.left); BinNode right = treeList(root.right); root.left = root; root.right = root; left = splice (left, root); left = splice (left, right); return left; }&lt;/p&gt;

&lt;p&gt;BinNode splice (BinNode list1, BinNode list2) { if (list1 == null) return list2; if (list2 == null) return list1; join(list1.left, list2); join(list2.left, list1); return list1; }&lt;/p&gt;

&lt;p&gt;void join(BinNode prev, BinNode next) { prev.right = next; next.left = prev; } [/sourcecode]&lt;/p&gt;

&lt;p&gt;2. Finding the longest path in a binary tree&lt;/p&gt;

&lt;p&gt;Use breadth-first search to find the last node visited - this shall necessarily be one of the longest paths. Maintain pointers in each node to the node’s parent. Use the last node to recursively find all of its ancestors. This&lt;/p&gt;

&lt;p&gt;[sourcecode language=”java”] public Queue getAncestors(BinNode child) { if (child == null) return null; BinNode current = child; Queue queue = new LinkedList(); while (current != null) { queue.add(current); current = current.parent; } return queue; }&lt;/p&gt;

&lt;p&gt;// Returns one of the leaf nodes in the tree, in the // order found using breadth-first search public BinNode getLeafNode (BinNode root) { if (root == null) return null; Queue queue = new LinkedList(); queue.add(root); root.visited=true; BinNode last = null; while(!queue.isEmpty()) { BinNode current = (BinNode) queue.remove(); BinNode child = null; while( (child = getUnvisitedChild (current)) != null ) { child.visited = true; queue.add(child); } last = current; } clearVisited(root); return last; }&lt;/p&gt;

&lt;p&gt;// Returns the unvisited (i.e. visited=false) child of given node, // and null otherwise BinNode getUnvisitedChild (BinNode parent) { if (parent == null) return null; if (parent.left != null &amp;amp;&amp;amp; !parent.left.visited) return parent.left; if (parent.right != null &amp;amp;&amp;amp; !parent.right.visited) return parent.right; return null; }&lt;/p&gt;

&lt;p&gt;// Clears the visited attribute of all nodes, starting // from the root void clearVisited(BinNode root) { if (root == null) return; clearVisited(root.left); root.visited = false; clearVisited(root.right);         } [/sourcecode]&lt;/p&gt;

&lt;p&gt;3. Find the least common ancestor for two given nodes in a tree.&lt;/p&gt;

&lt;p&gt;Search for one of the nodes and mark each node in along path as visited: takes O(log N) time. Search for the other nodes and keep track of the last visited node seen. net O(log N) time. Pre-processing the tree can be used by &lt;a href=&quot;http://en.wikipedia.org/wiki/Lowest_common_ancestor&quot;&gt;off-line algorithms&lt;/a&gt; to yield result constant times.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;p&gt;[1] Some simple binary &lt;a href=&quot;http://cslibrary.stanford.edu/110/BinaryTrees.html&quot;&gt;tree problems&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jul 2010 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2010/07/28/data-structure-problems-binary-trees/</link>
        <guid isPermaLink="true">http://localhost:4000/2010/07/28/data-structure-problems-binary-trees/</guid>
        
        
      </item>
    
      <item>
        <title>Data Structure Problems: Statistics</title>
        <description>&lt;p&gt;1. Algorithm to calculate running mean over a window of N values&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mean = SUM(n)/N therefore given the new data point y and old point x, new_mean = [ SUM(n) +y - x ] / N&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2. Algorithm to calculate running variance/standard deviation over a window of N values&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use the fact that Var[X] = E[X²] - E[X]². Maintain the running mean for the values and the squares of these values to estimate Var[X] and hence standard deviation on the fly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3. Algorithm to calculate running median over a window of N values&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Maintain a queue of values. Enqueue new value, and dequeue old value in O(1) time. Use an &lt;a href=&quot;http://en.wikipedia.org/wiki/Skip_list&quot;&gt;indexable skip list&lt;/a&gt; to remove the old value and to insert the new value in O(logN) time. Access the middle value in O(1) time using the half of the size of the list as index.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4. Algorithm to find the median value in an unsorted list of values.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using an array: sort in O(N log N) time (e.g. using heapsort) and access the middle values. Total time: O(N log N)&lt;/li&gt;
  &lt;li&gt;Use the &lt;a href=&quot;http://en.wikipedia.org/wiki/Selection_algorithm#Linear_general_selection_algorithm_-_Median_of_Medians_algorithm&quot;&gt;BFPRT partitioning algorithm&lt;/a&gt; to select median in worst-case O(N) time. It is as follows: - Recursively, group the data in fives and find the median of each group - Use the median of medians as a pivot to partition about - if current median is the same as pivot, return pivot - if current median is less than pivot, find median of medians till pivot index - if current median is greater, find median of medians from pivot index to end of array&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;References&lt;/p&gt;

&lt;p&gt;- &lt;a href=&quot;ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf&quot;&gt;William Pugh’s paper&lt;/a&gt; on skip lists&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Jul 2010 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2010/07/27/data-structure-problems-statistics/</link>
        <guid isPermaLink="true">http://localhost:4000/2010/07/27/data-structure-problems-statistics/</guid>
        
        
      </item>
    
      <item>
        <title>Data structure problems: Heaps and Priority Queues</title>
        <description>&lt;p&gt;1. Heap: in-place sorting using heap in O(n log n).&lt;/p&gt;

&lt;p&gt;2. Using heaps to improve merge k lists of size n each in O(n log k) time.&lt;/p&gt;

&lt;p&gt;3. How to find the kth smallest element using min-heaps in O(k log k) time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://discuss.joelonsoftware.com/default.asp?interview.11.593253.5&quot;&gt;One solution&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;- On various priority queue functions: &lt;a href=&quot;http://www.utdallas.edu/~ravip/cs3345/slidesweb/node5.html&quot;&gt;read&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sat, 24 Jul 2010 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/2010/07/24/heaps/</link>
        <guid isPermaLink="true">http://localhost:4000/2010/07/24/heaps/</guid>
        
        
      </item>
    
      <item>
        <title>Data structure problems: Linked Lists.</title>
        <description>&lt;p&gt;1. Reversing a singly-linked list:&lt;/p&gt;

&lt;p&gt;(a) &lt;em&gt;Iterative method&lt;/em&gt;: maintain three pointers, two to the nodes being reversed, and one to the next node to be reversed. Continue reversing nodes till the current node goes past the last node.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”cpp”] void reverse() { if (head == NULL&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;head-&amp;gt;next == NULL) return; ListNode *prev = head, *curr = head-&amp;gt;next, *next = (head-&amp;gt;next)-&amp;gt;next; while (curr != NULL) { curr-&amp;gt;next = prev; if (prev == head) prev-&amp;gt;next = NULL; // loop otherwise prev = curr; curr = next; if (next != NULL) next = next-&amp;gt;next; } ListNode *n = head; head = tail; tail = n; } [/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;(b) &lt;em&gt;Recursive method&lt;/em&gt;: Save the pointer to current head node. Starting with the first two node, reverse links and return the last node. Update pointers to head and tail nodes.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[sourcecode language=”cpp”] void recursiveReverse() { ListNode* tmp = head; head = recRev(head, head-&amp;gt;next); tail = tmp; } private: ListNode* recRev(ListNode* prev, ListNode* curr) { if (prev == NULL&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;curr == NULL) return prev; ListNode* next = curr-&amp;gt;next; curr-&amp;gt;next = prev; if (prev == head) prev-&amp;gt;next = NULL; return recRev(curr, next); } [/sourcecode]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2. “There is linked list of millions of node and you do not know the length of it. Write a function which will return a random number from the list.”&lt;/p&gt;

&lt;p&gt;3. “There is a linked list of numbers of length N. N is very large and you don’t know N. You have to write a function that will return k random numbers from the list. Numbers should be completely random. Hint: 1. Use random function rand() (returns a number between 0 and 1) and irand() (return either 0 or 1) 2. It should be done in O(n).”&lt;/p&gt;

&lt;p&gt;4. “Given two linked lists, return the intersection of the two lists: i.e. return a list containing only the elements that occur in both of the input lists.”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sort both lists. Starting with the first element of List1, iterate till the last occurrence of current element. Starting with the first element of List2, iterate till the last occurrence of current element. Compare List1’s current element with List2’s, and iterate on List1 as long as List1 element is less than List2. If elements are equal, then add element to new list, List3. If List2 elements is less than List1, iterate on List2. Repeat while both lists have elements left.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5. “Find or determine non existence of a number in a sorted list of N numbers where the numbers range over M, M» N and N large enough to span multiple disks. Algorithm to beat O(log n) bonus points for constant time algorithm.”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use a Bloom filter: k hash functions (where, optimally, k = (m/N)ln2) map a number to k locations in an m-bit array/vector. No false-negatives i.e. we can determine non-existence of a number mapped to the Bloom filter with certainty. See &lt;a href=&quot;http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html&quot;&gt;this post&lt;/a&gt; for Bloom filter math. “Google &lt;a href=&quot;http://en.wikipedia.org/wiki/BigTable&quot; title=&quot;BigTable&quot;&gt;BigTable&lt;/a&gt; uses Bloom filters to reduce the disk lookups for non-existent rows or columns.”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;6. “You are given a small sorted list of numbers, and a very very long sorted list of numbers - so long that it had to be put on a disk in different blocks. How would you find those short list numbers in the bigger one?”&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Let k be the size of the small list, p be the size of each block and q be the total number of blocks. Then, using binary search on each block, we can find the small number in O(k*q log p) time.&lt;/li&gt;
  &lt;li&gt;Better method: Find the first (i.e. minimum) number in each block and store in a sorted list in O(q). For each unique number in the small list, find which block it may lie in, and then search for the number in O(k log p) time. Total complexity is O(q)+O(k log p).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;7. “Write a function to find the middle node of a single link list.” Maintain a boolean toggle, and two pointers: slower and faster, initially pointing to the head. Move faster to next node till last node, and toggle counter. If toggle is true, move slower to next node. If faster goes beyond last node, return slower.&lt;/p&gt;

&lt;p&gt;[sourcecode language=”cpp”] T findMid() { if (head == NULL) return NULL; ListNode* slower = head, *faster = head; bool toggle = false; while (faster-&amp;gt;next != NULL) { faster = faster-&amp;gt;next; if (toggle) slower = slower-&amp;gt;next; toggle = !toggle; } return slower-&amp;gt;data; } [/sourcecode]&lt;/p&gt;

&lt;p&gt;8. “You are given a list of numbers. When you reach the end of the list you will come back to the beginning of the list (a circular list). Write the most efficient algorithm to find the minimum # in this list. Find any given # in the list. The numbers in the list are always increasing but you don’t know where the circular list begins, ie: 38, 40, 55, 89, 6, 13, 20, 23, 36.”&lt;/p&gt;

&lt;p&gt;9. How to find the kth node from last in a singly-linked list?&lt;/p&gt;
</description>
        <pubDate>Tue, 02 Feb 2010 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2010/02/02/linked-lists/</link>
        <guid isPermaLink="true">http://localhost:4000/2010/02/02/linked-lists/</guid>
        
        
      </item>
    
  </channel>
</rss>
