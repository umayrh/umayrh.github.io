<p>[caption id=”” align=”alignright” width=”265”]<a href="http://umayrh.files.wordpress.com/2012/11/regresssolution.png"><img src="http://umayrh.files.wordpress.com/2012/11/regresssolution.png?w=432" alt="Image" title="Regression using L1, L2 and LInf norms" /></a> Regression using L1, L2 and LInf norms [<a href="http://users.isy.liu.se/johanl/yalmip/pmwiki.php?n=Tutorials.LinearAndQuadraticProgramming">source</a>][/caption]Given a set of noisy data points, such as the following, how can we find the best fitting linear model?</p>

<p>[code language=”r” wraplines=”false”]</p>

<p>x &lt;- c(1, 2, 3, 4, 5, 6) t &lt;- seq(from = 0, by = 0.02, to = 2*pi) A &lt;- cbind(sin(t), sin(2*t), sin(3*t), sin(4*t), sin(5*t), sin(6*t)) e &lt;- -4+8*runif(length(t),min=-1,max=1) e[100:115] &lt;- 30 y = A%*%x + e plot(t, y, ‘l’)</p>

<p>[/code]</p>

<p>Various packages in R support linear regression models, such as stats (for least-squares) and quantreg (for quantile regression):</p>

<p>[code language=”r”]</p>

<p>library(stats) res1 &lt;- lm(y ~ A) lines(t, res1$fitted.values, col=’green’) qr.solve(A, res1$fitted.values)</p>

<p>library(MASS) res2 &lt;- rlm(y ~ A) lines(t, res2$fitted.values, col=’red’) qr.solve(A, res2$fitted.values)</p>

<p>library(quantreg) res3 &lt;- rq(y ~ A) lines(t, res3$fitted.values, col=’darkred’) qr.solve(A, res3$fitted.values) [/code]</p>

<p>How can we implement these techniques in R to better understand how they work?</p>

<p>Here are two implementations that use convex optimization:</p>

<p>[code language=”r”]</p>

<p># Ordinary Least Squares regression ols &lt;- function(x, y) { obj &lt;- rep(1, length(x) +2 ) obj[c(1,2)] &lt;- 0 eye &lt;- diag(length(x)) bvec &lt;- y Amat &lt;- cbind(x, rep(1, length(x)), eye) Dmat &lt;- matrix(0, length(x)+2, length(x)+2) diag(Dmat) &lt;- 1; Dmat[1,1] &lt;- 1e-7 Dmat[2,2] &lt;- 1e-7 dvec &lt;- rep(0, length(x)+2) res &lt;- solve.QP(Dmat,dvec,t(Amat),meq=length(x), bvec=bvec) yhat &lt;- res$solution[1]*x +res$solution[2] lines(x, yhat, col=’blue’) }</p>

<p># Ordinary Least Absolute Deviation regression olad &lt;- function(x, y) { obj &lt;- rep(1, length(x)+2) obj[c(1,2)] &lt;- 0 eye &lt;- diag(length(x)); mat1 &lt;- cbind(x, rep(1, length(x)), -1*eye) mat2 &lt;- cbind(x, rep(1, length(x)), eye) mat &lt;- rbind(mat1, mat2) dir &lt;- c(rep(“&lt;=”, length(x)), rep(“&gt;=”, length(x))) rhs &lt;- c(y, y) types &lt;- c(rep(“C”, length(x)+2)) max &lt;- F res &lt;- Rglpk_solve_LP(obj, mat, dir, rhs, types = types, max = max) yhat &lt;- res$solution[1]*x +res$solution[2] lines(x, yhat, col=’green’) } [/code]</p>

<p>How do these implementation work? What are their limitations?</p>
